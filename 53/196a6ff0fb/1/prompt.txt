I want you to review the whole voice chat module. We have a web based version of the app and a tauri client for it too, and we have the server implementation that also use media soup.

---

Create a voice chat report text file with the result

---

<task-notification>
<task-id>a492c1f</task-id>
<tool-use-id>toolu_01NPHycHRM9WQH7WoLj71rUN</tool-use-id>
<status>completed</status>
<summary>Agent "Explore voice chat server code" completed</summary>
<result>Now I have comprehensive information. Let me create a thorough report:

## COMPREHENSIVE SERVER-SIDE VOICE CHAT / WEBRTC / MEDIASOUP ANALYSIS

### EXECUTIVE SUMMARY

The Yankcord server implements a complete SFU (Selective Forwarding Unit) architecture for voice communication using mediasoup. The system manages WebRTC connections, audio/video producers and consumers, and maintains voice channel state through a combination of database persistence, in-memory state tracking, and real-time WebSocket signaling.

---

### 1. MEDIASOUP ARCHITECTURE & WORKER LIFECYCLE

**File:** `/home/guibibi/projects/yankcord/server/src/media/mod.rs`

#### Key Components:

**MediaService Structure:**
```rust
pub struct MediaService {
    workers: Vec<Worker>,
    routers: Arc<Mutex<HashMap<Uuid, Router>>>,
    connection_media: Arc<Mutex<HashMap<Uuid, transport::ConnectionMediaState>>>,
    webrtc_listen_ip: IpAddr,
    announced_ip: Option<String>,
    native_rtp_listen_ip: IpAddr,
    native_rtp_announced_ip: Option<IpAddr>,
}
```

**Worker Initialization:**
- Creates N workers based on `MEDIA_WORKER_COUNT` configuration (default: 2)
- Workers are created synchronously during server startup
- Each worker is managed by mediasoup's WorkerManager
- No documented worker lifecycle management (no restart/health-check logic)

**Router Management:**
- Routers are cached per channel_id in a HashMap
- Router assignment uses deterministic worker selection: `channel_id.as_bytes()[0] as usize % self.workers.len()`
- **Critical Issue**: Router caching means codec settings (opus_bitrate, opus_dtx, opus_fec) set at channel creation time are never updated after router creation, even if channel settings change
- Routers can be manually invalidated via `invalidate_router()` to force recreation

**Network Configuration:**
- WebRTC transport listen IP and announced IP are configurable
- Native RTP (for screen sharing) has separate listen/announced IP configuration
- Fallback to localhost (127.0.0.1) if IP parsing fails with warnings

---

### 2. ROUTER & CODEC CONFIGURATION

**File:** `/home/guibibi/projects/yankcord/server/src/media/router.rs`

#### Opus Configuration:
```rust
pub struct OpusConfig {
    pub bitrate: Option<u32>,          // Max average bitrate
    pub dtx: Option<bool>,              // Discontinuous Transmission
    pub fec: Option<bool>,              // Forward Error Correction
}
```

**Supported Codecs:**
- **Audio**: Opus (48kHz, stereo, 2 channels)
  - RTCP Feedback: TransportCc
  - Parameters: maxaveragebitrate, usedtx, useinbandfec
- **Video**: VP8, H.264, VP9, AV1
  - RTCP Feedback: Nack, NackPli, CcmFir, GoogRemb, TransportCc
  - H.264: packetization-mode=1, profile-level-id=42e01f

**Configuration Concerns:**
1. Opus parameters are applied at router creation only
2. No runtime codec parameter updates
3. Video codec negotiation not fully exposed to clients
4. Database schema stores opus settings but no per-message codec negotiation

**Database Schema (channels table):**
```sql
opus_bitrate INTEGER      -- Max bitrate in bps
opus_dtx     BOOLEAN      -- Enable DTX
opus_fec     BOOLEAN      -- Enable FEC
```

---

### 3. TRANSPORT MANAGEMENT

**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs`

#### ConnectionMediaState Structure:
```rust
pub struct ConnectionMediaState {
    pub channel_id: Uuid,
    pub send_transport_id: Option<String>,
    pub recv_transport_id: Option<String>,
    pub transports: HashMap<String, WebRtcTransport>,
    pub native_transports_by_producer: HashMap<String, PlainTransport>,
    pub producers: HashMap<String, ProducerEntry>,
    pub consumers: HashMap<String, Consumer>,
}
```

**Transport Creation:**
1. **SendTransport**: Used for uploading audio/video from client
   - Created per direction on demand
   - Replaced if same direction requested again
   - Uses WebRtcTransport with configured listen IPs

2. **RecvTransport**: Used for downloading media from other participants
   - Created per direction on demand
   - Sends existing producers to new recv transport creators
   - Also uses WebRtcTransport

3. **PlainTransport**: Used for native screen sharing
   - Created on demand for screen producers
   - Uses raw RTP/UDP
   - Comedia enabled (automatic endpoint detection)
   - RTCP multiplexed (rtcp_mux=true)

**Critical Logic Issues:**

1. **Channel Validation on Send Transport Creation (Lines 154-162):**
   - If connection switches channels, old ConnectionMediaState is cleared
   - **Issue**: Session switching doesn't properly validate permissions

2. **Duplicate Producer Check (Lines 266-282, 305-321):**
   - Checked TWICE: once before creating and once after
   - Race condition possible between checks
   - Only one camera and one screen producer allowed per connection

3. **Recv Transport Producer Snapshot (Lines 555-600):**
   - When recv transport created, sends all existing channel producers
   - **Issue**: Producer owner username lookup may fail silently (line 570-575)
   - If owner disconnected, producer info not sent to new consumer

**Producer Lifecycle:**
```
1. Client creates send transport
2. Client connects send transport (DTLS handshake)
3. Client calls MediaProduce with RTP parameters
4. Server creates producer on send transport
5. Producer added to state.producers HashMap
6. Other clients notified via broadcast ("new_producer")
7. Other clients create consumers on their recv transports
8. Client can close producer via MediaCloseProducer
```

---

### 4. PRODUCER MANAGEMENT

**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 238-340)

#### ProducerSource Enum:
```rust
pub enum ProducerSource {
    Microphone,  // Audio only
    Camera,      // Video only
    Screen,      // Video only
}
```

#### Validation Constraints:
1. **One camera per connection**: Prevents multiple camera producers simultaneously
2. **One screen per connection**: Prevents multiple screen shares
3. **Microphone**: No per-connection limit (multiple microphone sources possible)
4. **Kind/Source Validation**: Kind must match source (e.g., "microphone" requires kind="audio")

#### Producer Creation Flow:
```
Client sends: MediaProduce {
    kind: "audio"|"video",
    source: "microphone"|"camera"|"screen",
    routing_mode: "sfu",
    rtp_parameters: RtpParameters
}

Server:
1. Validates routing_mode (only "sfu" allowed, no mesh/hybrid)
2. Validates source matches kind
3. Verifies send transport exists
4. Checks camera/screen limits
5. Creates producer with mediasoup
6. Stores in state.producers
7. Broadcasts to all channel members
```

---

### 5. CONSUMER MANAGEMENT

**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 488-568)

#### Consumer Creation Logic:
```rust
pub async fn create_consumer_for_connection(
    connection_id: Uuid,
    channel_id: Uuid,
    producer_id: &str,
    rtp_capabilities: RtpCapabilities,
) -> Result<CreatedConsumer, String>
```

**Key Properties:**
- Created in PAUSED state: `consumer_options.paused = true`
- Client must call `MediaResumeConsumer` to start receiving
- RTP parameters negotiated based on client capabilities

**Validations:**
1. Producer must exist in same channel
2. Client must be in channel
3. Client RTP capabilities must be able to consume producer
4. Router validates compatibility: `router.can_consume()`

**Concerns:**
- No bitrate limits enforced on consumers
- No adaptive bitrate control
- Consumers manually managed (no automatic cleanup on producer close)
- No bandwidth constraints per channel

---

### 6. NATIVE VIDEO CODEC & SCREEN SHARING

**File:** `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs`

#### Native Video Codec Support:
```rust
pub enum NativeVideoCodec {
    H264,   // Ready - PT 96, clock_rate 90kHz
    Vp8,    // Ready - PT 98, clock_rate 90kHz
    Vp9,    // Ready - PT 100, clock_rate 90kHz
    Av1,    // Ready - PT 102, clock_rate 90kHz
}
```

#### Native Sender Session (for Screen Sharing):
```rust
pub struct NativeSenderSession {
    pub producer_id: String,
    pub rtp_target: String,           // Address to send RTP to
    pub payload_type: u8,
    pub ssrc: u32,                    // Canonical SSRC from connection_id
    pub mime_type: String,
    pub clock_rate: u32,
    pub packetization_mode: u8,       // H.264 only
    pub profile_level_id: String,     // H.264 only
    pub codec: NativeCodecDescriptor,
    pub available_codecs: Vec<NativeCodecDescriptor>,
}
```

#### Screen Sharing Flow:
1. Client requests `CreateNativeSenderSession` with optional preferred codecs
2. Server creates PlainTransport with comedia=true
3. Server creates producer on transport
4. Returns RTP target endpoint and codec parameters
5. Client sends raw H.264/VP8/VP9/AV1 RTP packets to target
6. Server forwards through SFU to consumers

**Configuration:**
- H.264: Packetization mode 1 (single NAL per RTP packet)
- SSRC deterministically derived from connection_id (first 4 bytes)
- RTCP cname formatted as `native-{ssrc:x}`

**Issue**: SSRC derivation is deterministic but could theoretically collide for different connection_ids sharing same first 4 bytes. Fallback seed is 0x4E41_5456 if collision detected.

---

### 7. WEBSOCKET SIGNALING LAYER

**File:** `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs`

#### Media Signal Protocol:

**Request Format:**
```json
{
  "action": "get_router_rtp_capabilities|create_webrtc_transport|...",
  "request_id": "optional-string",
  "..." : "other params"
}
```

**Supported Actions:**
1. `GetRouterRtpCapabilities` - Get channel's codec capabilities
2. `CreateWebrtcTransport` - Create send/recv transport
3. `ConnectWebrtcTransport` - Complete DTLS handshake
4. `MediaProduce` - Create producer
5. `MediaConsume` - Create consumer
6. `MediaResumeConsumer` - Resume paused consumer
7. `MediaCloseProducer` - Close producer
8. `CreateNativeSenderSession` - Setup screen sharing
9. `ClientDiagnostic` - Log client diagnostics

#### Rate Limiting:
```rust
const MAX_MEDIA_SIGNAL_EVENTS_PER_WINDOW: u32 = 80;
const MEDIA_SIGNAL_RATE_WINDOW: Duration = Duration::from_secs(5);
```

**Limit**: 80 media signal events per 5-second window per connection

#### Validation:
- request_id max 128 characters
- Payload size limit: 32 KB
- Field constraints: direction (16), transport_id (128), kind (16), source (32), routing_mode (16)

#### Error Handling:
```rust
pub enum MediaSignalSendOutcome {
    Delivered,
    Dropped,    // Serialization failed
    Disconnect, // Queue full or connection closed
}
```

**Policy**: Close connection if outbound queue full (prevents slow-consumer problems)

---

### 8. VOICE CHANNEL STATE MANAGEMENT

**Files:**
- `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 605-631, 1259-1415)
- `/home/guibibi/projects/yankcord/server/src/ws/voice.rs`
- `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` (Lines 318-394)

#### In-Memory State Maps:
```rust
pub struct AppState {
    // Voice channel membership
    pub voice_members_by_connection: Arc<RwLock<HashMap<Uuid, Uuid>>>,
                                     // connection_id -> channel_id
    pub voice_members_by_channel: Arc<RwLock<HashMap<Uuid, HashSet<String>>>>,
                                   // channel_id -> usernames
    // ... other fields
}
```

#### Join Flow:
```
Client: JoinVoice { channel_id }
    ↓
Handler validates:
    1. Channel exists
    2. Channel is voice-enabled
    3. Get channel's opus config
    ↓
Update state:
    1. voice_members_by_connection.insert(connection_id, channel_id)
    2. If switching channels: remove from old channel, cleanup media
    3. voice_members_by_channel.entry(channel_id).or_default().insert(username)
    ↓
Broadcast:
    1. GlobalMessage: VoiceUserJoined
    2. Send to client: VoiceJoined { channel_id, user_id }
```

#### Leave Flow:
```
Client: LeaveVoice { channel_id }
    ↓
Handler:
    1. Remove from voice_members_by_connection
    2. Remove username from voice_members_by_channel
    3. Cleanup producers via media.cleanup_connection_media()
    4. Broadcast closed_producers to channel
    ↓
Broadcast:
    1. GlobalMessage: VoiceUserLeft
    2. Send to client: VoiceLeft { channel_id, user_id }
```

#### Disconnect Handling:
When WebSocket connection closes:
1. `cleanup_connection()` called with connection_id
2. Removes from voice_members_by_connection and voice_members_by_channel
3. Calls `media.cleanup_connection_media()` to close all producers/consumers
4. Broadcasts VoiceUserLeft to all channels
5. Broadcasts closed producer info to affected channels

**Critical State Issue**: 
- No database persistence of voice channel membership
- Membership purely in-memory
- Server restart loses all voice session state
- Clients must rejoin voice channels after server restart

---

### 9. SPEAKING STATUS & VOICE ACTIVITY

**File:** `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 611-632)

#### Voice Activity Flow:
```
Client: VoiceActivity { channel_id, speaking: bool }
    ↓
Handler validates:
    1. Connection is in the specified channel
    2. (No rate limiting on speaking events)
    ↓
Broadcast:
    broadcast_voice_activity_to_channel(state, channel_id, username, speaking, None)
    └─> Sends to all OTHER connections in channel:
        ServerMessage::VoiceUserSpeaking {
            channel_id,
            username,
            speaking
        }
```

**Important Notes:**
- No database recording of speaking status
- Purely ephemeral, real-time signaling
- No speaking history or analytics
- Clients independently detect voice activity (VAD on client side)

---

### 10. PRODUCER/CONSUMER LIFECYCLE & CLEANUP

**Producer Cleanup:**
```
When Producer Closed:
    1. Removed from state.producers
    2. Removed from native_transports_by_producer (if native)
    3. Broadcast ClosedProducer message to channel:
        {
            "action": "producer_closed",
            "producer_id": "...",
            "source": "...",
            "routing_mode": "..."
        }
```

**Consumer Cleanup:**
- No explicit cleanup endpoint
- Consumers auto-close when producer closes
- Manual close not exposed via WebSocket

**Connection Cleanup:**
```
When Connection Disconnects:
    1. state.media.cleanup_connection_media(connection_id)
       └─> Removes all producers/consumers for this connection
    2. Returns Vec<ClosedProducer>
    3. Broadcasts closed_producers to all channels
```

---

### 11. ISSUES, BUGS & ANTI-PATTERNS

#### CRITICAL ISSUES:

1. **Codec Settings Never Update After Router Creation**
   - If channel opus_bitrate/dtx/fec changed after first user joins, new users don't get updated settings
   - Router caching doesn't invalidate on channel update
   - **Impact**: Codec configuration changes require server restart
   - **Solution**: Invalidate router when channel settings change

2. **Producer Owner Lookup Silently Fails**
   - When recv transport created, attempts to get producer owner's username
   - If owner connection already closed, warns but continues
   - New consumer doesn't receive "new_producer" notification for that producer
   - **Impact**: Consumer state out of sync with actual producers in channel
   - **Suggested Fix**: Either cache producer owner info or handle gracefully

3. **No Consumer Auto-Cleanup**
   - Consumers manually managed, no automatic lifecycle
   - When producer closes, consumers still exist in HashMap
   - Consumer close not exposed to client
   - **Impact**: Memory leak of stale consumers
   - **Suggested Fix**: Auto-close consumers when producer closes

4. **Duplicate Camera/Screen Check - TOCTOU**
   - Checked before creation AND after creation
   - Race condition: two concurrent produce requests could both pass first check
   - **Impact**: Theoretically could create 2 cameras per connection
   - **Suggested Fix**: Single atomic check or lock

5. **No Database Persistence of Voice Membership**
   - Voice state purely in-memory
   - Server restart loses all state
   - Clients don't know if they need to rejoin
   - **Impact**: Broken user experience on server restart
   - **Suggested Fix**: Persist voice channel membership in database

#### MEDIUM ISSUES:

6. **Slow Consumer Producer Notifications**
   - When recv transport created, for each producer, sends individual notification
   - N producers = N separate JSON broadcasts
   - No batching/bundling of producers list
   - **Impact**: Inefficient network usage with many producers
   - **Suggested Fix**: Send producer list in single JSON array

7. **No Bandwidth/Bitrate Enforcement**
   - Consumers created without bitrate limits
   - No max-bitrate set on encodings
   - No congestion control feedback from clients
   - **Impact**: Network overload possible
   - **Suggested Fix**: Configure reasonable defaults or per-channel limits

8. **Voice Activity Broadcasting Sends Extra Parameter**
   - `broadcast_voice_activity_to_channel` sends to ALL except sender
   - But the exclude_connection_id is set to None
   - Client sends their own speaking state to themselves too
   - **Impact**: Redundant message
   - **Suggested Fix**: Pass Some(connection_id) to exclude self

9. **No Channel Permission Checks**
   - Join voice doesn't verify user has permission to access channel
   - No ACL or role-based channel access control for voice
   - **Impact**: Any authenticated user can join any voice channel
   - **Suggested Fix**: Add channel permission model

10. **Mediasoup Worker Health Not Monitored**
    - Workers created at startup, no restart logic
    - No health checks or deadlock detection
    - Worker crash would cause silent failures
    - **Impact**: Server silently stops accepting voice connections
    - **Suggested Fix**: Add worker health monitoring and auto-restart

#### MINOR ISSUES:

11. **SSRC Derivation Collision Risk**
    - Canonical SSRC uses only first 4 bytes of UUID
    - Fallback seed only triggers if exactly 0
    - **Impact**: Extremely low, but possible SSRC collision
    - **Suggested Fix**: Use full UUID or CRC32 of full UUID

12. **No Requested Codec Preference Validation**
    - Client can request any codec, server just filters to ready ones
    - No limit on preferred_codecs list length
    - **Impact**: Mild - clients well-behaved, but no server-side guards

13. **Transport Direction Replaced Without Warning**
    - Creating send transport twice replaces first one
    - Any media sent on old transport is lost
    - **Impact**: Client-side bug would lose media
    - **Suggested Fix**: Return error if transport already exists

14. **Mediasoup Error Messages Exposed**
    - mediasoup library errors directly sent to client
    - Could expose internal implementation details
    - **Impact**: Low security impact, but information disclosure

---

### 12. CONFIGURATION SETTINGS

**File:** `/home/guibibi/projects/yankcord/server/src/config.rs`

```rust
pub struct MediaConfig {
    pub worker_count: usize,                    // ENV: MEDIA_WORKER_COUNT (default: 2)
    pub webrtc_listen_ip: String,               // ENV: WEBRTC_LISTEN_IP (default: 0.0.0.0)
    pub announced_ip: Option<String>,           // ENV: WEBRTC_ANNOUNCED_IP
    pub native_rtp_listen_ip: String,           // ENV: NATIVE_RTP_LISTEN_IP (default: 127.0.0.1)
    pub native_rtp_announced_ip: Option<String>,// ENV: NATIVE_RTP_ANNOUNCED_IP
}
```

**Environment Variables:**
- `MEDIA_WORKER_COUNT`: Number of mediasoup workers (must be ≥1)
- `WEBRTC_LISTEN_IP`: IP for WebRTC transport to listen on
- `WEBRTC_ANNOUNCED_IP`: Public IP announced in ICE candidates
- `NATIVE_RTP_LISTEN_IP`: IP for native RTP screen sharing
- `NATIVE_RTP_ANNOUNCED_IP`: Public IP for native RTP

**WebSocket Configuration (hardcoded):**
- Outbound queue capacity: 256 messages
- Idle timeout: 45 seconds
- Auth timeout: 15 seconds
- Presence idle (auto-idle status): 5 minutes

**Rate Limiting:**
- Media signal: 80 events per 5 seconds per connection
- Payload size limit: 32 KB per media signal

---

### 13. DATABASE SCHEMA FOR VOICE

```sql
-- Channels table (created in migrations/20260216000001_initial.sql)
CREATE TABLE channels (
    id              UUID PRIMARY KEY,
    name            TEXT NOT NULL,
    description     TEXT,
    kind            channel_kind,  -- 'text' or 'voice'
    position        INT NOT NULL,
    opus_bitrate    INTEGER,       -- Opus max average bitrate (bps)
    opus_dtx        BOOLEAN,       -- Opus discontinuous transmission
    opus_fec        BOOLEAN,       -- Opus forward error correction
    created_at      TIMESTAMPTZ
);
```

**No other voice-specific tables.**

**Missing Features:**
- No voice history/recording
- No meeting recordings
- No voice activity timeline
- No user voice settings per channel
- No voice mute/deafen state persistence
- No voice channel permissions model

---

### 14. KEY FILES & FUNCTIONS SUMMARY

| File | Key Components | Lines |
|------|-----------------|-------|
| `/home/guibibi/projects/yankcord/server/src/media/mod.rs` | MediaService, worker/router lifecycle | 177 |
| `/home/guibibi/projects/yankcord/server/src/media/router.rs` | OpusConfig, codec definitions | 91 |
| `/home/guibibi/projects/yankcord/server/src/media/transport.rs` | WebRTC transport, producer/consumer lifecycle | 656 |
| `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs` | Native video codec support, screen sharing | 215 |
| `/home/guibibi/projects/yankcord/server/src/media/producer.rs` | Producer stubs | 4 |
| `/home/guibibi/projects/yankcord/server/src/media/consumer.rs` | Consumer stubs | 4 |
| `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs` | Media signaling protocol handler | 1064 |
| `/home/guibibi/projects/yankcord/server/src/ws/voice.rs` | Voice broadcast functions | 118 |
| `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` | Voice join/leave, main WS handler | 1416 |
| `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` | State cleanup, connection management | 400 |
| `/home/guibibi/projects/yankcord/server/src/ws/messages.rs` | WebSocket message types | 257 |

---

### 15. ARCHITECTURE DIAGRAM

```
Client
  ↓ WebSocket Connection
┌─────────────────────────────────┐
│   WebSocket Handler             │
│   - Authentication              │
│   - Connection Management       │
│   - Message Dispatching         │
└─────────────────────────────────┘
  ↓
┌─────────────────────────────────────────────┐
│   Media Signaling Handler                   │
│   - Route RTP Capabilities                  │
│   - Create WebRTC Transport                 │
│   - Create Producer/Consumer                │
│   - Rate Limiting (80 events/5s)            │
└─────────────────────────────────────────────┘
  ↓
┌──────────────────────────────────────────────────┐
│   MediaService (SFU)                             │
├──────────────────────────────────────────────────┤
│  Workers (Vec<Worker>)                           │
│    ↓                                             │
│  Routers (HashMap<Uuid, Router>)                 │
│    ├─ per-channel caching                        │
│    ├─ codec config (opus, VP8, H264, etc)        │
│    └─ RTP capability negotiation                 │
│                                                  │
│  ConnectionMediaState (HashMap<Uuid, State>)    │
│    ├─ WebRTC Transports (send/recv)              │
│    ├─ PlainTransports (native RTP)               │
│    ├─ Producers (audio/video/screen)             │
│    └─ Consumers (receive streams)                │
└──────────────────────────────────────────────────┘
  ↓
┌──────────────────────────────────┐
│   In-Memory State                │
├──────────────────────────────────┤
│  voice_members_by_connection     │
│    (who's in which channel)      │
│                                  │
│  voice_members_by_channel        │
│    (channel membership list)     │
│                                  │
│  media_signal_rate_by_connection │
│    (rate limiting state)         │
└──────────────────────────────────┘
  ↓
┌──────────────────────────────────┐
│   Database                       │
├──────────────────────────────────┤
│  channels:                       │
│    - id, name, kind='voice'      │
│    - opus_bitrate, opus_dtx,fec  │
└──────────────────────────────────┘
```

---

### 16. RECOMMENDATIONS & IMPROVEMENTS

**Priority 1 (Critical):**
1. Add database persistence for voice channel membership
2. Invalidate router cache when channel codec settings change
3. Fix consumer auto-cleanup when producer closes
4. Add channel permission checks for voice access

**Priority 2 (High):**
5. Implement worker health monitoring
6. Batch producer notifications on recv transport creation
7. Add bitrate enforcement/limits per consumer
8. Fix producer owner lookup failure handling
9. Add TOCTOU guard for camera/screen limit checks

**Priority 3 (Medium):**
10. Implement consumer lifecycle management
11. Add voice history/analytics database table
12. Implement voice activity recording
13. Add per-user voice settings model
14. Implement voice mute/deafen persistence

**Priority 4 (Nice to Have):**
15. Add multiple transport error recovery
16. Implement auto-reconnection guidance
17. Add voice quality metrics collection
18. Implement adaptive bitrate adjustment
19. Support REMB/TWCC congestion control feedback

---

### CONCLUSION

The Yankcord voice system is a **well-architected SFU implementation** using mediasoup. It handles WebRTC connections, producer/consumer management, and signaling correctly. However, it has **several critical issues** around codec setting persistence, consumer lifecycle management, and state recovery that should be addressed before production use. The architecture is sound but needs hardening for robustness and reliability.</result>
<usage><total_tokens>80577</total_tokens><tool_uses>33</tool_uses><duration_ms>124352</duration_ms></usage>
</task-notification>
Full transcript available at: REDACTED.output

---

<task-notification>
<task-id>a4a521c</task-id>
<tool-use-id>REDACTED</tool-use-id>
<status>completed</status>
<summary>Agent "Explore voice chat client code" completed</summary>
<result>Perfect! Now I have a comprehensive view of the voice/audio/WebRTC system. Let me compile my findings:

## Comprehensive Exploration of Voice Chat/WebRTC/Mediasoup Client Implementation

Based on my thorough exploration of the client-side voice chat implementation in `/home/guibibi/projects/yankcord/client`, here's a detailed analysis:

---

## **1. ARCHITECTURE OVERVIEW**

The voice chat system uses **mediasoup-client** as the WebRTC library with an **SFU (Selective Forwarding Unit)** routing mode. It's a comprehensive implementation with client-side state management, audio/video processing, and native screen capture support via Tauri.

---

## **2. KEY COMPONENTS & FILES**

### **2.1 State Management & Store** 

**File: `/home/guibibi/projects/yankcord/client/src/stores/voice.ts` (413 lines)**

**Purpose:** Solid.js signal-based reactive state store for all voice-related state

**Key Signals:**
- `joinedVoiceChannelId` - Currently joined voice channel
- `participantsByChannel` - Track which users are in each channel
- `speakingByChannel` - Track speaking status per channel/user
- `voiceActionState` - "idle", "joining", "leaving" state machine
- `micMuted`, `speakerMuted` - Mute states
- `cameraEnabled`, `screenShareEnabled` - Media activation states
- `transportHealth` - Connection health state
- `videoTiles` - Array of remote video streams

**Key Functions:**
- `applyVoiceSnapshot()` - Initialize voice presence
- `applyVoiceJoined/Left/Speaking()` - Update participant state
- `startVideoTilesSubscription()` / `startConnectionStatusSubscription()` - Subscribe to media state
- `resetVoiceState()` - Clean slate when disconnecting
- Health monitoring via `voiceHealthLevel()` that aggregates WebSocket and transport health

**Issues Identified:**
- No automatic cleanup on component unmount for subscriptions in some cases
- Multiple unsubscribe refs that could leak if not properly managed

---

### **2.2 Media State Management**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/state.ts` (144 lines)**

**Purpose:** Module-level state (not reactive) for mediasoup infrastructure

**State Categories:**

1. **Device & Transport**
   - `device: Device | null` - mediasoup Device instance
   - `sendTransport, recvTransport: Transport | null` - WebRTC transports

2. **Producer State**
   - `micProducer, micStream, micTrack` - Microphone
   - `cameraProducer, cameraStream, cameraTrack` - Camera
   - `screenProducer, screenStream, screenTrack` - Screen share
   - `nativeScreenProducerId` - Tauri-native screen capture ID

3. **Consumer State**
   - `remoteConsumers: Map<string, Consumer>` - Audio/video consumers
   - `consumerIdByProducerId: Map<string, string>` - Lookup table

4. **Audio Processing**
   - `micLevelAudioContext, micLevelAnalyserNode, micLevelData` - For voice activity detection
   - `remotePlaybackAudioContext` - Shared context for remote audio

5. **Volume Control**
   - `consumerGainNodes, consumerNormalizationNodes` - Per-user volume/compression
   - `remoteAudioElements: Map<string, HTMLAudioElement>` - Audio playback elements

6. **Metadata**
   - `producerUsernameById, producerSourceById, producerRoutingModeById` - Track producer metadata
   - `queuedProducerAnnouncements` - Queue producers until initialized

7. **Health Monitoring**
   - `transportHealthState` - ICE connection state
   - `signalListenerInitialized` - Track media signal setup

---

### **2.3 Transport Initialization & Lifecycle**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts` (376 lines)**

**Purpose:** WebRTC transport setup, connection monitoring, and cleanup

**Key Functions:**

1. **`initializeMediaTransports(channelId: string)`** (Line 246-341)
   - Idempotent initialization with promise-based deduplication
   - Requests RTP capabilities from server
   - Creates mediasoup Device and Send/Recv transports
   - Wires up event handlers (connect, produce, ICE monitoring)
   - Starts local audio producer immediately
   - Flushes queued producer announcements
   - **Pattern: Robust re-entrant guard against multiple concurrent initializations**

2. **`closeTransports()`** (Line 163-244)
   - Comprehensive cleanup of all resources
   - Stops all producers (mic, camera, screen) and their tracks
   - Closes all consumers
   - Cleans up device change listener
   - Stops voice activity monitoring
   - Disposes microphone processing pipeline
   - **Pattern: Defensive cleanup - removes resources even if already null**

3. **Transport Health Monitoring** (Line 76-83, 101-132)
   - `updateTransportHealthFromIce()` - Aggregates send/recv transport states
   - Disconnect recovery with 10-second timeout (Line 119-123)
   - Notifies all subscribers on state change
   - States: "connected", "new", "closed", "disconnected", "failed"
   - Severity mapping for worst-state calculation

4. **Event Handlers**
   - `wireTransportConnect()` - DTLS parameter exchange
   - `wireSendTransportProduce()` - Producer creation signaling
   - `wireTransportConnectionStateMonitor()` - ICE monitoring with auto-recovery

5. **Mute Functions**
   - `setMicrophoneMuted(muted)` - Disables track + reports voice activity
   - `setSpeakersMuted(muted)` - Mutes all remote audio elements

**Issues Identified:**
- No retry logic if initial transport creation fails
- Single global `disconnectRecoveryTimer` could theoretically be overwritten
- Transport state machine could have edge cases with rapid join/leave
- Audio context resumption error handling is silent (no logs)

---

### **2.4 Producer Management (Sending Audio/Video)**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts` (737 lines)**

**Purpose:** Manage outgoing audio, camera, and screen share streams

**Key Producers:**

1. **Microphone Producer** - `startLocalAudioProducer()` (Line 143-223)
   - Gets user media with constraints (noise suppression, echo cancellation)
   - Creates processed microphone track via `createProcessedMicrophoneTrack()`
   - Wraps track in mediasoup Producer
   - Starts voice activity monitoring
   - Handles channel switch during startup
   - **Pattern: Careful track ownership - uses `stopTracks: false` to manage lifecycle separately**

2. **Camera Producer** - `startLocalCameraProducer()` (Line 237-315)
   - Gets video constraints via `cameraInputConstraint()`
   - Fallback logic for device availability
   - H.264 codec preference
   - Produces with `stopTracks: false`
   - Error normalization for user display

3. **Screen Share - Two Modes:**
   - **Browser Mode** - `startBrowserScreenProducer()` (Line 380-490)
     - Uses `getDisplayMedia()` API
     - Optional constraint application (resolution, FPS)
     - Content hint for encoder optimization (motion vs detail)
     - Codec preference for platform
     - Bitrate configuration with encoder hints
   
   - **Native Tauri Mode** - `startNativeScreenProducer()` (Line 492-643)
     - Only on Tauri runtime with sourceId selected
     - Uses RTP sender backend (not WebRTC producer)
     - H.264 codec only (for compatibility)
     - Extensive codec negotiation & validation
     - Fallback monitor (polling every 1s for encoder failures)
     - Diagnostics reporting to server
     - **Pattern: Graceful fallback with heartbeat monitoring**

4. **Track Lifecycle**
   - Cleanup functions: `stopAndReleaseCameraTracks()`, `stopAndReleaseScreenTracks()`
   - Producer close events trigger automatic cleanup
   - Track ended events trigger producer closure
   - Channel switch guards to prevent orphaned producers

5. **Microphone Processing Pipeline**
   - Volume gain node (for outgoing volume control)
   - Creates processed track from source
   - Mute state applied to both source and processed tracks

**Issues Identified:**
- No timeout for producer creation (could hang if network fails)
- Screen share codec selection logs to console in debug mode - could be verbose
- Native capture fallback flag is per-session; user can't retry browser mode once native attempted
- Multiple try-catch blocks could benefit from unified error logging
- Producer stats logging `logScreenShareProducerStats()` only logs on screen share start, not continuous

---

### **2.5 Consumer Management (Receiving Audio/Video)**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts` (382 lines)**

**Purpose:** Create and manage consuming remote audio/video streams

**Key Functions:**

1. **`consumeRemoteProducer(channelId, producerId)`** (Line 166-295)
   - Requests consumer from server
   - Creates consumer via `recvTransport.consume()`
   - **Audio Path:**
     - Creates HTMLAudioElement
     - Sets up audio processing chain: SourceNode → NormalizationCompressor → GainNode → Destination
     - Applies per-user volume + global incoming volume
     - Resumes consumer before playback
     - Retry logic for `audio.play()` (500ms delay + second attempt)
   - **Video Path:**
     - Creates RemoteVideoTile entry
     - Resumes consumer
     - Queues for tile updates
   - Event handlers for transport close and track ended

2. **Audio Chain Architecture** (Line 225-244)
   ```
   SourceNode (raw consumer track)
   → NormalizationNode (DynamicsCompressor)
   → GainNode (per-user volume)
   → Destination (playback)
   ```
   - Normalization threshold: -24dB, knee: 20dB, ratio: 3, attack: 3ms, release: 250ms
   - Provides consistent volume across speakers
   - Disabled when `voiceAutoLevelEnabled` is false

3. **Volume Management**
   - `updateUserGainNodes()` - Updates specific user's volume
   - `updateIncomingVoiceGainNodes()` - Updates global incoming volume
   - `updateVoiceNormalizationNodesEnabled()` - Toggle auto-leveling
   - Per-user volume from settings store

4. **Producer Queuing** - `queueOrConsumeProducer()` (Line 321-353)
   - If not initialized yet, queues producer announcement
   - On initialization complete, `flushQueuedProducerAnnouncements()` processes queue

5. **Cleanup** - `disposeRemoteConsumer(consumerId)` (Line 120-164)
   - Closes consumer
   - Disconnects all audio nodes
   - Removes audio element from DOM
   - Cleans up metadata maps
   - Possibly closes shared audio context if last consumer

**Issues Identified:**
- Audio play() retry uses hardcoded 500ms delay - no exponential backoff
- No per-consumer timeout for requestMediaSignal - could hang indefinitely
- Consumer track ended detection doesn't distinguish between normal end and network failure
- NormalizationNode configuration recreated per consumer instead of module-level constant
- No logging for consumer creation failures - silent error handling
- Gain node value clamping (0-200%) happens in multiple places - duplication

---

### **2.6 Voice Activity Detection & Speaking Status**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts` (111 lines)**

**Purpose:** Monitor microphone level and report speaking status

**Key Metrics:**
- FFT size: 512
- Smoothing time constant: 0.85
- RMS threshold: 0.04 (4%)
- Speaking hold duration: 220ms (hold-over to avoid jitter)

**Algorithm:**
1. Analyser node performs FFT on incoming audio
2. Calculates RMS (root mean square) of audio samples
3. If RMS >= threshold AND not muted → set hold-until time
4. Current time <= hold-until → report speaking=true
5. Muting immediately reports speaking=false

**Functions:**
- `startMicLevelMonitoring()` - Creates audio context and starts RAF-based monitor loop
- `stopMicLevelMonitoring()` - Cleanup and final speaking=false report

**Issues Identified:**
- Uses `requestAnimationFrame` for 60fps monitoring - unnecessary overhead
- Should use fixed interval (e.g., 50ms) instead
- `micSpeakingLastSent` is a boolean flag, not a full state - can't distinguish between not-yet-sent and sent-false
- No jitter buffer - could spam speaking state changes

---

### **2.7 Microphone Processing Pipeline**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts` (104 lines)**

**Purpose:** Apply outgoing volume control to microphone track

**Architecture:**
```
UserMedia Stream
  → SourceNode
    → GainNode (volume)
      → DestinationNode (processed track)
```

**Lifecycle:**
- Single active session at a time
- `createProcessedMicrophoneTrack()` - Creates new session with gain node
- `activateMicrophoneProcessing()` - Sets session as active (disposes previous)
- `updateOutgoingMicrophoneGain()` - Changes gain value in active session
- `updateOutgoingMicrophoneMuted()` - Sets track.enabled on both source and processed

**Issues Identified:**
- Keeps original sourceTrack around - consumes extra resources
- No cleanup callback - if active session set but never disposed, resources leak
- Gain clamping function duplicated from consumers.ts
- No validation that sourceTrack is still valid before using it

---

### **2.8 Media Signaling (WebSocket Integration)**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts` (178 lines)**

**Purpose:** Request-response protocol for media operations (RTC negotiation, producer/consumer management)

**Signal Actions:**
- `get_router_rtp_capabilities` - Get server's codec capabilities
- `create_webrtc_transport` - Create send/recv transport
- `connect_webrtc_transport` - Exchange DTLS parameters
- `media_produce` - Create producer
- `media_close_producer` - Close producer
- `media_consume` - Create consumer
- `media_resume_consumer` - Resume consumer playback
- `create_native_sender_session` - RTP sender setup (native capture)
- `client_diagnostic` - Report native sender metrics

**Request-Response Pattern:**
- Each request gets unique ID: `media-${Date.now()}-${counter}`
- 10-second timeout (Line 113-116)
- Response matched to request by ID
- Pending requests tracked in Map
- Server can send unsolicited messages (new_producer, producer_closed, voice_activity)

**Voice Activity Reporting:**
- `reportVoiceActivity()` - Send speaking=true/false to server
- Triggered by voice level monitoring

**Diagnostics:**
- `reportCodecDecision()` - Log codec selection decision
- `reportNativeSenderDiagnostic()` - Report native sender status/errors

**Issues Identified:**
- Fixed 10-second timeout for all operations - some might need longer (network dependent)
- No retry logic - first timeout = failure
- PendingRequests could accumulate if responses never arrive (timeout cleanup exists, but requests are still lost)
- No congestion detection - if many requests fail, no backpressure

---

### **2.9 Subscription System**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts` (122 lines)**

**Purpose:** Publisher-subscriber pattern for media state changes

**Subscribers:**
1. `videoTilesSubscribers` - Remote camera/screen tiles
2. `cameraStateSubscribers` - Local camera enabled/error/stream
3. `screenStateSubscribers` - Local screen share enabled/error/stream/routingMode
4. `transportHealthSubscribers` - Connection health state

**Pattern:**
- Each subscription function calls subscriber immediately with current state
- Returns unsubscribe function
- Used by `voice.ts` store to maintain reactive state

**Issues Identified:**
- No limits on subscriber count - potential memory leak if many subscriptions created
- No deduplication - could call subscriber twice if subscribed twice
- Subscribers called synchronously - blocking if callback is slow

---

### **2.10 Device Management**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts** (150+ lines)**

**Purpose:** Enumerate and switch audio/video devices at runtime

**Device Enumeration:**
- `listAudioDevices()` - List microphones & speakers
- `listCameraDevices()` - List cameras
- Labels sorted alphabetically with fallback numbering

**Device Selection:**
- `setPreferredMicrophoneDevice()` - Hot-swap microphone
  - Gets new user media
  - Creates new processing session
  - Replaces producer track if exists, or creates new producer
  - Manages fallback if device unavailable
  
- `setPreferredCameraDevice()` - Hot-swap camera (partial implementation visible)
- `setPreferredSpeakerDevice()` - Route speaker output
  - Uses `HTMLAudioElement.setSinkId()` if supported
  - Applied to all remote audio elements

**Device Change Detection:**
- `registerDeviceChangeListener()` - Fires when devices added/removed
- Resets audio devices if current device disappears
- Prevents duplicate registrations

**Issues Identified:**
- Device change listener doesn't distinguish between input/output changes
- Hot-swap has no fallback if getRtpCapabilities changes (rare but possible)
- Speaker routing set per-element, not globally - new consumers must be manually routed
- Sorting is expensive on every enumeration - could cache

---

### **2.11 Constraints & Codec Management**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts` (97 lines)**

**Audio Constraints:**
```typescript
{
  deviceId: { exact: selectedDeviceId },
  noiseSuppression: voiceNoiseSuppressionEnabled(),
  echoCancellation: voiceEchoCancellationEnabled(),
  channelCount: 1  // Mono
}
```
- Uses browser supported constraints API
- Graceful degradation if constraints unavailable

**Video Constraints (Camera):**
- Simple exact device ID constraint

**Screen Share Constraints:**
- Resolution: 720p (1280×720), 1080p (1920×1080), 1440p (2560×1440), 4k (3840×2160)
- FPS: 30 or 60
- displaySurface hint: "monitor" or "window"
- contentHint: "motion" (>=60fps or app) or "detail"

**Codec Selection:**
- Screen share: H.264 > VP8 > VP9 (platform-independent, NVENC hardware support)
- Native: H.264 only

**Issues Identified:**
- No support for audio bandwidth constraints
- Screen share 4K resolution could be very expensive
- No validation that requested FPS/resolution is supported before attempting

---

### **2.12 Error Handling**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts` (72 lines)**

**Error Normalization:**

1. **Camera Errors:**
   - Permission denied → "Camera access was denied..."
   - Not found → "No camera device was found..."
   - Not readable/in use → "Camera is unavailable or in use..."
   - Generic → Pass through error message

2. **Screen Share Errors:**
   - Permission denied → "Screen share permission was denied..."
   - Not found → "No shareable display source was found..."
   - Not readable → "Screen sharing is unavailable or already in use..."
   - Generic → Pass through error message

3. **Device Detection:**
   - `isMissingDeviceError()` - Check if error is device-not-found

**Issues Identified:**
- Error messages are user-friendly but not actionable
- No error codes - difficult to log/debug
- Generic DOMException handling is catch-all at end

---

### **2.13 Native Screen Capture (Tauri)**

**File: `/home/guibibi/projects/yankcord/client/src/api/media/native.ts` (88 lines)**

**Purpose:** Wrap Tauri native screen capture APIs

**Functions:**
- `listNativeCaptureSources()` - Enumerate windows/screens/apps
- `nativeCodecCapabilities()` - Check available codecs
- `startNativeCapture()` - Arm native capture service
- `stopNativeCapture()` - Disarm service
- `nativeCaptureStatus()` - Poll for live metrics

**Fallback Monitor:**
- Polling every 1s for encoder failures
- Fallback reasons: "degradation", "encoder_failure", etc.
- Auto-stops if fallback reason appears
- Reports diagnostic event to server

**Backend Selection:**
- Reads encoder_backend (NVENC, OpenH264)
- Tries requested backend, falls back to other
- Extensive diagnostics in `NativeCaptureStatus`

**Issues Identified:**
- Hardcoded 1s poll interval - could miss rapid failures
- Codec mime type validation string-matching (should use enum)
- No timeout if native capture hangs

---

## **3. UI COMPONENTS**

### **3.1 Voice Dock Component**

**File: `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx` (131 lines)**

**Purpose:** Main control panel for voice channel operations

**Controls:**
- Disconnect button
- Mic mute toggle
- Speaker mute toggle  
- Camera enable/disable
- Screen share enable/disable

**Status Display:**
- Connected channel name
- Connection health (good/degraded/failed)
- Health dot indicator + label
- Camera/screen share error messages
- Routing mode (SFU)

**Native Debug Panel** (Tauri only, debug mode):
- Frame queue stats
- Encoder output rate
- RTP packet counts
- Queue backlog & drop counts
- Encode latency
- Codec info
- Transport/producer health
- Pressure metrics
- Encoder backend info

**Issues Identified:**
- No tooltip for health states
- Debug panel is text-heavy and cramped
- Retry connection button shown but doesn't explain what will reconnect

---

### **3.2 Video Stage Component**

**File: `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx` (78 lines)**

**Purpose:** Display grid of video tiles (camera + screen share)

**Layout:**
- Local camera (if enabled) in grid
- Local screen share (if enabled) in grid
- Remote camera tiles (from videoTiles subscription)

**Features:**
- Auto-play video elements
- Muted local streams
- Username + source labels
- CSS classes for styling (is-local, is-screen-share)

**Issues Identified:**
- No pagination/max tile limit (could become unwieldy with many participants)
- No speaker highlight indicator
- Order is arbitrary for remote tiles (relies on alphabetical sort in subscriptions.ts)
- No click-to-focus or fullscreen

---

### **3.3 Voice Settings Component**

**File: `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx` (110 lines)**

**Purpose:** User-facing voice settings

**Toggles:**
- Noise suppression
- Echo cancellation
- Auto level incoming voices

**Sliders:**
- Incoming voice volume (0-200%)
- Outgoing microphone volume (0-200%)

**Issues Identified:**
- No input validation (could receive invalid percentages)
- Help text is generic, no device-specific guidance
- Volume slider goes to 200% - could cause distortion

---

## **4. INTEGRATION WITH MAIN APPLICATION**

### **4.1 ChannelList Component (Voice Integration)**

**File: `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (1200+ lines)**

**Key Voice Operations:**

1. **Join Voice** - `joinVoiceChannel()`
   - Sets state to "joining"
   - Sends WebSocket message

2. **Leave Voice** - `leaveVoiceChannel()`
   - Sets state to "leaving"
   - Sends WebSocket message

3. **Toggle Mic** - `handleToggleMicMuted()`
   - Updates mute state
   - Calls `setMicrophoneMuted()`

4. **Toggle Camera** - `handleToggleCamera()`
   - Idempotent with pending state
   - Calls `startLocalCameraProducer()` or `stopLocalCameraProducer()`
   - Shows error toast on failure

5. **Toggle Screen Share** - `handleToggleScreenShare()`
   - Browser mode: Immediate `startLocalScreenProducer()`
   - Tauri mode: Opens modal to select source, then starts
   - Calls `stopLocalScreenProducer()` if already sharing

6. **Voice Presence Events**
   - `voice_joined` → Initialize transports, restore settings
   - `voice_left` → Cleanup, reset state
   - `voice_user_joined` → Play join cue, update participants
   - `voice_user_left` → Play leave cue, update participants
   - `voice_user_speaking` → Update speaking indicator
   - `voice_presence_snapshot` → Initialize on startup

7. **Error Handling**
   - Error type message → Set action state to idle
   - Network close → Show rejoin notice + cleanup

8. **Cleanup on Unmount**
   - Stop subscriptions
   - Remove event listeners
   - Clear timers
   - Stop screen share preview

**Issues Identified:**
- Error message shown in toast but error details lost
- No user confirmation for destructive actions (e.g., leaving voice)
- Native metrics polling (1s interval) runs constantly when screen sharing - could drain battery

---

## **5. STATE FLOW DIAGRAM**

```
WebSocket Message (voice_joined)
  ↓
setJoinedVoiceChannel(id)
  ↓
initializeMediaTransports(id)
  ├─ Request RTP capabilities
  ├─ Load Device with capabilities
  ├─ Create Send/Recv transports
  ├─ Wire transport events
  └─ startLocalAudioProducer()
      ├─ getUserMedia() with constraints
      ├─ createProcessedMicrophoneTrack() (gain node)
      ├─ sendTransport.produce()
      └─ startMicLevelMonitoring()
        └─ RAF loop → Calculate RMS → reportVoiceActivity()
  ├─ registerDeviceChangeListener()
  └─ flushQueuedProducerAnnouncements()
      └─ consumeRemoteProducer() for each queued

On new_producer signal
  ├─ Record username, source, routingMode
  └─ queueOrConsumeProducer() → consumeRemoteProducer()
      ├─ Request consumer from server
      ├─ Create consumer via recvTransport
      ├─ If audio: Set up playback chain
      │   ├─ Create HTMLAudioElement
      │   ├─ SourceNode → NormalizationCompressor → GainNode → Destination
      │   └─ audio.play()
      └─ If video: Create VideoTile + subscribe UI

WebSocket Message (voice_left)
  ↓
cleanupMediaTransports()
  ├─ closeTransports()
  │   ├─ Dispose all producers & tracks
  │   ├─ Close all consumers
  │   ├─ Dispose audio nodes & elements
  │   └─ Close transports & device
  └─ Reset all state signals
```

---

## **6. DETAILED ISSUES & RECOMMENDATIONS**

### **Critical Issues**

1. **No Timeout on Transport Creation**
   - **Location:** `initializeMediaTransports()` line 279
   - **Issue:** If server hangs responding to capabilities request, initialization blocks indefinitely
   - **Fix:** Add 5-second timeout to `requestMediaSignal()` calls in transport init

2. **Silent Audio Play Failure Retry**
   - **Location:** `consumers.ts` line 247-265
   - **Issue:** If `audio.play()` fails twice, error is logged but not propagated
   - **Impact:** User hears silence but no error toast
   - **Fix:** Throw error after second failure, let caller handle

3. **Microphone Processing Resource Leak**
   - **Location:** `microphoneProcessing.ts`
   - **Issue:** If `activateMicrophoneProcessing()` is called without prior cleanup, old session orphaned
   - **Fix:** Explicit dispose call or use WeakMap for auto-cleanup

4. **Voice Activity Detection Too Sensitive**
   - **Location:** `voiceActivity.ts` line 77-78
   - **Issue:** 220ms hold-over can miss natural speech pauses
   - **Recommendation:** Use 300-400ms, or make configurable

### **High Priority Issues**

5. **Screen Share Fallback Stuck**
   - **Location:** `producers.ts` line 680-685
   - **Issue:** Once `nativeCaptureAttempted` set true, user can't retry browser mode
   - **Fix:** Add UI button to reset flag, or prompt user

6. **Transport Health Monitoring Race Condition**
   - **Location:** `transports.ts` line 106-112
   - **Issue:** Multiple transports closing in parallel could set state to wrong value
   - **Fix:** Use sequence number or lock to ensure ordering

7. **No Reconnection Logic**
   - **Issue:** If WebSocket reconnects, media transports not re-established
   - **Fix:** Add auto-reconnect on WS reconnect (currently relies on user clicking Retry)

### **Medium Priority Issues**

8. **Volume Clamping Duplicated**
   - **Locations:** `consumers.ts` line 39-44, `microphoneProcessing.ts` line 10-15
   - **Fix:** Export single function from utils module

9. **Consumer Creation Timeout**
   - **Location:** `consumers.ts` line 184
   - **Issue:** No timeout on `requestMediaSignal("media_consume")`
   - **Fix:** Add shorter timeout (3-5s) for per-consumer requests

10. **Device Change Listener Not De-Registered**
    - **Location:** `transports.ts` line 168
    - **Issue:** Listener registered in `initializeMediaTransports`, de-registered on close, but no guard
    - **Fix:** Add state guard to prevent double de-registration

### **Code Quality Issues**

11. **Error Handling Inconsistency**
    - Some code uses `console.warn`, some uses `console.error`, some uses throw
    - **Fix:** Standardize on error boundary propagation

12. **Missing JSDoc Comments**
    - Complex functions like `consumeRemoteProducer` lack documentation
    - **Fix:** Add JSDoc for public APIs

13. **Magic Numbers**
    - 10000ms timeout, 220ms hold, 512 FFT size, 0.04 threshold not documented
    - **Fix:** Extract to named constants with comments

---

## **7. PERFORMANCE CONSIDERATIONS**

1. **Audio Context Lifecycle**
   - Creates multiple AudioContexts (mic level, remote playback, mic processing)
   - Browser limits ~10 contexts max - current design uses 3 when at capacity
   - **Safe but could be optimized:** Reuse single context for monitoring

2. **Voice Activity Detection RAF Loop**
   - Runs at 60fps (browser refresh rate)
   - **Issue:** Overkill for voice activity (could be 20fps)
   - **Fix:** Use 50ms setInterval instead

3. **Storage of All Remote Audio Elements**
   - `remoteAudioElements` map keeps reference to all audio elements
   - **Potential issue:** Never cleaned from DOM, only disconnected
   - **Fix:** Use WeakMap or actively remove elements

4. **Native Sender Metrics Polling**
   - 1-second interval polling from Rust backend
   - **Cost:** Continuous IPC calls
   - **Optimization:** Debounce to 2-3 seconds or on-demand

---

## **8. SECURITY CONSIDERATIONS**

1. **Producer/Consumer Metadata**
   - Username stored client-side in `producerUsernameById` Map
   - **Risk:** Could be spoofed if network message forged
   - **Mitigation:** Server validates all signaling messages

2. **Codec Negotiation**
   - Accepts codec from server without validation
   - **Mitigation:** Limited set of supported codecs in device.rtpCapabilities

3. **SinkId Device Selection**
   - `setSinkId` could fail silently
   - **Risk:** Audio routed to unexpected output
   - **Mitigation:** Device selection is user-initiated

---

## **9. SUMMARY TABLE**

| Component | Purpose | Lines | Key Pattern | Risk Level |
|-----------|---------|-------|-------------|-----------|
| voice.ts | Reactive state store | 413 | Solid.js signals | Low |
| state.ts | Module-level state | 144 | Module exports | Low |
| transports.ts | RTC setup/lifecycle | 376 | Idempotent init + cleanup | Medium |
| producers.ts | Outgoing media | 737 | Track ownership mgmt | High |
| consumers.ts | Incoming media | 382 | Audio processing chain | High |
| voiceActivity.ts | Speaking detection | 111 | RAF-based monitoring | Medium |
| microphoneProcessing.ts | Outgoing volume | 104 | Single active session | Medium |
| signaling.ts | WebSocket protocol | 178 | Request-response | Medium |
| subscriptions.ts | Publisher-subscriber | 122 | Observer pattern | Low |
| devices.ts | Audio/video devices | 150+ | Hot-swap at runtime | High |
| constraints.ts | Media constraints | 97 | Constraint generation | Low |
| errors.ts | Error normalization | 72 | Error mapping | Low |
| native.ts | Tauri integration | 88 | API wrapper | Medium |
| VoiceDock.tsx | Control UI | 131 | Component | Low |
| VideoStage.tsx | Video grid | 78 | Component | Low |
| VoiceAudioPreferences.tsx | Settings UI | 110 | Component | Low |
| ChannelList.tsx | Main integration | 1200+ | Orchestration | High |

---

## **10. FILE PATHS (ABSOLUTE)**

All voice-related files are located at:

- `/home/guibibi/projects/yankcord/client/src/stores/voice.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/index.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/types.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/state.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/codecs.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media/native.ts`
- `/home/guibibi/projects/yankcord/client/src/api/media.ts` (re-export wrapper)
- `/home/guibibi/projects/yankcord/client/src/api/nativeCapture.ts` (Tauri bindings)
- `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx`
- `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx`
- `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx`
- `/home/guibibi/projects/yankcord/client/src/components/channel-list/ScreenShareModal.tsx`
- `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (integration)
- `/home/guibibi/projects/yankcord/client/src/utils/voiceCue.ts`
- `/home/guibibi/projects/yankcord/client/src/utils/audioCue.ts`
- `/home/guibibi/projects/yankcord/client/src/api/ws.ts` (WebSocket definitions)

Native Tauri implementation:
- `/home/guibibi/projects/yankcord/client/src-tauri/src/` (Rust backend for native capture)

This concludes the comprehensive exploration of the voice chat system on the client side.</result>
<usage><total_tokens>95540</total_tokens><tool_uses>41</tool_uses><duration_ms>162087</duration_ms></usage>
</task-notification>
Full transcript available at: REDACTED.output

---

<task-notification>
<task-id>af8b6d8</task-id>
<tool-use-id>toolu_01JiBfoph47qJdUduVVbVC9r</tool-use-id>
<status>completed</status>
<summary>Agent "Explore Tauri voice integration" completed</summary>
<result>Perfect! Now I have all the information I need. Let me compile my comprehensive findings:

## Comprehensive Exploration: Tauri Desktop Client Voice Chat Module

### Executive Summary

The Yankcord application uses **WebRTC via mediasoup-client** for voice communication, with **both web and Tauri clients sharing the same audio/voice logic**. The Tauri desktop client does NOT have separate audio handling - instead, it provides **native screen capture for video streaming** while delegating all voice/audio functionality to browser WebRTC APIs through the Chromium-based Tauri webview.

---

### 1. Tauri Backend (Rust) - /home/guibibi/projects/yankcord/client/src-tauri/

#### Structure:
- **Main entry point**: `/home/guibibi/projects/yankcord/client/src-tauri/src/main.rs` - Minimal Tauri bootstrap
- **Core logic**: `/home/guibibi/projects/yankcord/client/src-tauri/src/lib.rs`

#### Key Files:

**lib.rs**:
```rust
pub fn run() {
    tauri::Builder::default()
        .manage(capture::service::NativeCaptureService::default())
        .plugin(tauri_plugin_opener::init())
        .plugin(tauri_plugin_notification::init())
        .plugin(tauri_plugin_updater::Builder::new().build())
        .invoke_handler(tauri::generate_handler![
            capture::service::list_native_capture_sources,
            capture::service::native_codec_capabilities,
            capture::service::start_native_capture,
            capture::service::stop_native_capture,
            capture::service::native_capture_status
        ])
```

**Tauri Commands Exposed**:
1. `list_native_capture_sources` - Lists available screens/windows/applications to capture
2. `native_codec_capabilities` - Reports available video codecs (H264, VP8, VP9, AV1)
3. `start_native_capture` - Initiates native screen/window capture with specified codec, resolution, FPS, bitrate
4. `stop_native_capture` - Stops active native capture
5. `native_capture_status` - Returns detailed metrics on encoding, RTP transmission, performance

**No Tauri Commands for Audio**: The Rust backend provides **zero audio-related Tauri commands**. All voice/audio functionality is handled entirely through browser WebRTC APIs.

#### Dependencies:
- `tauri = { version = "2", features = [] }`
- `tauri-plugin-opener = "2"` - Open URLs/files
- `tauri-plugin-notification = "2"` - Desktop notifications
- `tauri-plugin-updater = "2"` - App auto-updates
- **No audio libraries** (no cpal, rodio, dasp, etc.)

#### Capabilities:
File: `/home/guibibi/projects/yankcord/client/src-tauri/capabilities/default.json`

```json
{
  "permissions": [
    "core:default",
    "core:window:allow-close",
    "core:window:allow-minimize",
    "core:window:allow-toggle-maximize",
    "core:window:allow-start-dragging",
    "opener:default",
    "notification:default",
    "updater:default"
  ]
}
```

**No WebRTC or audio permissions defined** - Tauri delegates these to the webview's built-in browser permissions system.

---

### 2. Frontend WebRTC Voice Architecture - /home/guibibi/projects/yankcord/client/src/

#### Core Voice Stack:
- **MediaSoup Client** (`mediasoup-client@3.18.6`) - SFU WebRTC protocol
- **Web Audio API** - For microphone monitoring and audio processing
- **getUserMedia API** - For microphone and speaker device enumeration
- **All audio handled through browser webview** - NO native Rust audio handling

#### Voice-Related Files:

**API Modules** (`/client/src/api/media/`):

1. **nativeCapture.ts** - Tauri bridge for screen capture (NOT audio)
   - Defines types: `NativeCaptureSource`, `StartNativeCaptureRequest`, `NativeCaptureStatus`
   - Calls Tauri commands via `invoke()` from `@tauri-apps/api/core`
   - Used for screen sharing only, not voice

2. **voiceActivity.ts** - Microphone level monitoring and speaking detection
   ```typescript
   export function startMicLevelMonitoring(channelId: string, stream: MediaStream) {
     const audioContext = new AudioContext();
     const analyserNode = audioContext.createAnalyser();
     analyserNode.fftSize = 512;
     analyserNode.smoothingTimeConstant = 0.85;
     
     // Monitors RMS level, reports speaking activity via reportVoiceActivity()
   }
   ```
   - Detects voice activity using RMS (root mean square) analysis
   - Reports to server via WebSocket signaling
   - **Platform agnostic** - same code for web and Tauri

3. **microphoneProcessing.ts** - Audio gain/volume control
   ```typescript
   export function createProcessedMicrophoneTrack(
     stream: MediaStream, 
     volume: number, 
     muted: boolean
   ): MicrophoneProcessingSession
   ```
   - Creates AudioContext with GainNode for outgoing volume adjustment
   - Applies muting/unmuting to source and processed tracks
   - **Pure Web Audio API** - zero native code

4. **devices.ts** - Microphone and speaker device management
   ```typescript
   export async function listAudioDevices(): Promise<AudioDeviceInventory> {
     const devices = await navigator.mediaDevices.enumerateDevices();
   }
   
   export async function setPreferredMicrophoneDevice(deviceId: string | null) {
     const nextStream = await navigator.mediaDevices.getUserMedia({
       audio: audioInputConstraint(deviceId)
     });
   }
   ```
   - Uses standard `navigator.mediaDevices` APIs
   - Supports speaker selection via `audio.setSinkId()` when available
   - **Zero Tauri-specific code**

5. **constraints.ts** - MediaTrackConstraints builder
   ```typescript
   export function audioInputConstraint(deviceId: string | null): MediaTrackConstraints | boolean {
     const constraints: MediaTrackConstraints = {};
     const supportedConstraints = navigator.mediaDevices?.getSupportedConstraints?.();
     
     if (supportedConstraints?.noiseSuppression) {
       constraints.noiseSuppression = voiceNoiseSuppressionEnabled();
     }
     if (supportedConstraints?.echoCancellation) {
       constraints.echoCancellation = voiceEchoCancellationEnabled();
     }
   }
   ```
   - Applies noise suppression (via WebRTC's libwebrtc)
   - Applies echo cancellation (via browser's built-in AEC)
   - Channel count: mono (1 channel)

6. **consumers.ts** - Remote audio playback (remote participants)
   - Creates HTML audio elements for each remote participant
   - Routes audio through Web Audio API for per-user volume control
   - Uses DynamicsCompressorNode for "auto level incoming voices" feature
   ```typescript
   function configureNormalizationNode(node: DynamicsCompressorNode, enabled: boolean) {
     if (enabled) {
       node.threshold.value = -24;
       node.knee.value = 20;
       node.ratio.value = 3;
       node.attack.value = 0.003;
       node.release.value = 0.25;
     }
   }
   ```

7. **producers.ts** - Local audio/video producer setup
   - Creates microphone producer via `sendTransport.produce()`
   - Creates camera producer for video
   - Creates screen share producer (uses native Tauri capture on desktop)

8. **signaling.ts** - WebSocket protocol for media negotiation
   - Reports voice activity to server
   - Requests media signal for producer/consumer setup
   - No direct audio signaling

9. **transports.ts** - WebRTC transport (DTLS/ICE) initialization
   - Handles DTLS parameter negotiation
   - Monitors transport health
   - Cleanup on disconnect

10. **codecs.ts** - Codec selection
    ```typescript
    export function selectScreenShareCodecForPlatform(): ProduceCodec | undefined {
      // Prefers H264 > VP8 > VP9
      // Platform-aware but applies to screen share only
    }
    
    export function nativePreferredCodecsFor(): string[] {
      return ["video/H264"]; // For native Tauri screen capture
    }
    ```

#### Voice Settings Storage:
File: `/client/src/stores/settings.ts`

```typescript
const AUDIO_INPUT_KEY = "yankcord_audio_input_device_id";
const AUDIO_OUTPUT_KEY = "yankcord_audio_output_device_id";
const VOICE_AUTO_LEVEL_ENABLED_KEY = "yankcord_voice_auto_level_enabled";
const VOICE_NOISE_SUPPRESSION_ENABLED_KEY = "yankcord_voice_noise_suppression_enabled";
const VOICE_ECHO_CANCELLATION_ENABLED_KEY = "yankcord_voice_echo_cancellation_enabled";
const VOICE_INCOMING_VOLUME_KEY = "yankcord_voice_incoming_volume";
const VOICE_OUTGOING_VOLUME_KEY = "yankcord_voice_outgoing_volume";
```

All settings stored in **localStorage** - same for web and Tauri.

#### Voice State Management:
File: `/client/src/stores/voice.ts` - Tracks:
- `joinedVoiceChannelId` - Current voice channel
- `participantsByChannel` - Who's in each channel
- `speakingByChannel` - Who's currently speaking
- `voiceActionState` - "idle" | "joining" | "leaving"
- `micMuted` - Local mute state
- `speakerMuted` - Remote audio mute
- `cameraEnabled`, `screenShareEnabled` - Video states
- `transportHealth` - WebRTC connection quality
- Video tile subscriptions for remote video streams

#### Voice UI Components:
- `/client/src/components/channel-list/VoiceDock.tsx` - Voice channel participant display
- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings UI
- Noise suppression, echo cancellation, volume controls (both incoming/outgoing)

---

### 3. Key Differences Between Web and Tauri Clients

#### Audio/Voice:
- **Web Client**: Uses browser WebRTC, browser's audio device enumeration
- **Tauri Client**: **Identical** - Same WebRTC via Tauri's Chromium webview, browser audio device enumeration
- **No difference** in how voices are captured, processed, or transmitted

#### Screen Sharing:
- **Web Client**: Uses `navigator.mediaDevices.getDisplayMedia()` (browser picker)
- **Tauri Client**: Uses native Tauri commands for screen/window capture, can pass native source IDs, supports hardware-accelerated H264/NVENC encoding
  - Fallback to browser capture if native fails
  - Native capture is **video-only** (no audio)

#### Platform Detection:
File: `/client/src/utils/platform.ts`

```typescript
export function isTauriRuntime(): boolean {
  return typeof window.__TAURI_INTERNALS__ !== "undefined";
}
```

Used to:
1. Attempt native screen capture first on Tauri
2. Check Windows platform for codec preferences
3. Enable NVENC hardware encoding feature flags

---

### 4. Native Audio Handling - Summary

**There is NO native audio handling in the Tauri client.**

Audio flows:
1. **Outgoing**: 
   - `navigator.mediaDevices.getUserMedia()` → microphone stream
   - WebAudioAPI GainNode for volume adjustment
   - Sent to server via WebRTC (mediasoup)

2. **Incoming**:
   - Received via WebRTC consumer
   - Routed to HTML audio element
   - Optional Web Audio API GainNode for per-user volume control
   - Optional DynamicsCompressorNode for auto-normalization

3. **Processing**:
   - Noise suppression: Browser's WebRTC libwebrtc (constraint-based)
   - Echo cancellation: Browser's WebRTC libwebrtc (constraint-based)
   - Voice activity detection: Custom JavaScript using Web Audio API FFT analysis

---

### 5. Recent Voice Improvements

Recent commit: **4cd8bfa** ("feat: improve voice connectivity")

Changes include:
- Improved transport health monitoring
- Better consumer audio routing
- Enhanced subscription system for media state
- Per-user volume control via DynamicsCompressor normalization
- Auto-level incoming voices feature

**No Tauri-specific changes** - all improvements are browser-level WebRTC optimizations.

---

### 6. Tauri Configuration

File: `/client/src-tauri/tauri.conf.json`

```json
{
  "app": {
    "windows": [{
      "title": "Yankcord",
      "decorations": false,
      "width": 1280,
      "height": 800
    }],
    "security": {
      "csp": "default-src 'self'; connect-src 'self' https: http: wss: ws:; img-src 'self' data: blob: https: http:; style-src 'self' 'unsafe-inline'"
    }
  }
}
```

**CSP allows**:
- WebSocket connections (wss: ws:) - for voice signaling
- HTTPS/HTTP - for API calls
- Blob resources - for media streams

**No WebRTC-specific CSP rules** - Tauri's webview handles this internally.

---

### 7. Files Summary

#### Tauri Rust Code (NO voice/audio):
- `/client/src-tauri/src/main.rs` - Entry point (181 bytes)
- `/client/src-tauri/src/lib.rs` - Tauri app setup, command handlers (764 bytes)
- `/client/src-tauri/src/capture/` - Screen capture backend (video only)
  - No audio dependencies or code

#### Frontend Voice Code (Browser WebRTC):
- `/client/src/api/media/` - 15 files, all platform-agnostic WebRTC/Web Audio
- `/client/src/api/nativeCapture.ts` - Tauri bridge (screen capture only)
- `/client/src/stores/voice.ts` - Voice state management
- `/client/src/stores/settings.ts` - Audio preferences storage
- `/client/src/components/channel-list/VoiceDock.tsx` - Voice UI
- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings panel

#### Configuration:
- `/client/src-tauri/Cargo.toml` - No audio libraries
- `/client/src-tauri/capabilities/default.json` - No WebRTC permissions (delegated to webview)
- `/client/package.json` - Only `@tauri-apps/api` used, not for audio

---

### Conclusion

The Tauri desktop client **reuses 100% of the web client's voice implementation**. There are no separate audio capture, processing, or transmission paths. The Tauri backend provides:

1. **Native screen capture for video** (not audio)
2. **Standard Tauri plugins** (notifications, updates, opener)
3. **No audio-specific functionality**

All voice/audio features use the browser's WebRTC stack through Tauri's Chromium webview:
- Device enumeration via `navigator.mediaDevices`
- Audio processing via Web Audio API
- Transmission via mediasoup-client
- Noise suppression/echo cancellation via browser's libwebrtc constraints

This is a **correct and efficient architecture** - native audio APIs would add complexity without benefit, as WebRTC already provides optimized audio capture and processing.</result>
<usage><total_tokens>68069</total_tokens><tool_uses>44</tool_uses><duration_ms>143681</duration_ms></usage>
</task-notification>
Full transcript available at: REDACTED.output