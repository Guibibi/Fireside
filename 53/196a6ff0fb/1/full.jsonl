{"type":"file-history-snapshot","messageId":"b76c31f5-3bc5-421a-973e-2fef4389f7e0","snapshot":{"messageId":"b76c31f5-3bc5-421a-973e-2fef4389f7e0","trackedFileBackups":{},"timestamp":"2026-02-23T14:43:14.984Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:clear","command":"entire hooks claude-code session-start"},"parentToolUseID":"92e062f7-281a-436b-8666-c5a276552fcd","toolUseID":"92e062f7-281a-436b-8666-c5a276552fcd","timestamp":"2026-02-23T14:43:14.027Z","uuid":"dd5b48ad-b0eb-4a1f-b5d6-c2c85274cf2c"}
{"parentUuid":"dd5b48ad-b0eb-4a1f-b5d6-c2c85274cf2c","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-caveat>Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.</local-command-caveat>"},"isMeta":true,"uuid":"fd4f28ce-7404-4677-a6a3-46e5280a7837","timestamp":"2026-02-23T14:43:14.984Z"}
{"parentUuid":"fd4f28ce-7404-4677-a6a3-46e5280a7837","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<command-name>/clear</command-name>\n            <command-message>clear</command-message>\n            <command-args></command-args>"},"uuid":"b76c31f5-3bc5-421a-973e-2fef4389f7e0","timestamp":"2026-02-23T14:43:13.258Z"}
{"parentUuid":"b76c31f5-3bc5-421a-973e-2fef4389f7e0","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"<local-command-stdout></local-command-stdout>"},"uuid":"3432e1f9-7dbd-4d6d-81d0-348873846a03","timestamp":"2026-02-23T14:43:14.983Z"}
{"type":"file-history-snapshot","messageId":"671984e6-dc68-46ad-a64c-796fab9ff27a","snapshot":{"messageId":"671984e6-dc68-46ad-a64c-796fab9ff27a","trackedFileBackups":{},"timestamp":"2026-02-23T14:46:12.217Z"},"isSnapshotUpdate":false}
{"parentUuid":"3432e1f9-7dbd-4d6d-81d0-348873846a03","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":"I want you to review the whole voice chat module. We have a web based version of the app and a tauri client for it too, and we have the server implementation that also use media soup."},"uuid":"671984e6-dc68-46ad-a64c-796fab9ff27a","timestamp":"2026-02-23T14:46:06.701Z","permissionMode":"default"}
{"parentUuid":"671984e6-dc68-46ad-a64c-796fab9ff27a","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","message":{"model":"claude-opus-4-6","id":"msg_01SJCTq7trGjY34GtLxuUKvX","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants me to review the entire voice chat module across their web client, Tauri client, and server implementation. This is a significant exploration task. Let me start by understanding the project structure and then dive into the voice chat related code.\n\nLet me explore the codebase to find all voice chat related files.","signature":"EvIDCkYICxgCKkDv2hlS4yR5KeZo5GnarIc7BVXy78nx7HXXrktUo+6pdPDWSxcznzW8NwRKP9wtx6zQ01uDs9qfnr/WunAmVntHEgxVZQmcyqSW3R+MKVcaDMs8a4utrBEwe+YSMSIwagdqDEnsW89d+RO3jdhX8xH87Aey/E0y4LTcqklNz454sIc264yFpbKgsbmQfi+QKtkC5zBSxpTLnA07K4XOpfb5IM0o3vW6gB/1Gwq8veBJLC2QSzafSOERymuM94Y318kVu0MCoGGrUoVDN09oyBuAu6iOC9XWaNNd7lh4gUV/TWccaGrTMxs7R84WeSs2tSb52Wql8GAdJOdfC8POf3ACwE8toJrhNd6Q22PZlwJlj7V2RNwOtyP4IQOvz/DJnM/xBgdNonFxzyQ9BeJCJ/2O+76c2ksF/H4Zcjh2yDqSoQL5XW0ywFAXei97HjOoUiUz5JB5tCztUQ5zJE+Es3JqoRBNBufZo9vvft3U8n7Kn0SZMAjnMw/W4xzCJgCRy7Kv0nT7otxt+d7Rxm4EZwDb3B1b+p9XRBip1fcaUs8R9XXp/OjTiDEFbkhq6DeE9o7D2ECs/V7splhHoNOmEgD89dZ8QO81fBLbGOKaou2znFnmVeyERSa4bOx4T2C3ZvrViYy8VC7k6tYxGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1791,"cache_read_input_tokens":18631,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1791},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBWPN3qsD9WYguDEXiJ","type":"assistant","uuid":"7a334702-bc58-443a-9352-16d340e70bdf","timestamp":"2026-02-23T14:46:16.825Z"}
{"parentUuid":"7a334702-bc58-443a-9352-16d340e70bdf","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","message":{"model":"claude-opus-4-6","id":"msg_01SJCTq7trGjY34GtLxuUKvX","type":"message","role":"assistant","content":[{"type":"text","text":"I'll explore the voice chat module across the entire codebase — client, Tauri, and server. Let me kick off parallel searches to map everything out."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1791,"cache_read_input_tokens":18631,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1791},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBWPN3qsD9WYguDEXiJ","type":"assistant","uuid":"679487fa-6af6-4699-97ca-c0d097b39a4c","timestamp":"2026-02-23T14:46:17.452Z"}
{"parentUuid":"679487fa-6af6-4699-97ca-c0d097b39a4c","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","message":{"model":"claude-opus-4-6","id":"msg_01SJCTq7trGjY34GtLxuUKvX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NMwofYAnsc3BjzwUAQCqgR","name":"Task","input":{"description":"Explore voice chat client code","prompt":"Thoroughly explore the voice chat / audio / WebRTC / mediasoup related code in the CLIENT side of this project. The project is at /home/guibibi/projects/yankcord.\n\nLook in client/ directory for:\n1. All voice chat related components, hooks, utilities, services\n2. WebRTC / mediasoup-client integration code\n3. Voice state management (stores, contexts, signals)\n4. UI components for voice channels, voice controls, mute/deafen, etc.\n5. How audio streams are handled (producing, consuming, track management)\n6. Connection lifecycle (join, leave, reconnect logic)\n7. Any Tauri-specific voice integration in client/ or a separate tauri/ directory\n\nSearch broadly using patterns like: voice, audio, webrtc, mediasoup, rtc, transport, producer, consumer, track, mute, deafen, speaking, call, channel.\n\nFor each file found, read it fully and provide:\n- File path and purpose\n- Key functions/components and what they do\n- Any issues, bugs, anti-patterns, or improvements you notice\n- How it connects to other parts of the system\n\nBe very thorough - read every relevant file completely.","subagent_type":"Explore","run_in_background":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1791,"cache_read_input_tokens":18631,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1791},"output_tokens":9,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBWPN3qsD9WYguDEXiJ","type":"assistant","uuid":"039f2ec3-877e-4c82-974f-d64e4882c045","timestamp":"2026-02-23T14:46:24.964Z"}
{"parentUuid":"039f2ec3-877e-4c82-974f-d64e4882c045","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"PreToolUse","hookName":"PreToolUse:Task","command":"entire hooks claude-code pre-task"},"toolUseID":"toolu_01NMwofYAnsc3BjzwUAQCqgR","parentToolUseID":"toolu_01NMwofYAnsc3BjzwUAQCqgR","uuid":"b2423e0d-7eb0-424c-9f5c-f56839e13d70","timestamp":"2026-02-23T14:46:24.966Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-23T14:46:26.654Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","content":"{\"task_id\":\"a4a521c\",\"tool_use_id\":\"REDACTED\",\"description\":\"Explore voice chat client code\",\"task_type\":\"local_agent\"}"}
{"parentUuid":"b2423e0d-7eb0-424c-9f5c-f56839e13d70","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Task","command":"entire hooks claude-code post-task"},"parentToolUseID":"toolu_01NMwofYAnsc3BjzwUAQCqgR","toolUseID":"toolu_01NMwofYAnsc3BjzwUAQCqgR","timestamp":"2026-02-23T14:46:26.660Z","uuid":"d068196f-cf96-4857-8b26-528314765173"}
{"parentUuid":"039f2ec3-877e-4c82-974f-d64e4882c045","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NMwofYAnsc3BjzwUAQCqgR","type":"tool_result","content":[{"type":"text","text":"Async agent launched successfully.\nagentId: a4a521c (internal ID - do not mention to user. Use to resume later if needed.)\nThe agent is working in the background. You will be notified automatically when it completes.\nDo not duplicate this agent's work — avoid working with the same files or topics it is using. Work on non-overlapping tasks, or briefly tell the user what you launched and end your response.\noutput_file: REDACTED.output\nIf asked, you can check progress before completion by using Read or Bash tail on the output file."}]}]},"uuid":"0b64a9c6-367c-4f18-806f-a2f7ab35d5b8","timestamp":"2026-02-23T14:46:26.658Z","toolUseResult":{"isAsync":true,"status":"async_launched","agentId":"a4a521c","description":"Explore voice chat client code","prompt":"Thoroughly explore the voice chat / audio / WebRTC / mediasoup related code in the CLIENT side of this project. The project is at /home/guibibi/projects/yankcord.\n\nLook in client/ directory for:\n1. All voice chat related components, hooks, utilities, services\n2. WebRTC / mediasoup-client integration code\n3. Voice state management (stores, contexts, signals)\n4. UI components for voice channels, voice controls, mute/deafen, etc.\n5. How audio streams are handled (producing, consuming, track management)\n6. Connection lifecycle (join, leave, reconnect logic)\n7. Any Tauri-specific voice integration in client/ or a separate tauri/ directory\n\nSearch broadly using patterns like: voice, audio, webrtc, mediasoup, rtc, transport, producer, consumer, track, mute, deafen, speaking, call, channel.\n\nFor each file found, read it fully and provide:\n- File path and purpose\n- Key functions/components and what they do\n- Any issues, bugs, anti-patterns, or improvements you notice\n- How it connects to other parts of the system\n\nBe very thorough - read every relevant file completely.","outputFile":"REDACTED.output","canReadOutputFile":true},"sourceToolAssistantUUID":"039f2ec3-877e-4c82-974f-d64e4882c045"}
{"parentUuid":"0b64a9c6-367c-4f18-806f-a2f7ab35d5b8","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01WrxD8WDkGaSY7byEkiZryF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NPHycHRM9WQH7WoLj71rUN","name":"Task","input":{"description":"Explore voice chat server code","prompt":"Thoroughly explore the voice chat / audio / WebRTC / mediasoup related code on the SERVER side of this project. The project is at /home/guibibi/projects/yankcord.\n\nLook in server/ directory for:\n1. All voice/audio related route handlers, services, and modules\n2. Mediasoup server-side integration (workers, routers, transports, producers, consumers)\n3. WebSocket/signaling logic for voice connections\n4. Voice channel state management (who's in which channel, speaking state)\n5. SFU (Selective Forwarding Unit) architecture and configuration\n6. Mediasoup worker/router lifecycle management\n7. Transport creation and connection logic\n8. Any voice-related database models or schemas\n\nSearch broadly using patterns like: voice, audio, webrtc, mediasoup, rtc, transport, producer, consumer, router, worker, rtp, codec, mute, deafen, speaking, channel.\n\nFor each file found, read it fully and provide:\n- File path and purpose\n- Key functions/structures and what they do\n- Any issues, bugs, anti-patterns, or improvements you notice\n- How it connects to other parts of the system\n- Configuration concerns (codecs, bitrates, etc.)\n\nBe very thorough - read every relevant file completely.","subagent_type":"Explore","run_in_background":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":667,"cache_read_input_tokens":20422,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":667},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBXVywn2QVwsNRLt9Cm","type":"assistant","uuid":"8f35a552-4162-43ea-bae6-baef78dbd419","timestamp":"2026-02-23T14:46:36.830Z"}
{"parentUuid":"8f35a552-4162-43ea-bae6-baef78dbd419","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"PreToolUse","hookName":"PreToolUse:Task","command":"entire hooks claude-code pre-task"},"toolUseID":"toolu_01NPHycHRM9WQH7WoLj71rUN","parentToolUseID":"toolu_01NPHycHRM9WQH7WoLj71rUN","uuid":"ec5d4cfa-3a20-4f39-bdf3-a5bcb470f9be","timestamp":"2026-02-23T14:46:36.832Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-23T14:46:38.578Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","content":"{\"task_id\":\"a492c1f\",\"tool_use_id\":\"toolu_01NPHycHRM9WQH7WoLj71rUN\",\"description\":\"Explore voice chat server code\",\"task_type\":\"local_agent\"}"}
{"parentUuid":"ec5d4cfa-3a20-4f39-bdf3-a5bcb470f9be","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Task","command":"entire hooks claude-code post-task"},"parentToolUseID":"toolu_01NPHycHRM9WQH7WoLj71rUN","toolUseID":"toolu_01NPHycHRM9WQH7WoLj71rUN","timestamp":"2026-02-23T14:46:38.580Z","uuid":"2427ad37-06a7-444f-8256-baed6d805082"}
{"parentUuid":"8f35a552-4162-43ea-bae6-baef78dbd419","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NPHycHRM9WQH7WoLj71rUN","type":"tool_result","content":[{"type":"text","text":"Async agent launched successfully.\nagentId: a492c1f (internal ID - do not mention to user. Use to resume later if needed.)\nThe agent is working in the background. You will be notified automatically when it completes.\nDo not duplicate this agent's work — avoid working with the same files or topics it is using. Work on non-overlapping tasks, or briefly tell the user what you launched and end your response.\noutput_file: REDACTED.output\nIf asked, you can check progress before completion by using Read or Bash tail on the output file."}]}]},"uuid":"003cd25a-41f9-45f3-9115-259d0c4454c6","timestamp":"2026-02-23T14:46:38.579Z","toolUseResult":{"isAsync":true,"status":"async_launched","agentId":"a492c1f","description":"Explore voice chat server code","prompt":"Thoroughly explore the voice chat / audio / WebRTC / mediasoup related code on the SERVER side of this project. The project is at /home/guibibi/projects/yankcord.\n\nLook in server/ directory for:\n1. All voice/audio related route handlers, services, and modules\n2. Mediasoup server-side integration (workers, routers, transports, producers, consumers)\n3. WebSocket/signaling logic for voice connections\n4. Voice channel state management (who's in which channel, speaking state)\n5. SFU (Selective Forwarding Unit) architecture and configuration\n6. Mediasoup worker/router lifecycle management\n7. Transport creation and connection logic\n8. Any voice-related database models or schemas\n\nSearch broadly using patterns like: voice, audio, webrtc, mediasoup, rtc, transport, producer, consumer, router, worker, rtp, codec, mute, deafen, speaking, channel.\n\nFor each file found, read it fully and provide:\n- File path and purpose\n- Key functions/structures and what they do\n- Any issues, bugs, anti-patterns, or improvements you notice\n- How it connects to other parts of the system\n- Configuration concerns (codecs, bitrates, etc.)\n\nBe very thorough - read every relevant file completely.","outputFile":"REDACTED.output","canReadOutputFile":true},"sourceToolAssistantUUID":"8f35a552-4162-43ea-bae6-baef78dbd419"}
{"parentUuid":"003cd25a-41f9-45f3-9115-259d0c4454c6","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01JyRV6DNbdQJ6JrsXE6ZZth","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Both agents are still running. Let me wait for them to complete before synthesizing the review. I'll also look for any Tauri-specific voice code while waiting.","signature":"EsgCCkYICxgCKkChhVrMtmUkKixZA9t7WJmnrzAASyW54/ryP4SFzU5vZmdQI2ajbOPrhV0n2f1EvzZ/qA58/LApWmQqZ4kR31uJEgzLiaUNR6q4v2i/eJMaDNE6UtUGR9/LfRMW6iIwcrxGvSBFfjefXT31KY7kzn6dUwKHfFPOr35+621KpETdMMekMqcbYOJABwwTfxbWKq8BDz0G8Xl9k+IYy43erWn7CVVv5X/Mftmi4jiYKDTD1I95w0A6v+mtN7yI52V31oO7RTY6eg5Pw1AqOIjPTX8uQI06dIxizs6GDvBjAcsK1mF8+2mS9qPsrqHTQpFapin2oRFRePf0lEhm0hDqiehxe2yIZ9KofPgATqerT6oW0XZdwPliJ4yW053G5V310eXmyQwXIkNWhNQ1yMXO1AQzgD48q7IyzqrexydLdV3bMRgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":755,"cache_read_input_tokens":21089,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":755},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBYP7Unp2w7c7CzRZLy","type":"assistant","uuid":"bfa94533-d611-415a-9c9b-c55ff5ef2e10","timestamp":"2026-02-23T14:46:42.927Z"}
{"parentUuid":"bfa94533-d611-415a-9c9b-c55ff5ef2e10","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01JyRV6DNbdQJ6JrsXE6ZZth","type":"message","role":"assistant","content":[{"type":"text","text":"Both exploration agents are still working through the codebase. Let me also check for any Tauri-specific voice code while they run."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":755,"cache_read_input_tokens":21089,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":755},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBYP7Unp2w7c7CzRZLy","type":"assistant","uuid":"d7b3f61e-d004-4f00-87f2-fea1778fe1f8","timestamp":"2026-02-23T14:46:43.531Z"}
{"parentUuid":"d7b3f61e-d004-4f00-87f2-fea1778fe1f8","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01JyRV6DNbdQJ6JrsXE6ZZth","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JiBfoph47qJdUduVVbVC9r","name":"Task","input":{"description":"Explore Tauri voice integration","prompt":"Explore the Tauri desktop client side of the voice chat module in /home/guibibi/projects/yankcord.\n\nLook for:\n1. Any tauri/ or src-tauri/ directory with Rust backend code related to voice/audio\n2. Tauri commands or plugins for audio device management\n3. Any native audio handling (not via browser WebRTC)\n4. Tauri-specific configuration for WebRTC permissions or audio\n5. Any differences between how the web client and Tauri client handle voice\n\nSearch in all directories for tauri-related voice code. Also check for any shared types or protocols between the Tauri app and the web frontend regarding voice.\n\nRead all relevant files completely and report what you find.","subagent_type":"Explore","run_in_background":true},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":755,"cache_read_input_tokens":21089,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":755},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBYP7Unp2w7c7CzRZLy","type":"assistant","uuid":"25c14fec-f345-4aed-84c3-edcb208acc1d","timestamp":"2026-02-23T14:46:48.397Z"}
{"parentUuid":"25c14fec-f345-4aed-84c3-edcb208acc1d","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"PreToolUse","hookName":"PreToolUse:Task","command":"entire hooks claude-code pre-task"},"toolUseID":"toolu_01JiBfoph47qJdUduVVbVC9r","parentToolUseID":"toolu_01JiBfoph47qJdUduVVbVC9r","uuid":"f98fc7f9-18c2-48d4-b78e-b67cfaea9184","timestamp":"2026-02-23T14:46:48.399Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-23T14:46:50.039Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","content":"{\"task_id\":\"af8b6d8\",\"tool_use_id\":\"toolu_01JiBfoph47qJdUduVVbVC9r\",\"description\":\"Explore Tauri voice integration\",\"task_type\":\"local_agent\"}"}
{"parentUuid":"f98fc7f9-18c2-48d4-b78e-b67cfaea9184","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Task","command":"entire hooks claude-code post-task"},"parentToolUseID":"toolu_01JiBfoph47qJdUduVVbVC9r","toolUseID":"toolu_01JiBfoph47qJdUduVVbVC9r","timestamp":"2026-02-23T14:46:50.041Z","uuid":"b1202342-c304-449c-8634-f5c35329c648"}
{"parentUuid":"25c14fec-f345-4aed-84c3-edcb208acc1d","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JiBfoph47qJdUduVVbVC9r","type":"tool_result","content":[{"type":"text","text":"Async agent launched successfully.\nagentId: af8b6d8 (internal ID - do not mention to user. Use to resume later if needed.)\nThe agent is working in the background. You will be notified automatically when it completes.\nDo not duplicate this agent's work — avoid working with the same files or topics it is using. Work on non-overlapping tasks, or briefly tell the user what you launched and end your response.\noutput_file: REDACTED.output\nIf asked, you can check progress before completion by using Read or Bash tail on the output file."}]}]},"uuid":"336130e2-57ff-4e4b-ad8b-a94b9d22d610","timestamp":"2026-02-23T14:46:50.040Z","toolUseResult":{"isAsync":true,"status":"async_launched","agentId":"af8b6d8","description":"Explore Tauri voice integration","prompt":"Explore the Tauri desktop client side of the voice chat module in /home/guibibi/projects/yankcord.\n\nLook for:\n1. Any tauri/ or src-tauri/ directory with Rust backend code related to voice/audio\n2. Tauri commands or plugins for audio device management\n3. Any native audio handling (not via browser WebRTC)\n4. Tauri-specific configuration for WebRTC permissions or audio\n5. Any differences between how the web client and Tauri client handle voice\n\nSearch in all directories for tauri-related voice code. Also check for any shared types or protocols between the Tauri app and the web frontend regarding voice.\n\nRead all relevant files completely and report what you find.","outputFile":"REDACTED.output","canReadOutputFile":true},"sourceToolAssistantUUID":"25c14fec-f345-4aed-84c3-edcb208acc1d"}
{"parentUuid":"336130e2-57ff-4e4b-ad8b-a94b9d22d610","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_016WX2B9XDccNFNgchJzKVBS","type":"message","role":"assistant","content":[{"type":"text","text":"Three agents are now exploring in parallel:\n1. **Client-side voice code** — components, hooks, mediasoup-client, state management\n2. **Server-side voice code** — Rust mediasoup integration, signaling, SFU architecture\n3. **Tauri-specific voice code** — native audio handling, Tauri commands/plugins\n\nI'll compile a comprehensive review once all three complete. This may take a couple minutes."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":525,"cache_read_input_tokens":21844,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":525},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBZDpf5UTMXtynVzTy7","type":"assistant","uuid":"b0449f57-4801-43b9-a000-ee651054b361","timestamp":"2026-02-23T14:46:55.985Z"}
{"parentUuid":"b0449f57-4801-43b9-a000-ee651054b361","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"00e09097-780d-44e0-a436-486f722ddfd3","toolUseID":"00e09097-780d-44e0-a436-486f722ddfd3","timestamp":"2026-02-23T14:46:56.055Z","uuid":"72eef6e2-d7bf-4f3a-9a61-4550ca501b51"}
{"type":"queue-operation","operation":"remove","timestamp":"2026-02-23T14:47:05.430Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c"}
{"type":"queue-operation","operation":"remove","timestamp":"2026-02-23T14:47:05.430Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c"}
{"type":"queue-operation","operation":"remove","timestamp":"2026-02-23T14:47:05.430Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c"}
{"parentUuid":"72eef6e2-d7bf-4f3a-9a61-4550ca501b51","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1843}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-23T14:46:57.898Z","uuid":"ae364b6a-036c-4608-9816-036ab466ddc8","toolUseID":"00e09097-780d-44e0-a436-486f722ddfd3"}
{"parentUuid":"ae364b6a-036c-4608-9816-036ab466ddc8","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"system","subtype":"turn_duration","durationMs":53158,"timestamp":"2026-02-23T14:47:05.420Z","uuid":"6a5d20f7-cd74-4149-aa09-1cd19ec866aa","isMeta":false}
{"type":"file-history-snapshot","messageId":"e80e1af5-319b-47b1-bd2f-035936002109","snapshot":{"messageId":"e80e1af5-319b-47b1-bd2f-035936002109","trackedFileBackups":{},"timestamp":"2026-02-23T14:48:03.554Z"},"isSnapshotUpdate":false}
{"parentUuid":"6a5d20f7-cd74-4149-aa09-1cd19ec866aa","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":"Create a voice chat report text file with the result"},"uuid":"e80e1af5-319b-47b1-bd2f-035936002109","timestamp":"2026-02-23T14:48:00.650Z","permissionMode":"default"}
{"parentUuid":"e80e1af5-319b-47b1-bd2f-035936002109","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01FKzgSPhZgzbt8zZyMp66wj","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nI'll wait for all three agents to finish, then compile the report. Let me check their status."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":299,"cache_read_input_tokens":22468,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":299},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBeXCZasCwg2jZuL5HQ","type":"assistant","uuid":"97e1811a-23e2-4d5d-8779-b1a879477adf","timestamp":"2026-02-23T14:48:06.362Z"}
{"parentUuid":"97e1811a-23e2-4d5d-8779-b1a879477adf","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01FKzgSPhZgzbt8zZyMp66wj","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011P3vw8PMtG2bzzXUNaFuqr","name":"TaskOutput","input":{"task_id":"a4a521c","block":true,"timeout":120000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":299,"cache_read_input_tokens":22468,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":299},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBeXCZasCwg2jZuL5HQ","type":"assistant","uuid":"5ff0b289-d04f-4517-8905-9a49cb5c306c","timestamp":"2026-02-23T14:48:07.087Z"}
{"parentUuid":"5ff0b289-d04f-4517-8905-9a49cb5c306c","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"waiting_for_task","taskDescription":"Explore voice chat client code","taskType":"local_agent"},"toolUseID":"task-output-waiting-1771858087090","parentToolUseID":"toolu_011P3vw8PMtG2bzzXUNaFuqr","uuid":"98f1b46c-0cbe-4744-8a22-5136f21ffc97","timestamp":"2026-02-23T14:48:07.090Z"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-23T14:48:42.930Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","content":"<task-notification>\n<task-id>a492c1f</task-id>\n<tool-use-id>toolu_01NPHycHRM9WQH7WoLj71rUN</tool-use-id>\n<status>completed</status>\n<summary>Agent \"Explore voice chat server code\" completed</summary>\n<result>Now I have comprehensive information. Let me create a thorough report:\n\n## COMPREHENSIVE SERVER-SIDE VOICE CHAT / WEBRTC / MEDIASOUP ANALYSIS\n\n### EXECUTIVE SUMMARY\n\nThe Yankcord server implements a complete SFU (Selective Forwarding Unit) architecture for voice communication using mediasoup. The system manages WebRTC connections, audio/video producers and consumers, and maintains voice channel state through a combination of database persistence, in-memory state tracking, and real-time WebSocket signaling.\n\n---\n\n### 1. MEDIASOUP ARCHITECTURE & WORKER LIFECYCLE\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/mod.rs`\n\n#### Key Components:\n\n**MediaService Structure:**\n```rust\npub struct MediaService {\n    workers: Vec<Worker>,\n    routers: Arc<Mutex<HashMap<Uuid, Router>>>,\n    connection_media: Arc<Mutex<HashMap<Uuid, transport::ConnectionMediaState>>>,\n    webrtc_listen_ip: IpAddr,\n    announced_ip: Option<String>,\n    native_rtp_listen_ip: IpAddr,\n    native_rtp_announced_ip: Option<IpAddr>,\n}\n```\n\n**Worker Initialization:**\n- Creates N workers based on `MEDIA_WORKER_COUNT` configuration (default: 2)\n- Workers are created synchronously during server startup\n- Each worker is managed by mediasoup's WorkerManager\n- No documented worker lifecycle management (no restart/health-check logic)\n\n**Router Management:**\n- Routers are cached per channel_id in a HashMap\n- Router assignment uses deterministic worker selection: `channel_id.as_bytes()[0] as usize % self.workers.len()`\n- **Critical Issue**: Router caching means codec settings (opus_bitrate, opus_dtx, opus_fec) set at channel creation time are never updated after router creation, even if channel settings change\n- Routers can be manually invalidated via `invalidate_router()` to force recreation\n\n**Network Configuration:**\n- WebRTC transport listen IP and announced IP are configurable\n- Native RTP (for screen sharing) has separate listen/announced IP configuration\n- Fallback to localhost (127.0.0.1) if IP parsing fails with warnings\n\n---\n\n### 2. ROUTER & CODEC CONFIGURATION\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/router.rs`\n\n#### Opus Configuration:\n```rust\npub struct OpusConfig {\n    pub bitrate: Option<u32>,          // Max average bitrate\n    pub dtx: Option<bool>,              // Discontinuous Transmission\n    pub fec: Option<bool>,              // Forward Error Correction\n}\n```\n\n**Supported Codecs:**\n- **Audio**: Opus (48kHz, stereo, 2 channels)\n  - RTCP Feedback: TransportCc\n  - Parameters: maxaveragebitrate, usedtx, useinbandfec\n- **Video**: VP8, H.264, VP9, AV1\n  - RTCP Feedback: Nack, NackPli, CcmFir, GoogRemb, TransportCc\n  - H.264: packetization-mode=1, profile-level-id=42e01f\n\n**Configuration Concerns:**\n1. Opus parameters are applied at router creation only\n2. No runtime codec parameter updates\n3. Video codec negotiation not fully exposed to clients\n4. Database schema stores opus settings but no per-message codec negotiation\n\n**Database Schema (channels table):**\n```sql\nopus_bitrate INTEGER      -- Max bitrate in bps\nopus_dtx     BOOLEAN      -- Enable DTX\nopus_fec     BOOLEAN      -- Enable FEC\n```\n\n---\n\n### 3. TRANSPORT MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs`\n\n#### ConnectionMediaState Structure:\n```rust\npub struct ConnectionMediaState {\n    pub channel_id: Uuid,\n    pub send_transport_id: Option<String>,\n    pub recv_transport_id: Option<String>,\n    pub transports: HashMap<String, WebRtcTransport>,\n    pub native_transports_by_producer: HashMap<String, PlainTransport>,\n    pub producers: HashMap<String, ProducerEntry>,\n    pub consumers: HashMap<String, Consumer>,\n}\n```\n\n**Transport Creation:**\n1. **SendTransport**: Used for uploading audio/video from client\n   - Created per direction on demand\n   - Replaced if same direction requested again\n   - Uses WebRtcTransport with configured listen IPs\n\n2. **RecvTransport**: Used for downloading media from other participants\n   - Created per direction on demand\n   - Sends existing producers to new recv transport creators\n   - Also uses WebRtcTransport\n\n3. **PlainTransport**: Used for native screen sharing\n   - Created on demand for screen producers\n   - Uses raw RTP/UDP\n   - Comedia enabled (automatic endpoint detection)\n   - RTCP multiplexed (rtcp_mux=true)\n\n**Critical Logic Issues:**\n\n1. **Channel Validation on Send Transport Creation (Lines 154-162):**\n   - If connection switches channels, old ConnectionMediaState is cleared\n   - **Issue**: Session switching doesn't properly validate permissions\n\n2. **Duplicate Producer Check (Lines 266-282, 305-321):**\n   - Checked TWICE: once before creating and once after\n   - Race condition possible between checks\n   - Only one camera and one screen producer allowed per connection\n\n3. **Recv Transport Producer Snapshot (Lines 555-600):**\n   - When recv transport created, sends all existing channel producers\n   - **Issue**: Producer owner username lookup may fail silently (line 570-575)\n   - If owner disconnected, producer info not sent to new consumer\n\n**Producer Lifecycle:**\n```\n1. Client creates send transport\n2. Client connects send transport (DTLS handshake)\n3. Client calls MediaProduce with RTP parameters\n4. Server creates producer on send transport\n5. Producer added to state.producers HashMap\n6. Other clients notified via broadcast (\"new_producer\")\n7. Other clients create consumers on their recv transports\n8. Client can close producer via MediaCloseProducer\n```\n\n---\n\n### 4. PRODUCER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 238-340)\n\n#### ProducerSource Enum:\n```rust\npub enum ProducerSource {\n    Microphone,  // Audio only\n    Camera,      // Video only\n    Screen,      // Video only\n}\n```\n\n#### Validation Constraints:\n1. **One camera per connection**: Prevents multiple camera producers simultaneously\n2. **One screen per connection**: Prevents multiple screen shares\n3. **Microphone**: No per-connection limit (multiple microphone sources possible)\n4. **Kind/Source Validation**: Kind must match source (e.g., \"microphone\" requires kind=\"audio\")\n\n#### Producer Creation Flow:\n```\nClient sends: MediaProduce {\n    kind: \"audio\"|\"video\",\n    source: \"microphone\"|\"camera\"|\"screen\",\n    routing_mode: \"sfu\",\n    rtp_parameters: RtpParameters\n}\n\nServer:\n1. Validates routing_mode (only \"sfu\" allowed, no mesh/hybrid)\n2. Validates source matches kind\n3. Verifies send transport exists\n4. Checks camera/screen limits\n5. Creates producer with mediasoup\n6. Stores in state.producers\n7. Broadcasts to all channel members\n```\n\n---\n\n### 5. CONSUMER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 488-568)\n\n#### Consumer Creation Logic:\n```rust\npub async fn create_consumer_for_connection(\n    connection_id: Uuid,\n    channel_id: Uuid,\n    producer_id: &str,\n    rtp_capabilities: RtpCapabilities,\n) -> Result<CreatedConsumer, String>\n```\n\n**Key Properties:**\n- Created in PAUSED state: `consumer_options.paused = true`\n- Client must call `MediaResumeConsumer` to start receiving\n- RTP parameters negotiated based on client capabilities\n\n**Validations:**\n1. Producer must exist in same channel\n2. Client must be in channel\n3. Client RTP capabilities must be able to consume producer\n4. Router validates compatibility: `router.can_consume()`\n\n**Concerns:**\n- No bitrate limits enforced on consumers\n- No adaptive bitrate control\n- Consumers manually managed (no automatic cleanup on producer close)\n- No bandwidth constraints per channel\n\n---\n\n### 6. NATIVE VIDEO CODEC & SCREEN SHARING\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs`\n\n#### Native Video Codec Support:\n```rust\npub enum NativeVideoCodec {\n    H264,   // Ready - PT 96, clock_rate 90kHz\n    Vp8,    // Ready - PT 98, clock_rate 90kHz\n    Vp9,    // Ready - PT 100, clock_rate 90kHz\n    Av1,    // Ready - PT 102, clock_rate 90kHz\n}\n```\n\n#### Native Sender Session (for Screen Sharing):\n```rust\npub struct NativeSenderSession {\n    pub producer_id: String,\n    pub rtp_target: String,           // Address to send RTP to\n    pub payload_type: u8,\n    pub ssrc: u32,                    // Canonical SSRC from connection_id\n    pub mime_type: String,\n    pub clock_rate: u32,\n    pub packetization_mode: u8,       // H.264 only\n    pub profile_level_id: String,     // H.264 only\n    pub codec: NativeCodecDescriptor,\n    pub available_codecs: Vec<NativeCodecDescriptor>,\n}\n```\n\n#### Screen Sharing Flow:\n1. Client requests `CreateNativeSenderSession` with optional preferred codecs\n2. Server creates PlainTransport with comedia=true\n3. Server creates producer on transport\n4. Returns RTP target endpoint and codec parameters\n5. Client sends raw H.264/VP8/VP9/AV1 RTP packets to target\n6. Server forwards through SFU to consumers\n\n**Configuration:**\n- H.264: Packetization mode 1 (single NAL per RTP packet)\n- SSRC deterministically derived from connection_id (first 4 bytes)\n- RTCP cname formatted as `native-{ssrc:x}`\n\n**Issue**: SSRC derivation is deterministic but could theoretically collide for different connection_ids sharing same first 4 bytes. Fallback seed is 0x4E41_5456 if collision detected.\n\n---\n\n### 7. WEBSOCKET SIGNALING LAYER\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs`\n\n#### Media Signal Protocol:\n\n**Request Format:**\n```json\n{\n  \"action\": \"get_router_rtp_capabilities|create_webrtc_transport|...\",\n  \"request_id\": \"optional-string\",\n  \"...\" : \"other params\"\n}\n```\n\n**Supported Actions:**\n1. `GetRouterRtpCapabilities` - Get channel's codec capabilities\n2. `CreateWebrtcTransport` - Create send/recv transport\n3. `ConnectWebrtcTransport` - Complete DTLS handshake\n4. `MediaProduce` - Create producer\n5. `MediaConsume` - Create consumer\n6. `MediaResumeConsumer` - Resume paused consumer\n7. `MediaCloseProducer` - Close producer\n8. `CreateNativeSenderSession` - Setup screen sharing\n9. `ClientDiagnostic` - Log client diagnostics\n\n#### Rate Limiting:\n```rust\nconst MAX_MEDIA_SIGNAL_EVENTS_PER_WINDOW: u32 = 80;\nconst MEDIA_SIGNAL_RATE_WINDOW: Duration = Duration::from_secs(5);\n```\n\n**Limit**: 80 media signal events per 5-second window per connection\n\n#### Validation:\n- request_id max 128 characters\n- Payload size limit: 32 KB\n- Field constraints: direction (16), transport_id (128), kind (16), source (32), routing_mode (16)\n\n#### Error Handling:\n```rust\npub enum MediaSignalSendOutcome {\n    Delivered,\n    Dropped,    // Serialization failed\n    Disconnect, // Queue full or connection closed\n}\n```\n\n**Policy**: Close connection if outbound queue full (prevents slow-consumer problems)\n\n---\n\n### 8. VOICE CHANNEL STATE MANAGEMENT\n\n**Files:**\n- `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 605-631, 1259-1415)\n- `/home/guibibi/projects/yankcord/server/src/ws/voice.rs`\n- `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` (Lines 318-394)\n\n#### In-Memory State Maps:\n```rust\npub struct AppState {\n    // Voice channel membership\n    pub voice_members_by_connection: Arc<RwLock<HashMap<Uuid, Uuid>>>,\n                                     // connection_id -> channel_id\n    pub voice_members_by_channel: Arc<RwLock<HashMap<Uuid, HashSet<String>>>>,\n                                   // channel_id -> usernames\n    // ... other fields\n}\n```\n\n#### Join Flow:\n```\nClient: JoinVoice { channel_id }\n    ↓\nHandler validates:\n    1. Channel exists\n    2. Channel is voice-enabled\n    3. Get channel's opus config\n    ↓\nUpdate state:\n    1. voice_members_by_connection.insert(connection_id, channel_id)\n    2. If switching channels: remove from old channel, cleanup media\n    3. voice_members_by_channel.entry(channel_id).or_default().insert(username)\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserJoined\n    2. Send to client: VoiceJoined { channel_id, user_id }\n```\n\n#### Leave Flow:\n```\nClient: LeaveVoice { channel_id }\n    ↓\nHandler:\n    1. Remove from voice_members_by_connection\n    2. Remove username from voice_members_by_channel\n    3. Cleanup producers via media.cleanup_connection_media()\n    4. Broadcast closed_producers to channel\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserLeft\n    2. Send to client: VoiceLeft { channel_id, user_id }\n```\n\n#### Disconnect Handling:\nWhen WebSocket connection closes:\n1. `cleanup_connection()` called with connection_id\n2. Removes from voice_members_by_connection and voice_members_by_channel\n3. Calls `media.cleanup_connection_media()` to close all producers/consumers\n4. Broadcasts VoiceUserLeft to all channels\n5. Broadcasts closed producer info to affected channels\n\n**Critical State Issue**: \n- No database persistence of voice channel membership\n- Membership purely in-memory\n- Server restart loses all voice session state\n- Clients must rejoin voice channels after server restart\n\n---\n\n### 9. SPEAKING STATUS & VOICE ACTIVITY\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 611-632)\n\n#### Voice Activity Flow:\n```\nClient: VoiceActivity { channel_id, speaking: bool }\n    ↓\nHandler validates:\n    1. Connection is in the specified channel\n    2. (No rate limiting on speaking events)\n    ↓\nBroadcast:\n    broadcast_voice_activity_to_channel(state, channel_id, username, speaking, None)\n    └─> Sends to all OTHER connections in channel:\n        ServerMessage::VoiceUserSpeaking {\n            channel_id,\n            username,\n            speaking\n        }\n```\n\n**Important Notes:**\n- No database recording of speaking status\n- Purely ephemeral, real-time signaling\n- No speaking history or analytics\n- Clients independently detect voice activity (VAD on client side)\n\n---\n\n### 10. PRODUCER/CONSUMER LIFECYCLE & CLEANUP\n\n**Producer Cleanup:**\n```\nWhen Producer Closed:\n    1. Removed from state.producers\n    2. Removed from native_transports_by_producer (if native)\n    3. Broadcast ClosedProducer message to channel:\n        {\n            \"action\": \"producer_closed\",\n            \"producer_id\": \"...\",\n            \"source\": \"...\",\n            \"routing_mode\": \"...\"\n        }\n```\n\n**Consumer Cleanup:**\n- No explicit cleanup endpoint\n- Consumers auto-close when producer closes\n- Manual close not exposed via WebSocket\n\n**Connection Cleanup:**\n```\nWhen Connection Disconnects:\n    1. state.media.cleanup_connection_media(connection_id)\n       └─> Removes all producers/consumers for this connection\n    2. Returns Vec<ClosedProducer>\n    3. Broadcasts closed_producers to all channels\n```\n\n---\n\n### 11. ISSUES, BUGS & ANTI-PATTERNS\n\n#### CRITICAL ISSUES:\n\n1. **Codec Settings Never Update After Router Creation**\n   - If channel opus_bitrate/dtx/fec changed after first user joins, new users don't get updated settings\n   - Router caching doesn't invalidate on channel update\n   - **Impact**: Codec configuration changes require server restart\n   - **Solution**: Invalidate router when channel settings change\n\n2. **Producer Owner Lookup Silently Fails**\n   - When recv transport created, attempts to get producer owner's username\n   - If owner connection already closed, warns but continues\n   - New consumer doesn't receive \"new_producer\" notification for that producer\n   - **Impact**: Consumer state out of sync with actual producers in channel\n   - **Suggested Fix**: Either cache producer owner info or handle gracefully\n\n3. **No Consumer Auto-Cleanup**\n   - Consumers manually managed, no automatic lifecycle\n   - When producer closes, consumers still exist in HashMap\n   - Consumer close not exposed to client\n   - **Impact**: Memory leak of stale consumers\n   - **Suggested Fix**: Auto-close consumers when producer closes\n\n4. **Duplicate Camera/Screen Check - TOCTOU**\n   - Checked before creation AND after creation\n   - Race condition: two concurrent produce requests could both pass first check\n   - **Impact**: Theoretically could create 2 cameras per connection\n   - **Suggested Fix**: Single atomic check or lock\n\n5. **No Database Persistence of Voice Membership**\n   - Voice state purely in-memory\n   - Server restart loses all state\n   - Clients don't know if they need to rejoin\n   - **Impact**: Broken user experience on server restart\n   - **Suggested Fix**: Persist voice channel membership in database\n\n#### MEDIUM ISSUES:\n\n6. **Slow Consumer Producer Notifications**\n   - When recv transport created, for each producer, sends individual notification\n   - N producers = N separate JSON broadcasts\n   - No batching/bundling of producers list\n   - **Impact**: Inefficient network usage with many producers\n   - **Suggested Fix**: Send producer list in single JSON array\n\n7. **No Bandwidth/Bitrate Enforcement**\n   - Consumers created without bitrate limits\n   - No max-bitrate set on encodings\n   - No congestion control feedback from clients\n   - **Impact**: Network overload possible\n   - **Suggested Fix**: Configure reasonable defaults or per-channel limits\n\n8. **Voice Activity Broadcasting Sends Extra Parameter**\n   - `broadcast_voice_activity_to_channel` sends to ALL except sender\n   - But the exclude_connection_id is set to None\n   - Client sends their own speaking state to themselves too\n   - **Impact**: Redundant message\n   - **Suggested Fix**: Pass Some(connection_id) to exclude self\n\n9. **No Channel Permission Checks**\n   - Join voice doesn't verify user has permission to access channel\n   - No ACL or role-based channel access control for voice\n   - **Impact**: Any authenticated user can join any voice channel\n   - **Suggested Fix**: Add channel permission model\n\n10. **Mediasoup Worker Health Not Monitored**\n    - Workers created at startup, no restart logic\n    - No health checks or deadlock detection\n    - Worker crash would cause silent failures\n    - **Impact**: Server silently stops accepting voice connections\n    - **Suggested Fix**: Add worker health monitoring and auto-restart\n\n#### MINOR ISSUES:\n\n11. **SSRC Derivation Collision Risk**\n    - Canonical SSRC uses only first 4 bytes of UUID\n    - Fallback seed only triggers if exactly 0\n    - **Impact**: Extremely low, but possible SSRC collision\n    - **Suggested Fix**: Use full UUID or CRC32 of full UUID\n\n12. **No Requested Codec Preference Validation**\n    - Client can request any codec, server just filters to ready ones\n    - No limit on preferred_codecs list length\n    - **Impact**: Mild - clients well-behaved, but no server-side guards\n\n13. **Transport Direction Replaced Without Warning**\n    - Creating send transport twice replaces first one\n    - Any media sent on old transport is lost\n    - **Impact**: Client-side bug would lose media\n    - **Suggested Fix**: Return error if transport already exists\n\n14. **Mediasoup Error Messages Exposed**\n    - mediasoup library errors directly sent to client\n    - Could expose internal implementation details\n    - **Impact**: Low security impact, but information disclosure\n\n---\n\n### 12. CONFIGURATION SETTINGS\n\n**File:** `/home/guibibi/projects/yankcord/server/src/config.rs`\n\n```rust\npub struct MediaConfig {\n    pub worker_count: usize,                    // ENV: MEDIA_WORKER_COUNT (default: 2)\n    pub webrtc_listen_ip: String,               // ENV: WEBRTC_LISTEN_IP (default: 0.0.0.0)\n    pub announced_ip: Option<String>,           // ENV: WEBRTC_ANNOUNCED_IP\n    pub native_rtp_listen_ip: String,           // ENV: NATIVE_RTP_LISTEN_IP (default: 127.0.0.1)\n    pub native_rtp_announced_ip: Option<String>,// ENV: NATIVE_RTP_ANNOUNCED_IP\n}\n```\n\n**Environment Variables:**\n- `MEDIA_WORKER_COUNT`: Number of mediasoup workers (must be ≥1)\n- `WEBRTC_LISTEN_IP`: IP for WebRTC transport to listen on\n- `WEBRTC_ANNOUNCED_IP`: Public IP announced in ICE candidates\n- `NATIVE_RTP_LISTEN_IP`: IP for native RTP screen sharing\n- `NATIVE_RTP_ANNOUNCED_IP`: Public IP for native RTP\n\n**WebSocket Configuration (hardcoded):**\n- Outbound queue capacity: 256 messages\n- Idle timeout: 45 seconds\n- Auth timeout: 15 seconds\n- Presence idle (auto-idle status): 5 minutes\n\n**Rate Limiting:**\n- Media signal: 80 events per 5 seconds per connection\n- Payload size limit: 32 KB per media signal\n\n---\n\n### 13. DATABASE SCHEMA FOR VOICE\n\n```sql\n-- Channels table (created in migrations/20260216000001_initial.sql)\nCREATE TABLE channels (\n    id              UUID PRIMARY KEY,\n    name            TEXT NOT NULL,\n    description     TEXT,\n    kind            channel_kind,  -- 'text' or 'voice'\n    position        INT NOT NULL,\n    opus_bitrate    INTEGER,       -- Opus max average bitrate (bps)\n    opus_dtx        BOOLEAN,       -- Opus discontinuous transmission\n    opus_fec        BOOLEAN,       -- Opus forward error correction\n    created_at      TIMESTAMPTZ\n);\n```\n\n**No other voice-specific tables.**\n\n**Missing Features:**\n- No voice history/recording\n- No meeting recordings\n- No voice activity timeline\n- No user voice settings per channel\n- No voice mute/deafen state persistence\n- No voice channel permissions model\n\n---\n\n### 14. KEY FILES & FUNCTIONS SUMMARY\n\n| File | Key Components | Lines |\n|------|-----------------|-------|\n| `/home/guibibi/projects/yankcord/server/src/media/mod.rs` | MediaService, worker/router lifecycle | 177 |\n| `/home/guibibi/projects/yankcord/server/src/media/router.rs` | OpusConfig, codec definitions | 91 |\n| `/home/guibibi/projects/yankcord/server/src/media/transport.rs` | WebRTC transport, producer/consumer lifecycle | 656 |\n| `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs` | Native video codec support, screen sharing | 215 |\n| `/home/guibibi/projects/yankcord/server/src/media/producer.rs` | Producer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/media/consumer.rs` | Consumer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs` | Media signaling protocol handler | 1064 |\n| `/home/guibibi/projects/yankcord/server/src/ws/voice.rs` | Voice broadcast functions | 118 |\n| `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` | Voice join/leave, main WS handler | 1416 |\n| `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` | State cleanup, connection management | 400 |\n| `/home/guibibi/projects/yankcord/server/src/ws/messages.rs` | WebSocket message types | 257 |\n\n---\n\n### 15. ARCHITECTURE DIAGRAM\n\n```\nClient\n  ↓ WebSocket Connection\n┌─────────────────────────────────┐\n│   WebSocket Handler             │\n│   - Authentication              │\n│   - Connection Management       │\n│   - Message Dispatching         │\n└─────────────────────────────────┘\n  ↓\n┌─────────────────────────────────────────────┐\n│   Media Signaling Handler                   │\n│   - Route RTP Capabilities                  │\n│   - Create WebRTC Transport                 │\n│   - Create Producer/Consumer                │\n│   - Rate Limiting (80 events/5s)            │\n└─────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────────────────────┐\n│   MediaService (SFU)                             │\n├──────────────────────────────────────────────────┤\n│  Workers (Vec<Worker>)                           │\n│    ↓                                             │\n│  Routers (HashMap<Uuid, Router>)                 │\n│    ├─ per-channel caching                        │\n│    ├─ codec config (opus, VP8, H264, etc)        │\n│    └─ RTP capability negotiation                 │\n│                                                  │\n│  ConnectionMediaState (HashMap<Uuid, State>)    │\n│    ├─ WebRTC Transports (send/recv)              │\n│    ├─ PlainTransports (native RTP)               │\n│    ├─ Producers (audio/video/screen)             │\n│    └─ Consumers (receive streams)                │\n└──────────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   In-Memory State                │\n├──────────────────────────────────┤\n│  voice_members_by_connection     │\n│    (who's in which channel)      │\n│                                  │\n│  voice_members_by_channel        │\n│    (channel membership list)     │\n│                                  │\n│  media_signal_rate_by_connection │\n│    (rate limiting state)         │\n└──────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   Database                       │\n├──────────────────────────────────┤\n│  channels:                       │\n│    - id, name, kind='voice'      │\n│    - opus_bitrate, opus_dtx,fec  │\n└──────────────────────────────────┘\n```\n\n---\n\n### 16. RECOMMENDATIONS & IMPROVEMENTS\n\n**Priority 1 (Critical):**\n1. Add database persistence for voice channel membership\n2. Invalidate router cache when channel codec settings change\n3. Fix consumer auto-cleanup when producer closes\n4. Add channel permission checks for voice access\n\n**Priority 2 (High):**\n5. Implement worker health monitoring\n6. Batch producer notifications on recv transport creation\n7. Add bitrate enforcement/limits per consumer\n8. Fix producer owner lookup failure handling\n9. Add TOCTOU guard for camera/screen limit checks\n\n**Priority 3 (Medium):**\n10. Implement consumer lifecycle management\n11. Add voice history/analytics database table\n12. Implement voice activity recording\n13. Add per-user voice settings model\n14. Implement voice mute/deafen persistence\n\n**Priority 4 (Nice to Have):**\n15. Add multiple transport error recovery\n16. Implement auto-reconnection guidance\n17. Add voice quality metrics collection\n18. Implement adaptive bitrate adjustment\n19. Support REMB/TWCC congestion control feedback\n\n---\n\n### CONCLUSION\n\nThe Yankcord voice system is a **well-architected SFU implementation** using mediasoup. It handles WebRTC connections, producer/consumer management, and signaling correctly. However, it has **several critical issues** around codec setting persistence, consumer lifecycle management, and state recovery that should be addressed before production use. The architecture is sound but needs hardening for robustness and reliability.</result>\n<usage><total_tokens>80577</total_tokens><tool_uses>33</tool_uses><duration_ms>124352</duration_ms></usage>\n</task-notification>\nFull transcript available at: REDACTED.output"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-23T14:49:08.740Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","content":"<task-notification>\n<task-id>a4a521c</task-id>\n<tool-use-id>REDACTED</tool-use-id>\n<status>completed</status>\n<summary>Agent \"Explore voice chat client code\" completed</summary>\n<result>Perfect! Now I have a comprehensive view of the voice/audio/WebRTC system. Let me compile my findings:\n\n## Comprehensive Exploration of Voice Chat/WebRTC/Mediasoup Client Implementation\n\nBased on my thorough exploration of the client-side voice chat implementation in `/home/guibibi/projects/yankcord/client`, here's a detailed analysis:\n\n---\n\n## **1. ARCHITECTURE OVERVIEW**\n\nThe voice chat system uses **mediasoup-client** as the WebRTC library with an **SFU (Selective Forwarding Unit)** routing mode. It's a comprehensive implementation with client-side state management, audio/video processing, and native screen capture support via Tauri.\n\n---\n\n## **2. KEY COMPONENTS & FILES**\n\n### **2.1 State Management & Store** \n\n**File: `/home/guibibi/projects/yankcord/client/src/stores/voice.ts` (413 lines)**\n\n**Purpose:** Solid.js signal-based reactive state store for all voice-related state\n\n**Key Signals:**\n- `joinedVoiceChannelId` - Currently joined voice channel\n- `participantsByChannel` - Track which users are in each channel\n- `speakingByChannel` - Track speaking status per channel/user\n- `voiceActionState` - \"idle\", \"joining\", \"leaving\" state machine\n- `micMuted`, `speakerMuted` - Mute states\n- `cameraEnabled`, `screenShareEnabled` - Media activation states\n- `transportHealth` - Connection health state\n- `videoTiles` - Array of remote video streams\n\n**Key Functions:**\n- `applyVoiceSnapshot()` - Initialize voice presence\n- `applyVoiceJoined/Left/Speaking()` - Update participant state\n- `startVideoTilesSubscription()` / `startConnectionStatusSubscription()` - Subscribe to media state\n- `resetVoiceState()` - Clean slate when disconnecting\n- Health monitoring via `voiceHealthLevel()` that aggregates WebSocket and transport health\n\n**Issues Identified:**\n- No automatic cleanup on component unmount for subscriptions in some cases\n- Multiple unsubscribe refs that could leak if not properly managed\n\n---\n\n### **2.2 Media State Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/state.ts` (144 lines)**\n\n**Purpose:** Module-level state (not reactive) for mediasoup infrastructure\n\n**State Categories:**\n\n1. **Device & Transport**\n   - `device: Device | null` - mediasoup Device instance\n   - `sendTransport, recvTransport: Transport | null` - WebRTC transports\n\n2. **Producer State**\n   - `micProducer, micStream, micTrack` - Microphone\n   - `cameraProducer, cameraStream, cameraTrack` - Camera\n   - `screenProducer, screenStream, screenTrack` - Screen share\n   - `nativeScreenProducerId` - Tauri-native screen capture ID\n\n3. **Consumer State**\n   - `remoteConsumers: Map<string, Consumer>` - Audio/video consumers\n   - `consumerIdByProducerId: Map<string, string>` - Lookup table\n\n4. **Audio Processing**\n   - `micLevelAudioContext, micLevelAnalyserNode, micLevelData` - For voice activity detection\n   - `remotePlaybackAudioContext` - Shared context for remote audio\n\n5. **Volume Control**\n   - `consumerGainNodes, consumerNormalizationNodes` - Per-user volume/compression\n   - `remoteAudioElements: Map<string, HTMLAudioElement>` - Audio playback elements\n\n6. **Metadata**\n   - `producerUsernameById, producerSourceById, producerRoutingModeById` - Track producer metadata\n   - `queuedProducerAnnouncements` - Queue producers until initialized\n\n7. **Health Monitoring**\n   - `transportHealthState` - ICE connection state\n   - `signalListenerInitialized` - Track media signal setup\n\n---\n\n### **2.3 Transport Initialization & Lifecycle**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts` (376 lines)**\n\n**Purpose:** WebRTC transport setup, connection monitoring, and cleanup\n\n**Key Functions:**\n\n1. **`initializeMediaTransports(channelId: string)`** (Line 246-341)\n   - Idempotent initialization with promise-based deduplication\n   - Requests RTP capabilities from server\n   - Creates mediasoup Device and Send/Recv transports\n   - Wires up event handlers (connect, produce, ICE monitoring)\n   - Starts local audio producer immediately\n   - Flushes queued producer announcements\n   - **Pattern: Robust re-entrant guard against multiple concurrent initializations**\n\n2. **`closeTransports()`** (Line 163-244)\n   - Comprehensive cleanup of all resources\n   - Stops all producers (mic, camera, screen) and their tracks\n   - Closes all consumers\n   - Cleans up device change listener\n   - Stops voice activity monitoring\n   - Disposes microphone processing pipeline\n   - **Pattern: Defensive cleanup - removes resources even if already null**\n\n3. **Transport Health Monitoring** (Line 76-83, 101-132)\n   - `updateTransportHealthFromIce()` - Aggregates send/recv transport states\n   - Disconnect recovery with 10-second timeout (Line 119-123)\n   - Notifies all subscribers on state change\n   - States: \"connected\", \"new\", \"closed\", \"disconnected\", \"failed\"\n   - Severity mapping for worst-state calculation\n\n4. **Event Handlers**\n   - `wireTransportConnect()` - DTLS parameter exchange\n   - `wireSendTransportProduce()` - Producer creation signaling\n   - `wireTransportConnectionStateMonitor()` - ICE monitoring with auto-recovery\n\n5. **Mute Functions**\n   - `setMicrophoneMuted(muted)` - Disables track + reports voice activity\n   - `setSpeakersMuted(muted)` - Mutes all remote audio elements\n\n**Issues Identified:**\n- No retry logic if initial transport creation fails\n- Single global `disconnectRecoveryTimer` could theoretically be overwritten\n- Transport state machine could have edge cases with rapid join/leave\n- Audio context resumption error handling is silent (no logs)\n\n---\n\n### **2.4 Producer Management (Sending Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts` (737 lines)**\n\n**Purpose:** Manage outgoing audio, camera, and screen share streams\n\n**Key Producers:**\n\n1. **Microphone Producer** - `startLocalAudioProducer()` (Line 143-223)\n   - Gets user media with constraints (noise suppression, echo cancellation)\n   - Creates processed microphone track via `createProcessedMicrophoneTrack()`\n   - Wraps track in mediasoup Producer\n   - Starts voice activity monitoring\n   - Handles channel switch during startup\n   - **Pattern: Careful track ownership - uses `stopTracks: false` to manage lifecycle separately**\n\n2. **Camera Producer** - `startLocalCameraProducer()` (Line 237-315)\n   - Gets video constraints via `cameraInputConstraint()`\n   - Fallback logic for device availability\n   - H.264 codec preference\n   - Produces with `stopTracks: false`\n   - Error normalization for user display\n\n3. **Screen Share - Two Modes:**\n   - **Browser Mode** - `startBrowserScreenProducer()` (Line 380-490)\n     - Uses `getDisplayMedia()` API\n     - Optional constraint application (resolution, FPS)\n     - Content hint for encoder optimization (motion vs detail)\n     - Codec preference for platform\n     - Bitrate configuration with encoder hints\n   \n   - **Native Tauri Mode** - `startNativeScreenProducer()` (Line 492-643)\n     - Only on Tauri runtime with sourceId selected\n     - Uses RTP sender backend (not WebRTC producer)\n     - H.264 codec only (for compatibility)\n     - Extensive codec negotiation & validation\n     - Fallback monitor (polling every 1s for encoder failures)\n     - Diagnostics reporting to server\n     - **Pattern: Graceful fallback with heartbeat monitoring**\n\n4. **Track Lifecycle**\n   - Cleanup functions: `stopAndReleaseCameraTracks()`, `stopAndReleaseScreenTracks()`\n   - Producer close events trigger automatic cleanup\n   - Track ended events trigger producer closure\n   - Channel switch guards to prevent orphaned producers\n\n5. **Microphone Processing Pipeline**\n   - Volume gain node (for outgoing volume control)\n   - Creates processed track from source\n   - Mute state applied to both source and processed tracks\n\n**Issues Identified:**\n- No timeout for producer creation (could hang if network fails)\n- Screen share codec selection logs to console in debug mode - could be verbose\n- Native capture fallback flag is per-session; user can't retry browser mode once native attempted\n- Multiple try-catch blocks could benefit from unified error logging\n- Producer stats logging `logScreenShareProducerStats()` only logs on screen share start, not continuous\n\n---\n\n### **2.5 Consumer Management (Receiving Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts` (382 lines)**\n\n**Purpose:** Create and manage consuming remote audio/video streams\n\n**Key Functions:**\n\n1. **`consumeRemoteProducer(channelId, producerId)`** (Line 166-295)\n   - Requests consumer from server\n   - Creates consumer via `recvTransport.consume()`\n   - **Audio Path:**\n     - Creates HTMLAudioElement\n     - Sets up audio processing chain: SourceNode → NormalizationCompressor → GainNode → Destination\n     - Applies per-user volume + global incoming volume\n     - Resumes consumer before playback\n     - Retry logic for `audio.play()` (500ms delay + second attempt)\n   - **Video Path:**\n     - Creates RemoteVideoTile entry\n     - Resumes consumer\n     - Queues for tile updates\n   - Event handlers for transport close and track ended\n\n2. **Audio Chain Architecture** (Line 225-244)\n   ```\n   SourceNode (raw consumer track)\n   → NormalizationNode (DynamicsCompressor)\n   → GainNode (per-user volume)\n   → Destination (playback)\n   ```\n   - Normalization threshold: -24dB, knee: 20dB, ratio: 3, attack: 3ms, release: 250ms\n   - Provides consistent volume across speakers\n   - Disabled when `voiceAutoLevelEnabled` is false\n\n3. **Volume Management**\n   - `updateUserGainNodes()` - Updates specific user's volume\n   - `updateIncomingVoiceGainNodes()` - Updates global incoming volume\n   - `updateVoiceNormalizationNodesEnabled()` - Toggle auto-leveling\n   - Per-user volume from settings store\n\n4. **Producer Queuing** - `queueOrConsumeProducer()` (Line 321-353)\n   - If not initialized yet, queues producer announcement\n   - On initialization complete, `flushQueuedProducerAnnouncements()` processes queue\n\n5. **Cleanup** - `disposeRemoteConsumer(consumerId)` (Line 120-164)\n   - Closes consumer\n   - Disconnects all audio nodes\n   - Removes audio element from DOM\n   - Cleans up metadata maps\n   - Possibly closes shared audio context if last consumer\n\n**Issues Identified:**\n- Audio play() retry uses hardcoded 500ms delay - no exponential backoff\n- No per-consumer timeout for requestMediaSignal - could hang indefinitely\n- Consumer track ended detection doesn't distinguish between normal end and network failure\n- NormalizationNode configuration recreated per consumer instead of module-level constant\n- No logging for consumer creation failures - silent error handling\n- Gain node value clamping (0-200%) happens in multiple places - duplication\n\n---\n\n### **2.6 Voice Activity Detection & Speaking Status**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts` (111 lines)**\n\n**Purpose:** Monitor microphone level and report speaking status\n\n**Key Metrics:**\n- FFT size: 512\n- Smoothing time constant: 0.85\n- RMS threshold: 0.04 (4%)\n- Speaking hold duration: 220ms (hold-over to avoid jitter)\n\n**Algorithm:**\n1. Analyser node performs FFT on incoming audio\n2. Calculates RMS (root mean square) of audio samples\n3. If RMS >= threshold AND not muted → set hold-until time\n4. Current time <= hold-until → report speaking=true\n5. Muting immediately reports speaking=false\n\n**Functions:**\n- `startMicLevelMonitoring()` - Creates audio context and starts RAF-based monitor loop\n- `stopMicLevelMonitoring()` - Cleanup and final speaking=false report\n\n**Issues Identified:**\n- Uses `requestAnimationFrame` for 60fps monitoring - unnecessary overhead\n- Should use fixed interval (e.g., 50ms) instead\n- `micSpeakingLastSent` is a boolean flag, not a full state - can't distinguish between not-yet-sent and sent-false\n- No jitter buffer - could spam speaking state changes\n\n---\n\n### **2.7 Microphone Processing Pipeline**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts` (104 lines)**\n\n**Purpose:** Apply outgoing volume control to microphone track\n\n**Architecture:**\n```\nUserMedia Stream\n  → SourceNode\n    → GainNode (volume)\n      → DestinationNode (processed track)\n```\n\n**Lifecycle:**\n- Single active session at a time\n- `createProcessedMicrophoneTrack()` - Creates new session with gain node\n- `activateMicrophoneProcessing()` - Sets session as active (disposes previous)\n- `updateOutgoingMicrophoneGain()` - Changes gain value in active session\n- `updateOutgoingMicrophoneMuted()` - Sets track.enabled on both source and processed\n\n**Issues Identified:**\n- Keeps original sourceTrack around - consumes extra resources\n- No cleanup callback - if active session set but never disposed, resources leak\n- Gain clamping function duplicated from consumers.ts\n- No validation that sourceTrack is still valid before using it\n\n---\n\n### **2.8 Media Signaling (WebSocket Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts` (178 lines)**\n\n**Purpose:** Request-response protocol for media operations (RTC negotiation, producer/consumer management)\n\n**Signal Actions:**\n- `get_router_rtp_capabilities` - Get server's codec capabilities\n- `create_webrtc_transport` - Create send/recv transport\n- `connect_webrtc_transport` - Exchange DTLS parameters\n- `media_produce` - Create producer\n- `media_close_producer` - Close producer\n- `media_consume` - Create consumer\n- `media_resume_consumer` - Resume consumer playback\n- `create_native_sender_session` - RTP sender setup (native capture)\n- `client_diagnostic` - Report native sender metrics\n\n**Request-Response Pattern:**\n- Each request gets unique ID: `media-${Date.now()}-${counter}`\n- 10-second timeout (Line 113-116)\n- Response matched to request by ID\n- Pending requests tracked in Map\n- Server can send unsolicited messages (new_producer, producer_closed, voice_activity)\n\n**Voice Activity Reporting:**\n- `reportVoiceActivity()` - Send speaking=true/false to server\n- Triggered by voice level monitoring\n\n**Diagnostics:**\n- `reportCodecDecision()` - Log codec selection decision\n- `reportNativeSenderDiagnostic()` - Report native sender status/errors\n\n**Issues Identified:**\n- Fixed 10-second timeout for all operations - some might need longer (network dependent)\n- No retry logic - first timeout = failure\n- PendingRequests could accumulate if responses never arrive (timeout cleanup exists, but requests are still lost)\n- No congestion detection - if many requests fail, no backpressure\n\n---\n\n### **2.9 Subscription System**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts` (122 lines)**\n\n**Purpose:** Publisher-subscriber pattern for media state changes\n\n**Subscribers:**\n1. `videoTilesSubscribers` - Remote camera/screen tiles\n2. `cameraStateSubscribers` - Local camera enabled/error/stream\n3. `screenStateSubscribers` - Local screen share enabled/error/stream/routingMode\n4. `transportHealthSubscribers` - Connection health state\n\n**Pattern:**\n- Each subscription function calls subscriber immediately with current state\n- Returns unsubscribe function\n- Used by `voice.ts` store to maintain reactive state\n\n**Issues Identified:**\n- No limits on subscriber count - potential memory leak if many subscriptions created\n- No deduplication - could call subscriber twice if subscribed twice\n- Subscribers called synchronously - blocking if callback is slow\n\n---\n\n### **2.10 Device Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts** (150+ lines)**\n\n**Purpose:** Enumerate and switch audio/video devices at runtime\n\n**Device Enumeration:**\n- `listAudioDevices()` - List microphones & speakers\n- `listCameraDevices()` - List cameras\n- Labels sorted alphabetically with fallback numbering\n\n**Device Selection:**\n- `setPreferredMicrophoneDevice()` - Hot-swap microphone\n  - Gets new user media\n  - Creates new processing session\n  - Replaces producer track if exists, or creates new producer\n  - Manages fallback if device unavailable\n  \n- `setPreferredCameraDevice()` - Hot-swap camera (partial implementation visible)\n- `setPreferredSpeakerDevice()` - Route speaker output\n  - Uses `HTMLAudioElement.setSinkId()` if supported\n  - Applied to all remote audio elements\n\n**Device Change Detection:**\n- `registerDeviceChangeListener()` - Fires when devices added/removed\n- Resets audio devices if current device disappears\n- Prevents duplicate registrations\n\n**Issues Identified:**\n- Device change listener doesn't distinguish between input/output changes\n- Hot-swap has no fallback if getRtpCapabilities changes (rare but possible)\n- Speaker routing set per-element, not globally - new consumers must be manually routed\n- Sorting is expensive on every enumeration - could cache\n\n---\n\n### **2.11 Constraints & Codec Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts` (97 lines)**\n\n**Audio Constraints:**\n```typescript\n{\n  deviceId: { exact: selectedDeviceId },\n  noiseSuppression: voiceNoiseSuppressionEnabled(),\n  echoCancellation: voiceEchoCancellationEnabled(),\n  channelCount: 1  // Mono\n}\n```\n- Uses browser supported constraints API\n- Graceful degradation if constraints unavailable\n\n**Video Constraints (Camera):**\n- Simple exact device ID constraint\n\n**Screen Share Constraints:**\n- Resolution: 720p (1280×720), 1080p (1920×1080), 1440p (2560×1440), 4k (3840×2160)\n- FPS: 30 or 60\n- displaySurface hint: \"monitor\" or \"window\"\n- contentHint: \"motion\" (>=60fps or app) or \"detail\"\n\n**Codec Selection:**\n- Screen share: H.264 > VP8 > VP9 (platform-independent, NVENC hardware support)\n- Native: H.264 only\n\n**Issues Identified:**\n- No support for audio bandwidth constraints\n- Screen share 4K resolution could be very expensive\n- No validation that requested FPS/resolution is supported before attempting\n\n---\n\n### **2.12 Error Handling**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts` (72 lines)**\n\n**Error Normalization:**\n\n1. **Camera Errors:**\n   - Permission denied → \"Camera access was denied...\"\n   - Not found → \"No camera device was found...\"\n   - Not readable/in use → \"Camera is unavailable or in use...\"\n   - Generic → Pass through error message\n\n2. **Screen Share Errors:**\n   - Permission denied → \"Screen share permission was denied...\"\n   - Not found → \"No shareable display source was found...\"\n   - Not readable → \"Screen sharing is unavailable or already in use...\"\n   - Generic → Pass through error message\n\n3. **Device Detection:**\n   - `isMissingDeviceError()` - Check if error is device-not-found\n\n**Issues Identified:**\n- Error messages are user-friendly but not actionable\n- No error codes - difficult to log/debug\n- Generic DOMException handling is catch-all at end\n\n---\n\n### **2.13 Native Screen Capture (Tauri)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/native.ts` (88 lines)**\n\n**Purpose:** Wrap Tauri native screen capture APIs\n\n**Functions:**\n- `listNativeCaptureSources()` - Enumerate windows/screens/apps\n- `nativeCodecCapabilities()` - Check available codecs\n- `startNativeCapture()` - Arm native capture service\n- `stopNativeCapture()` - Disarm service\n- `nativeCaptureStatus()` - Poll for live metrics\n\n**Fallback Monitor:**\n- Polling every 1s for encoder failures\n- Fallback reasons: \"degradation\", \"encoder_failure\", etc.\n- Auto-stops if fallback reason appears\n- Reports diagnostic event to server\n\n**Backend Selection:**\n- Reads encoder_backend (NVENC, OpenH264)\n- Tries requested backend, falls back to other\n- Extensive diagnostics in `NativeCaptureStatus`\n\n**Issues Identified:**\n- Hardcoded 1s poll interval - could miss rapid failures\n- Codec mime type validation string-matching (should use enum)\n- No timeout if native capture hangs\n\n---\n\n## **3. UI COMPONENTS**\n\n### **3.1 Voice Dock Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx` (131 lines)**\n\n**Purpose:** Main control panel for voice channel operations\n\n**Controls:**\n- Disconnect button\n- Mic mute toggle\n- Speaker mute toggle  \n- Camera enable/disable\n- Screen share enable/disable\n\n**Status Display:**\n- Connected channel name\n- Connection health (good/degraded/failed)\n- Health dot indicator + label\n- Camera/screen share error messages\n- Routing mode (SFU)\n\n**Native Debug Panel** (Tauri only, debug mode):\n- Frame queue stats\n- Encoder output rate\n- RTP packet counts\n- Queue backlog & drop counts\n- Encode latency\n- Codec info\n- Transport/producer health\n- Pressure metrics\n- Encoder backend info\n\n**Issues Identified:**\n- No tooltip for health states\n- Debug panel is text-heavy and cramped\n- Retry connection button shown but doesn't explain what will reconnect\n\n---\n\n### **3.2 Video Stage Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx` (78 lines)**\n\n**Purpose:** Display grid of video tiles (camera + screen share)\n\n**Layout:**\n- Local camera (if enabled) in grid\n- Local screen share (if enabled) in grid\n- Remote camera tiles (from videoTiles subscription)\n\n**Features:**\n- Auto-play video elements\n- Muted local streams\n- Username + source labels\n- CSS classes for styling (is-local, is-screen-share)\n\n**Issues Identified:**\n- No pagination/max tile limit (could become unwieldy with many participants)\n- No speaker highlight indicator\n- Order is arbitrary for remote tiles (relies on alphabetical sort in subscriptions.ts)\n- No click-to-focus or fullscreen\n\n---\n\n### **3.3 Voice Settings Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx` (110 lines)**\n\n**Purpose:** User-facing voice settings\n\n**Toggles:**\n- Noise suppression\n- Echo cancellation\n- Auto level incoming voices\n\n**Sliders:**\n- Incoming voice volume (0-200%)\n- Outgoing microphone volume (0-200%)\n\n**Issues Identified:**\n- No input validation (could receive invalid percentages)\n- Help text is generic, no device-specific guidance\n- Volume slider goes to 200% - could cause distortion\n\n---\n\n## **4. INTEGRATION WITH MAIN APPLICATION**\n\n### **4.1 ChannelList Component (Voice Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (1200+ lines)**\n\n**Key Voice Operations:**\n\n1. **Join Voice** - `joinVoiceChannel()`\n   - Sets state to \"joining\"\n   - Sends WebSocket message\n\n2. **Leave Voice** - `leaveVoiceChannel()`\n   - Sets state to \"leaving\"\n   - Sends WebSocket message\n\n3. **Toggle Mic** - `handleToggleMicMuted()`\n   - Updates mute state\n   - Calls `setMicrophoneMuted()`\n\n4. **Toggle Camera** - `handleToggleCamera()`\n   - Idempotent with pending state\n   - Calls `startLocalCameraProducer()` or `stopLocalCameraProducer()`\n   - Shows error toast on failure\n\n5. **Toggle Screen Share** - `handleToggleScreenShare()`\n   - Browser mode: Immediate `startLocalScreenProducer()`\n   - Tauri mode: Opens modal to select source, then starts\n   - Calls `stopLocalScreenProducer()` if already sharing\n\n6. **Voice Presence Events**\n   - `voice_joined` → Initialize transports, restore settings\n   - `voice_left` → Cleanup, reset state\n   - `voice_user_joined` → Play join cue, update participants\n   - `voice_user_left` → Play leave cue, update participants\n   - `voice_user_speaking` → Update speaking indicator\n   - `voice_presence_snapshot` → Initialize on startup\n\n7. **Error Handling**\n   - Error type message → Set action state to idle\n   - Network close → Show rejoin notice + cleanup\n\n8. **Cleanup on Unmount**\n   - Stop subscriptions\n   - Remove event listeners\n   - Clear timers\n   - Stop screen share preview\n\n**Issues Identified:**\n- Error message shown in toast but error details lost\n- No user confirmation for destructive actions (e.g., leaving voice)\n- Native metrics polling (1s interval) runs constantly when screen sharing - could drain battery\n\n---\n\n## **5. STATE FLOW DIAGRAM**\n\n```\nWebSocket Message (voice_joined)\n  ↓\nsetJoinedVoiceChannel(id)\n  ↓\ninitializeMediaTransports(id)\n  ├─ Request RTP capabilities\n  ├─ Load Device with capabilities\n  ├─ Create Send/Recv transports\n  ├─ Wire transport events\n  └─ startLocalAudioProducer()\n      ├─ getUserMedia() with constraints\n      ├─ createProcessedMicrophoneTrack() (gain node)\n      ├─ sendTransport.produce()\n      └─ startMicLevelMonitoring()\n        └─ RAF loop → Calculate RMS → reportVoiceActivity()\n  ├─ registerDeviceChangeListener()\n  └─ flushQueuedProducerAnnouncements()\n      └─ consumeRemoteProducer() for each queued\n\nOn new_producer signal\n  ├─ Record username, source, routingMode\n  └─ queueOrConsumeProducer() → consumeRemoteProducer()\n      ├─ Request consumer from server\n      ├─ Create consumer via recvTransport\n      ├─ If audio: Set up playback chain\n      │   ├─ Create HTMLAudioElement\n      │   ├─ SourceNode → NormalizationCompressor → GainNode → Destination\n      │   └─ audio.play()\n      └─ If video: Create VideoTile + subscribe UI\n\nWebSocket Message (voice_left)\n  ↓\ncleanupMediaTransports()\n  ├─ closeTransports()\n  │   ├─ Dispose all producers & tracks\n  │   ├─ Close all consumers\n  │   ├─ Dispose audio nodes & elements\n  │   └─ Close transports & device\n  └─ Reset all state signals\n```\n\n---\n\n## **6. DETAILED ISSUES & RECOMMENDATIONS**\n\n### **Critical Issues**\n\n1. **No Timeout on Transport Creation**\n   - **Location:** `initializeMediaTransports()` line 279\n   - **Issue:** If server hangs responding to capabilities request, initialization blocks indefinitely\n   - **Fix:** Add 5-second timeout to `requestMediaSignal()` calls in transport init\n\n2. **Silent Audio Play Failure Retry**\n   - **Location:** `consumers.ts` line 247-265\n   - **Issue:** If `audio.play()` fails twice, error is logged but not propagated\n   - **Impact:** User hears silence but no error toast\n   - **Fix:** Throw error after second failure, let caller handle\n\n3. **Microphone Processing Resource Leak**\n   - **Location:** `microphoneProcessing.ts`\n   - **Issue:** If `activateMicrophoneProcessing()` is called without prior cleanup, old session orphaned\n   - **Fix:** Explicit dispose call or use WeakMap for auto-cleanup\n\n4. **Voice Activity Detection Too Sensitive**\n   - **Location:** `voiceActivity.ts` line 77-78\n   - **Issue:** 220ms hold-over can miss natural speech pauses\n   - **Recommendation:** Use 300-400ms, or make configurable\n\n### **High Priority Issues**\n\n5. **Screen Share Fallback Stuck**\n   - **Location:** `producers.ts` line 680-685\n   - **Issue:** Once `nativeCaptureAttempted` set true, user can't retry browser mode\n   - **Fix:** Add UI button to reset flag, or prompt user\n\n6. **Transport Health Monitoring Race Condition**\n   - **Location:** `transports.ts` line 106-112\n   - **Issue:** Multiple transports closing in parallel could set state to wrong value\n   - **Fix:** Use sequence number or lock to ensure ordering\n\n7. **No Reconnection Logic**\n   - **Issue:** If WebSocket reconnects, media transports not re-established\n   - **Fix:** Add auto-reconnect on WS reconnect (currently relies on user clicking Retry)\n\n### **Medium Priority Issues**\n\n8. **Volume Clamping Duplicated**\n   - **Locations:** `consumers.ts` line 39-44, `microphoneProcessing.ts` line 10-15\n   - **Fix:** Export single function from utils module\n\n9. **Consumer Creation Timeout**\n   - **Location:** `consumers.ts` line 184\n   - **Issue:** No timeout on `requestMediaSignal(\"media_consume\")`\n   - **Fix:** Add shorter timeout (3-5s) for per-consumer requests\n\n10. **Device Change Listener Not De-Registered**\n    - **Location:** `transports.ts` line 168\n    - **Issue:** Listener registered in `initializeMediaTransports`, de-registered on close, but no guard\n    - **Fix:** Add state guard to prevent double de-registration\n\n### **Code Quality Issues**\n\n11. **Error Handling Inconsistency**\n    - Some code uses `console.warn`, some uses `console.error`, some uses throw\n    - **Fix:** Standardize on error boundary propagation\n\n12. **Missing JSDoc Comments**\n    - Complex functions like `consumeRemoteProducer` lack documentation\n    - **Fix:** Add JSDoc for public APIs\n\n13. **Magic Numbers**\n    - 10000ms timeout, 220ms hold, 512 FFT size, 0.04 threshold not documented\n    - **Fix:** Extract to named constants with comments\n\n---\n\n## **7. PERFORMANCE CONSIDERATIONS**\n\n1. **Audio Context Lifecycle**\n   - Creates multiple AudioContexts (mic level, remote playback, mic processing)\n   - Browser limits ~10 contexts max - current design uses 3 when at capacity\n   - **Safe but could be optimized:** Reuse single context for monitoring\n\n2. **Voice Activity Detection RAF Loop**\n   - Runs at 60fps (browser refresh rate)\n   - **Issue:** Overkill for voice activity (could be 20fps)\n   - **Fix:** Use 50ms setInterval instead\n\n3. **Storage of All Remote Audio Elements**\n   - `remoteAudioElements` map keeps reference to all audio elements\n   - **Potential issue:** Never cleaned from DOM, only disconnected\n   - **Fix:** Use WeakMap or actively remove elements\n\n4. **Native Sender Metrics Polling**\n   - 1-second interval polling from Rust backend\n   - **Cost:** Continuous IPC calls\n   - **Optimization:** Debounce to 2-3 seconds or on-demand\n\n---\n\n## **8. SECURITY CONSIDERATIONS**\n\n1. **Producer/Consumer Metadata**\n   - Username stored client-side in `producerUsernameById` Map\n   - **Risk:** Could be spoofed if network message forged\n   - **Mitigation:** Server validates all signaling messages\n\n2. **Codec Negotiation**\n   - Accepts codec from server without validation\n   - **Mitigation:** Limited set of supported codecs in device.rtpCapabilities\n\n3. **SinkId Device Selection**\n   - `setSinkId` could fail silently\n   - **Risk:** Audio routed to unexpected output\n   - **Mitigation:** Device selection is user-initiated\n\n---\n\n## **9. SUMMARY TABLE**\n\n| Component | Purpose | Lines | Key Pattern | Risk Level |\n|-----------|---------|-------|-------------|-----------|\n| voice.ts | Reactive state store | 413 | Solid.js signals | Low |\n| state.ts | Module-level state | 144 | Module exports | Low |\n| transports.ts | RTC setup/lifecycle | 376 | Idempotent init + cleanup | Medium |\n| producers.ts | Outgoing media | 737 | Track ownership mgmt | High |\n| consumers.ts | Incoming media | 382 | Audio processing chain | High |\n| voiceActivity.ts | Speaking detection | 111 | RAF-based monitoring | Medium |\n| microphoneProcessing.ts | Outgoing volume | 104 | Single active session | Medium |\n| signaling.ts | WebSocket protocol | 178 | Request-response | Medium |\n| subscriptions.ts | Publisher-subscriber | 122 | Observer pattern | Low |\n| devices.ts | Audio/video devices | 150+ | Hot-swap at runtime | High |\n| constraints.ts | Media constraints | 97 | Constraint generation | Low |\n| errors.ts | Error normalization | 72 | Error mapping | Low |\n| native.ts | Tauri integration | 88 | API wrapper | Medium |\n| VoiceDock.tsx | Control UI | 131 | Component | Low |\n| VideoStage.tsx | Video grid | 78 | Component | Low |\n| VoiceAudioPreferences.tsx | Settings UI | 110 | Component | Low |\n| ChannelList.tsx | Main integration | 1200+ | Orchestration | High |\n\n---\n\n## **10. FILE PATHS (ABSOLUTE)**\n\nAll voice-related files are located at:\n\n- `/home/guibibi/projects/yankcord/client/src/stores/voice.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/index.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/types.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/state.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/codecs.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/native.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media.ts` (re-export wrapper)\n- `/home/guibibi/projects/yankcord/client/src/api/nativeCapture.ts` (Tauri bindings)\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/ScreenShareModal.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (integration)\n- `/home/guibibi/projects/yankcord/client/src/utils/voiceCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/utils/audioCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/ws.ts` (WebSocket definitions)\n\nNative Tauri implementation:\n- `/home/guibibi/projects/yankcord/client/src-tauri/src/` (Rust backend for native capture)\n\nThis concludes the comprehensive exploration of the voice chat system on the client side.</result>\n<usage><total_tokens>95540</total_tokens><tool_uses>41</tool_uses><duration_ms>162087</duration_ms></usage>\n</task-notification>\nFull transcript available at: REDACTED.output"}
{"parentUuid":"5ff0b289-d04f-4517-8905-9a49cb5c306c","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011P3vw8PMtG2bzzXUNaFuqr","type":"tool_result","content":"<retrieval_status>success</retrieval_status>\n\n<task_id>a4a521c</task_id>\n\n<task_type>local_agent</task_type>\n\n<status>completed</status>\n\n<output>\n[Truncated. Full output: REDACTED.output]\n\n`videoTiles` - Array of remote video streams\n\n**Key Functions:**\n- `applyVoiceSnapshot()` - Initialize voice presence\n- `applyVoiceJoined/Left/Speaking()` - Update participant state\n- `startVideoTilesSubscription()` / `startConnectionStatusSubscription()` - Subscribe to media state\n- `resetVoiceState()` - Clean slate when disconnecting\n- Health monitoring via `voiceHealthLevel()` that aggregates WebSocket and transport health\n\n**Issues Identified:**\n- No automatic cleanup on component unmount for subscriptions in some cases\n- Multiple unsubscribe refs that could leak if not properly managed\n\n---\n\n### **2.2 Media State Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/state.ts` (144 lines)**\n\n**Purpose:** Module-level state (not reactive) for mediasoup infrastructure\n\n**State Categories:**\n\n1. **Device & Transport**\n   - `device: Device | null` - mediasoup Device instance\n   - `sendTransport, recvTransport: Transport | null` - WebRTC transports\n\n2. **Producer State**\n   - `micProducer, micStream, micTrack` - Microphone\n   - `cameraProducer, cameraStream, cameraTrack` - Camera\n   - `screenProducer, screenStream, screenTrack` - Screen share\n   - `nativeScreenProducerId` - Tauri-native screen capture ID\n\n3. **Consumer State**\n   - `remoteConsumers: Map<string, Consumer>` - Audio/video consumers\n   - `consumerIdByProducerId: Map<string, string>` - Lookup table\n\n4. **Audio Processing**\n   - `micLevelAudioContext, micLevelAnalyserNode, micLevelData` - For voice activity detection\n   - `remotePlaybackAudioContext` - Shared context for remote audio\n\n5. **Volume Control**\n   - `consumerGainNodes, consumerNormalizationNodes` - Per-user volume/compression\n   - `remoteAudioElements: Map<string, HTMLAudioElement>` - Audio playback elements\n\n6. **Metadata**\n   - `producerUsernameById, producerSourceById, producerRoutingModeById` - Track producer metadata\n   - `queuedProducerAnnouncements` - Queue producers until initialized\n\n7. **Health Monitoring**\n   - `transportHealthState` - ICE connection state\n   - `signalListenerInitialized` - Track media signal setup\n\n---\n\n### **2.3 Transport Initialization & Lifecycle**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts` (376 lines)**\n\n**Purpose:** WebRTC transport setup, connection monitoring, and cleanup\n\n**Key Functions:**\n\n1. **`initializeMediaTransports(channelId: string)`** (Line 246-341)\n   - Idempotent initialization with promise-based deduplication\n   - Requests RTP capabilities from server\n   - Creates mediasoup Device and Send/Recv transports\n   - Wires up event handlers (connect, produce, ICE monitoring)\n   - Starts local audio producer immediately\n   - Flushes queued producer announcements\n   - **Pattern: Robust re-entrant guard against multiple concurrent initializations**\n\n2. **`closeTransports()`** (Line 163-244)\n   - Comprehensive cleanup of all resources\n   - Stops all producers (mic, camera, screen) and their tracks\n   - Closes all consumers\n   - Cleans up device change listener\n   - Stops voice activity monitoring\n   - Disposes microphone processing pipeline\n   - **Pattern: Defensive cleanup - removes resources even if already null**\n\n3. **Transport Health Monitoring** (Line 76-83, 101-132)\n   - `updateTransportHealthFromIce()` - Aggregates send/recv transport states\n   - Disconnect recovery with 10-second timeout (Line 119-123)\n   - Notifies all subscribers on state change\n   - States: \"connected\", \"new\", \"closed\", \"disconnected\", \"failed\"\n   - Severity mapping for worst-state calculation\n\n4. **Event Handlers**\n   - `wireTransportConnect()` - DTLS parameter exchange\n   - `wireSendTransportProduce()` - Producer creation signaling\n   - `wireTransportConnectionStateMonitor()` - ICE monitoring with auto-recovery\n\n5. **Mute Functions**\n   - `setMicrophoneMuted(muted)` - Disables track + reports voice activity\n   - `setSpeakersMuted(muted)` - Mutes all remote audio elements\n\n**Issues Identified:**\n- No retry logic if initial transport creation fails\n- Single global `disconnectRecoveryTimer` could theoretically be overwritten\n- Transport state machine could have edge cases with rapid join/leave\n- Audio context resumption error handling is silent (no logs)\n\n---\n\n### **2.4 Producer Management (Sending Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts` (737 lines)**\n\n**Purpose:** Manage outgoing audio, camera, and screen share streams\n\n**Key Producers:**\n\n1. **Microphone Producer** - `startLocalAudioProducer()` (Line 143-223)\n   - Gets user media with constraints (noise suppression, echo cancellation)\n   - Creates processed microphone track via `createProcessedMicrophoneTrack()`\n   - Wraps track in mediasoup Producer\n   - Starts voice activity monitoring\n   - Handles channel switch during startup\n   - **Pattern: Careful track ownership - uses `stopTracks: false` to manage lifecycle separately**\n\n2. **Camera Producer** - `startLocalCameraProducer()` (Line 237-315)\n   - Gets video constraints via `cameraInputConstraint()`\n   - Fallback logic for device availability\n   - H.264 codec preference\n   - Produces with `stopTracks: false`\n   - Error normalization for user display\n\n3. **Screen Share - Two Modes:**\n   - **Browser Mode** - `startBrowserScreenProducer()` (Line 380-490)\n     - Uses `getDisplayMedia()` API\n     - Optional constraint application (resolution, FPS)\n     - Content hint for encoder optimization (motion vs detail)\n     - Codec preference for platform\n     - Bitrate configuration with encoder hints\n   \n   - **Native Tauri Mode** - `startNativeScreenProducer()` (Line 492-643)\n     - Only on Tauri runtime with sourceId selected\n     - Uses RTP sender backend (not WebRTC producer)\n     - H.264 codec only (for compatibility)\n     - Extensive codec negotiation & validation\n     - Fallback monitor (polling every 1s for encoder failures)\n     - Diagnostics reporting to server\n     - **Pattern: Graceful fallback with heartbeat monitoring**\n\n4. **Track Lifecycle**\n   - Cleanup functions: `stopAndReleaseCameraTracks()`, `stopAndReleaseScreenTracks()`\n   - Producer close events trigger automatic cleanup\n   - Track ended events trigger producer closure\n   - Channel switch guards to prevent orphaned producers\n\n5. **Microphone Processing Pipeline**\n   - Volume gain node (for outgoing volume control)\n   - Creates processed track from source\n   - Mute state applied to both source and processed tracks\n\n**Issues Identified:**\n- No timeout for producer creation (could hang if network fails)\n- Screen share codec selection logs to console in debug mode - could be verbose\n- Native capture fallback flag is per-session; user can't retry browser mode once native attempted\n- Multiple try-catch blocks could benefit from unified error logging\n- Producer stats logging `logScreenShareProducerStats()` only logs on screen share start, not continuous\n\n---\n\n### **2.5 Consumer Management (Receiving Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts` (382 lines)**\n\n**Purpose:** Create and manage consuming remote audio/video streams\n\n**Key Functions:**\n\n1. **`consumeRemoteProducer(channelId, producerId)`** (Line 166-295)\n   - Requests consumer from server\n   - Creates consumer via `recvTransport.consume()`\n   - **Audio Path:**\n     - Creates HTMLAudioElement\n     - Sets up audio processing chain: SourceNode → NormalizationCompressor → GainNode → Destination\n     - Applies per-user volume + global incoming volume\n     - Resumes consumer before playback\n     - Retry logic for `audio.play()` (500ms delay + second attempt)\n   - **Video Path:**\n     - Creates RemoteVideoTile entry\n     - Resumes consumer\n     - Queues for tile updates\n   - Event handlers for transport close and track ended\n\n2. **Audio Chain Architecture** (Line 225-244)\n   ```\n   SourceNode (raw consumer track)\n   → NormalizationNode (DynamicsCompressor)\n   → GainNode (per-user volume)\n   → Destination (playback)\n   ```\n   - Normalization threshold: -24dB, knee: 20dB, ratio: 3, attack: 3ms, release: 250ms\n   - Provides consistent volume across speakers\n   - Disabled when `voiceAutoLevelEnabled` is false\n\n3. **Volume Management**\n   - `updateUserGainNodes()` - Updates specific user's volume\n   - `updateIncomingVoiceGainNodes()` - Updates global incoming volume\n   - `updateVoiceNormalizationNodesEnabled()` - Toggle auto-leveling\n   - Per-user volume from settings store\n\n4. **Producer Queuing** - `queueOrConsumeProducer()` (Line 321-353)\n   - If not initialized yet, queues producer announcement\n   - On initialization complete, `flushQueuedProducerAnnouncements()` processes queue\n\n5. **Cleanup** - `disposeRemoteConsumer(consumerId)` (Line 120-164)\n   - Closes consumer\n   - Disconnects all audio nodes\n   - Removes audio element from DOM\n   - Cleans up metadata maps\n   - Possibly closes shared audio context if last consumer\n\n**Issues Identified:**\n- Audio play() retry uses hardcoded 500ms delay - no exponential backoff\n- No per-consumer timeout for requestMediaSignal - could hang indefinitely\n- Consumer track ended detection doesn't distinguish between normal end and network failure\n- NormalizationNode configuration recreated per consumer instead of module-level constant\n- No logging for consumer creation failures - silent error handling\n- Gain node value clamping (0-200%) happens in multiple places - duplication\n\n---\n\n### **2.6 Voice Activity Detection & Speaking Status**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts` (111 lines)**\n\n**Purpose:** Monitor microphone level and report speaking status\n\n**Key Metrics:**\n- FFT size: 512\n- Smoothing time constant: 0.85\n- RMS threshold: 0.04 (4%)\n- Speaking hold duration: 220ms (hold-over to avoid jitter)\n\n**Algorithm:**\n1. Analyser node performs FFT on incoming audio\n2. Calculates RMS (root mean square) of audio samples\n3. If RMS >= threshold AND not muted → set hold-until time\n4. Current time <= hold-until → report speaking=true\n5. Muting immediately reports speaking=false\n\n**Functions:**\n- `startMicLevelMonitoring()` - Creates audio context and starts RAF-based monitor loop\n- `stopMicLevelMonitoring()` - Cleanup and final speaking=false report\n\n**Issues Identified:**\n- Uses `requestAnimationFrame` for 60fps monitoring - unnecessary overhead\n- Should use fixed interval (e.g., 50ms) instead\n- `micSpeakingLastSent` is a boolean flag, not a full state - can't distinguish between not-yet-sent and sent-false\n- No jitter buffer - could spam speaking state changes\n\n---\n\n### **2.7 Microphone Processing Pipeline**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts` (104 lines)**\n\n**Purpose:** Apply outgoing volume control to microphone track\n\n**Architecture:**\n```\nUserMedia Stream\n  → SourceNode\n    → GainNode (volume)\n      → DestinationNode (processed track)\n```\n\n**Lifecycle:**\n- Single active session at a time\n- `createProcessedMicrophoneTrack()` - Creates new session with gain node\n- `activateMicrophoneProcessing()` - Sets session as active (disposes previous)\n- `updateOutgoingMicrophoneGain()` - Changes gain value in active session\n- `updateOutgoingMicrophoneMuted()` - Sets track.enabled on both source and processed\n\n**Issues Identified:**\n- Keeps original sourceTrack around - consumes extra resources\n- No cleanup callback - if active session set but never disposed, resources leak\n- Gain clamping function duplicated from consumers.ts\n- No validation that sourceTrack is still valid before using it\n\n---\n\n### **2.8 Media Signaling (WebSocket Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts` (178 lines)**\n\n**Purpose:** Request-response protocol for media operations (RTC negotiation, producer/consumer management)\n\n**Signal Actions:**\n- `get_router_rtp_capabilities` - Get server's codec capabilities\n- `create_webrtc_transport` - Create send/recv transport\n- `connect_webrtc_transport` - Exchange DTLS parameters\n- `media_produce` - Create producer\n- `media_close_producer` - Close producer\n- `media_consume` - Create consumer\n- `media_resume_consumer` - Resume consumer playback\n- `create_native_sender_session` - RTP sender setup (native capture)\n- `client_diagnostic` - Report native sender metrics\n\n**Request-Response Pattern:**\n- Each request gets unique ID: `media-${Date.now()}-${counter}`\n- 10-second timeout (Line 113-116)\n- Response matched to request by ID\n- Pending requests tracked in Map\n- Server can send unsolicited messages (new_producer, producer_closed, voice_activity)\n\n**Voice Activity Reporting:**\n- `reportVoiceActivity()` - Send speaking=true/false to server\n- Triggered by voice level monitoring\n\n**Diagnostics:**\n- `reportCodecDecision()` - Log codec selection decision\n- `reportNativeSenderDiagnostic()` - Report native sender status/errors\n\n**Issues Identified:**\n- Fixed 10-second timeout for all operations - some might need longer (network dependent)\n- No retry logic - first timeout = failure\n- PendingRequests could accumulate if responses never arrive (timeout cleanup exists, but requests are still lost)\n- No congestion detection - if many requests fail, no backpressure\n\n---\n\n### **2.9 Subscription System**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts` (122 lines)**\n\n**Purpose:** Publisher-subscriber pattern for media state changes\n\n**Subscribers:**\n1. `videoTilesSubscribers` - Remote camera/screen tiles\n2. `cameraStateSubscribers` - Local camera enabled/error/stream\n3. `screenStateSubscribers` - Local screen share enabled/error/stream/routingMode\n4. `transportHealthSubscribers` - Connection health state\n\n**Pattern:**\n- Each subscription function calls subscriber immediately with current state\n- Returns unsubscribe function\n- Used by `voice.ts` store to maintain reactive state\n\n**Issues Identified:**\n- No limits on subscriber count - potential memory leak if many subscriptions created\n- No deduplication - could call subscriber twice if subscribed twice\n- Subscribers called synchronously - blocking if callback is slow\n\n---\n\n### **2.10 Device Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts** (150+ lines)**\n\n**Purpose:** Enumerate and switch audio/video devices at runtime\n\n**Device Enumeration:**\n- `listAudioDevices()` - List microphones & speakers\n- `listCameraDevices()` - List cameras\n- Labels sorted alphabetically with fallback numbering\n\n**Device Selection:**\n- `setPreferredMicrophoneDevice()` - Hot-swap microphone\n  - Gets new user media\n  - Creates new processing session\n  - Replaces producer track if exists, or creates new producer\n  - Manages fallback if device unavailable\n  \n- `setPreferredCameraDevice()` - Hot-swap camera (partial implementation visible)\n- `setPreferredSpeakerDevice()` - Route speaker output\n  - Uses `HTMLAudioElement.setSinkId()` if supported\n  - Applied to all remote audio elements\n\n**Device Change Detection:**\n- `registerDeviceChangeListener()` - Fires when devices added/removed\n- Resets audio devices if current device disappears\n- Prevents duplicate registrations\n\n**Issues Identified:**\n- Device change listener doesn't distinguish between input/output changes\n- Hot-swap has no fallback if getRtpCapabilities changes (rare but possible)\n- Speaker routing set per-element, not globally - new consumers must be manually routed\n- Sorting is expensive on every enumeration - could cache\n\n---\n\n### **2.11 Constraints & Codec Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts` (97 lines)**\n\n**Audio Constraints:**\n```typescript\n{\n  deviceId: { exact: selectedDeviceId },\n  noiseSuppression: voiceNoiseSuppressionEnabled(),\n  echoCancellation: voiceEchoCancellationEnabled(),\n  channelCount: 1  // Mono\n}\n```\n- Uses browser supported constraints API\n- Graceful degradation if constraints unavailable\n\n**Video Constraints (Camera):**\n- Simple exact device ID constraint\n\n**Screen Share Constraints:**\n- Resolution: 720p (1280×720), 1080p (1920×1080), 1440p (2560×1440), 4k (3840×2160)\n- FPS: 30 or 60\n- displaySurface hint: \"monitor\" or \"window\"\n- contentHint: \"motion\" (>=60fps or app) or \"detail\"\n\n**Codec Selection:**\n- Screen share: H.264 > VP8 > VP9 (platform-independent, NVENC hardware support)\n- Native: H.264 only\n\n**Issues Identified:**\n- No support for audio bandwidth constraints\n- Screen share 4K resolution could be very expensive\n- No validation that requested FPS/resolution is supported before attempting\n\n---\n\n### **2.12 Error Handling**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts` (72 lines)**\n\n**Error Normalization:**\n\n1. **Camera Errors:**\n   - Permission denied → \"Camera access was denied...\"\n   - Not found → \"No camera device was found...\"\n   - Not readable/in use → \"Camera is unavailable or in use...\"\n   - Generic → Pass through error message\n\n2. **Screen Share Errors:**\n   - Permission denied → \"Screen share permission was denied...\"\n   - Not found → \"No shareable display source was found...\"\n   - Not readable → \"Screen sharing is unavailable or already in use...\"\n   - Generic → Pass through error message\n\n3. **Device Detection:**\n   - `isMissingDeviceError()` - Check if error is device-not-found\n\n**Issues Identified:**\n- Error messages are user-friendly but not actionable\n- No error codes - difficult to log/debug\n- Generic DOMException handling is catch-all at end\n\n---\n\n### **2.13 Native Screen Capture (Tauri)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/native.ts` (88 lines)**\n\n**Purpose:** Wrap Tauri native screen capture APIs\n\n**Functions:**\n- `listNativeCaptureSources()` - Enumerate windows/screens/apps\n- `nativeCodecCapabilities()` - Check available codecs\n- `startNativeCapture()` - Arm native capture service\n- `stopNativeCapture()` - Disarm service\n- `nativeCaptureStatus()` - Poll for live metrics\n\n**Fallback Monitor:**\n- Polling every 1s for encoder failures\n- Fallback reasons: \"degradation\", \"encoder_failure\", etc.\n- Auto-stops if fallback reason appears\n- Reports diagnostic event to server\n\n**Backend Selection:**\n- Reads encoder_backend (NVENC, OpenH264)\n- Tries requested backend, falls back to other\n- Extensive diagnostics in `NativeCaptureStatus`\n\n**Issues Identified:**\n- Hardcoded 1s poll interval - could miss rapid failures\n- Codec mime type validation string-matching (should use enum)\n- No timeout if native capture hangs\n\n---\n\n## **3. UI COMPONENTS**\n\n### **3.1 Voice Dock Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx` (131 lines)**\n\n**Purpose:** Main control panel for voice channel operations\n\n**Controls:**\n- Disconnect button\n- Mic mute toggle\n- Speaker mute toggle  \n- Camera enable/disable\n- Screen share enable/disable\n\n**Status Display:**\n- Connected channel name\n- Connection health (good/degraded/failed)\n- Health dot indicator + label\n- Camera/screen share error messages\n- Routing mode (SFU)\n\n**Native Debug Panel** (Tauri only, debug mode):\n- Frame queue stats\n- Encoder output rate\n- RTP packet counts\n- Queue backlog & drop counts\n- Encode latency\n- Codec info\n- Transport/producer health\n- Pressure metrics\n- Encoder backend info\n\n**Issues Identified:**\n- No tooltip for health states\n- Debug panel is text-heavy and cramped\n- Retry connection button shown but doesn't explain what will reconnect\n\n---\n\n### **3.2 Video Stage Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx` (78 lines)**\n\n**Purpose:** Display grid of video tiles (camera + screen share)\n\n**Layout:**\n- Local camera (if enabled) in grid\n- Local screen share (if enabled) in grid\n- Remote camera tiles (from videoTiles subscription)\n\n**Features:**\n- Auto-play video elements\n- Muted local streams\n- Username + source labels\n- CSS classes for styling (is-local, is-screen-share)\n\n**Issues Identified:**\n- No pagination/max tile limit (could become unwieldy with many participants)\n- No speaker highlight indicator\n- Order is arbitrary for remote tiles (relies on alphabetical sort in subscriptions.ts)\n- No click-to-focus or fullscreen\n\n---\n\n### **3.3 Voice Settings Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx` (110 lines)**\n\n**Purpose:** User-facing voice settings\n\n**Toggles:**\n- Noise suppression\n- Echo cancellation\n- Auto level incoming voices\n\n**Sliders:**\n- Incoming voice volume (0-200%)\n- Outgoing microphone volume (0-200%)\n\n**Issues Identified:**\n- No input validation (could receive invalid percentages)\n- Help text is generic, no device-specific guidance\n- Volume slider goes to 200% - could cause distortion\n\n---\n\n## **4. INTEGRATION WITH MAIN APPLICATION**\n\n### **4.1 ChannelList Component (Voice Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (1200+ lines)**\n\n**Key Voice Operations:**\n\n1. **Join Voice** - `joinVoiceChannel()`\n   - Sets state to \"joining\"\n   - Sends WebSocket message\n\n2. **Leave Voice** - `leaveVoiceChannel()`\n   - Sets state to \"leaving\"\n   - Sends WebSocket message\n\n3. **Toggle Mic** - `handleToggleMicMuted()`\n   - Updates mute state\n   - Calls `setMicrophoneMuted()`\n\n4. **Toggle Camera** - `handleToggleCamera()`\n   - Idempotent with pending state\n   - Calls `startLocalCameraProducer()` or `stopLocalCameraProducer()`\n   - Shows error toast on failure\n\n5. **Toggle Screen Share** - `handleToggleScreenShare()`\n   - Browser mode: Immediate `startLocalScreenProducer()`\n   - Tauri mode: Opens modal to select source, then starts\n   - Calls `stopLocalScreenProducer()` if already sharing\n\n6. **Voice Presence Events**\n   - `voice_joined` → Initialize transports, restore settings\n   - `voice_left` → Cleanup, reset state\n   - `voice_user_joined` → Play join cue, update participants\n   - `voice_user_left` → Play leave cue, update participants\n   - `voice_user_speaking` → Update speaking indicator\n   - `voice_presence_snapshot` → Initialize on startup\n\n7. **Error Handling**\n   - Error type message → Set action state to idle\n   - Network close → Show rejoin notice + cleanup\n\n8. **Cleanup on Unmount**\n   - Stop subscriptions\n   - Remove event listeners\n   - Clear timers\n   - Stop screen share preview\n\n**Issues Identified:**\n- Error message shown in toast but error details lost\n- No user confirmation for destructive actions (e.g., leaving voice)\n- Native metrics polling (1s interval) runs constantly when screen sharing - could drain battery\n\n---\n\n## **5. STATE FLOW DIAGRAM**\n\n```\nWebSocket Message (voice_joined)\n  ↓\nsetJoinedVoiceChannel(id)\n  ↓\ninitializeMediaTransports(id)\n  ├─ Request RTP capabilities\n  ├─ Load Device with capabilities\n  ├─ Create Send/Recv transports\n  ├─ Wire transport events\n  └─ startLocalAudioProducer()\n      ├─ getUserMedia() with constraints\n      ├─ createProcessedMicrophoneTrack() (gain node)\n      ├─ sendTransport.produce()\n      └─ startMicLevelMonitoring()\n        └─ RAF loop → Calculate RMS → reportVoiceActivity()\n  ├─ registerDeviceChangeListener()\n  └─ flushQueuedProducerAnnouncements()\n      └─ consumeRemoteProducer() for each queued\n\nOn new_producer signal\n  ├─ Record username, source, routingMode\n  └─ queueOrConsumeProducer() → consumeRemoteProducer()\n      ├─ Request consumer from server\n      ├─ Create consumer via recvTransport\n      ├─ If audio: Set up playback chain\n      │   ├─ Create HTMLAudioElement\n      │   ├─ SourceNode → NormalizationCompressor → GainNode → Destination\n      │   └─ audio.play()\n      └─ If video: Create VideoTile + subscribe UI\n\nWebSocket Message (voice_left)\n  ↓\ncleanupMediaTransports()\n  ├─ closeTransports()\n  │   ├─ Dispose all producers & tracks\n  │   ├─ Close all consumers\n  │   ├─ Dispose audio nodes & elements\n  │   └─ Close transports & device\n  └─ Reset all state signals\n```\n\n---\n\n## **6. DETAILED ISSUES & RECOMMENDATIONS**\n\n### **Critical Issues**\n\n1. **No Timeout on Transport Creation**\n   - **Location:** `initializeMediaTransports()` line 279\n   - **Issue:** If server hangs responding to capabilities request, initialization blocks indefinitely\n   - **Fix:** Add 5-second timeout to `requestMediaSignal()` calls in transport init\n\n2. **Silent Audio Play Failure Retry**\n   - **Location:** `consumers.ts` line 247-265\n   - **Issue:** If `audio.play()` fails twice, error is logged but not propagated\n   - **Impact:** User hears silence but no error toast\n   - **Fix:** Throw error after second failure, let caller handle\n\n3. **Microphone Processing Resource Leak**\n   - **Location:** `microphoneProcessing.ts`\n   - **Issue:** If `activateMicrophoneProcessing()` is called without prior cleanup, old session orphaned\n   - **Fix:** Explicit dispose call or use WeakMap for auto-cleanup\n\n4. **Voice Activity Detection Too Sensitive**\n   - **Location:** `voiceActivity.ts` line 77-78\n   - **Issue:** 220ms hold-over can miss natural speech pauses\n   - **Recommendation:** Use 300-400ms, or make configurable\n\n### **High Priority Issues**\n\n5. **Screen Share Fallback Stuck**\n   - **Location:** `producers.ts` line 680-685\n   - **Issue:** Once `nativeCaptureAttempted` set true, user can't retry browser mode\n   - **Fix:** Add UI button to reset flag, or prompt user\n\n6. **Transport Health Monitoring Race Condition**\n   - **Location:** `transports.ts` line 106-112\n   - **Issue:** Multiple transports closing in parallel could set state to wrong value\n   - **Fix:** Use sequence number or lock to ensure ordering\n\n7. **No Reconnection Logic**\n   - **Issue:** If WebSocket reconnects, media transports not re-established\n   - **Fix:** Add auto-reconnect on WS reconnect (currently relies on user clicking Retry)\n\n### **Medium Priority Issues**\n\n8. **Volume Clamping Duplicated**\n   - **Locations:** `consumers.ts` line 39-44, `microphoneProcessing.ts` line 10-15\n   - **Fix:** Export single function from utils module\n\n9. **Consumer Creation Timeout**\n   - **Location:** `consumers.ts` line 184\n   - **Issue:** No timeout on `requestMediaSignal(\"media_consume\")`\n   - **Fix:** Add shorter timeout (3-5s) for per-consumer requests\n\n10. **Device Change Listener Not De-Registered**\n    - **Location:** `transports.ts` line 168\n    - **Issue:** Listener registered in `initializeMediaTransports`, de-registered on close, but no guard\n    - **Fix:** Add state guard to prevent double de-registration\n\n### **Code Quality Issues**\n\n11. **Error Handling Inconsistency**\n    - Some code uses `console.warn`, some uses `console.error`, some uses throw\n    - **Fix:** Standardize on error boundary propagation\n\n12. **Missing JSDoc Comments**\n    - Complex functions like `consumeRemoteProducer` lack documentation\n    - **Fix:** Add JSDoc for public APIs\n\n13. **Magic Numbers**\n    - 10000ms timeout, 220ms hold, 512 FFT size, 0.04 threshold not documented\n    - **Fix:** Extract to named constants with comments\n\n---\n\n## **7. PERFORMANCE CONSIDERATIONS**\n\n1. **Audio Context Lifecycle**\n   - Creates multiple AudioContexts (mic level, remote playback, mic processing)\n   - Browser limits ~10 contexts max - current design uses 3 when at capacity\n   - **Safe but could be optimized:** Reuse single context for monitoring\n\n2. **Voice Activity Detection RAF Loop**\n   - Runs at 60fps (browser refresh rate)\n   - **Issue:** Overkill for voice activity (could be 20fps)\n   - **Fix:** Use 50ms setInterval instead\n\n3. **Storage of All Remote Audio Elements**\n   - `remoteAudioElements` map keeps reference to all audio elements\n   - **Potential issue:** Never cleaned from DOM, only disconnected\n   - **Fix:** Use WeakMap or actively remove elements\n\n4. **Native Sender Metrics Polling**\n   - 1-second interval polling from Rust backend\n   - **Cost:** Continuous IPC calls\n   - **Optimization:** Debounce to 2-3 seconds or on-demand\n\n---\n\n## **8. SECURITY CONSIDERATIONS**\n\n1. **Producer/Consumer Metadata**\n   - Username stored client-side in `producerUsernameById` Map\n   - **Risk:** Could be spoofed if network message forged\n   - **Mitigation:** Server validates all signaling messages\n\n2. **Codec Negotiation**\n   - Accepts codec from server without validation\n   - **Mitigation:** Limited set of supported codecs in device.rtpCapabilities\n\n3. **SinkId Device Selection**\n   - `setSinkId` could fail silently\n   - **Risk:** Audio routed to unexpected output\n   - **Mitigation:** Device selection is user-initiated\n\n---\n\n## **9. SUMMARY TABLE**\n\n| Component | Purpose | Lines | Key Pattern | Risk Level |\n|-----------|---------|-------|-------------|-----------|\n| voice.ts | Reactive state store | 413 | Solid.js signals | Low |\n| state.ts | Module-level state | 144 | Module exports | Low |\n| transports.ts | RTC setup/lifecycle | 376 | Idempotent init + cleanup | Medium |\n| producers.ts | Outgoing media | 737 | Track ownership mgmt | High |\n| consumers.ts | Incoming media | 382 | Audio processing chain | High |\n| voiceActivity.ts | Speaking detection | 111 | RAF-based monitoring | Medium |\n| microphoneProcessing.ts | Outgoing volume | 104 | Single active session | Medium |\n| signaling.ts | WebSocket protocol | 178 | Request-response | Medium |\n| subscriptions.ts | Publisher-subscriber | 122 | Observer pattern | Low |\n| devices.ts | Audio/video devices | 150+ | Hot-swap at runtime | High |\n| constraints.ts | Media constraints | 97 | Constraint generation | Low |\n| errors.ts | Error normalization | 72 | Error mapping | Low |\n| native.ts | Tauri integration | 88 | API wrapper | Medium |\n| VoiceDock.tsx | Control UI | 131 | Component | Low |\n| VideoStage.tsx | Video grid | 78 | Component | Low |\n| VoiceAudioPreferences.tsx | Settings UI | 110 | Component | Low |\n| ChannelList.tsx | Main integration | 1200+ | Orchestration | High |\n\n---\n\n## **10. FILE PATHS (ABSOLUTE)**\n\nAll voice-related files are located at:\n\n- `/home/guibibi/projects/yankcord/client/src/stores/voice.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/index.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/types.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/state.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/codecs.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/native.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media.ts` (re-export wrapper)\n- `/home/guibibi/projects/yankcord/client/src/api/nativeCapture.ts` (Tauri bindings)\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/ScreenShareModal.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (integration)\n- `/home/guibibi/projects/yankcord/client/src/utils/voiceCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/utils/audioCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/ws.ts` (WebSocket definitions)\n\nNative Tauri implementation:\n- `/home/guibibi/projects/yankcord/client/src-tauri/src/` (Rust backend for native capture)\n\nThis concludes the comprehensive exploration of the voice chat system on the client side.\n</output>"}]},"uuid":"2d1abb79-2d88-4c1a-95ae-c7b85e067c9b","timestamp":"2026-02-23T14:49:08.771Z","toolUseResult":{"retrieval_status":"success","task":{"task_id":"a4a521c","task_type":"local_agent","status":"completed","description":"Explore voice chat client code","output":"Perfect! Now I have a comprehensive view of the voice/audio/WebRTC system. Let me compile my findings:\n\n## Comprehensive Exploration of Voice Chat/WebRTC/Mediasoup Client Implementation\n\nBased on my thorough exploration of the client-side voice chat implementation in `/home/guibibi/projects/yankcord/client`, here's a detailed analysis:\n\n---\n\n## **1. ARCHITECTURE OVERVIEW**\n\nThe voice chat system uses **mediasoup-client** as the WebRTC library with an **SFU (Selective Forwarding Unit)** routing mode. It's a comprehensive implementation with client-side state management, audio/video processing, and native screen capture support via Tauri.\n\n---\n\n## **2. KEY COMPONENTS & FILES**\n\n### **2.1 State Management & Store** \n\n**File: `/home/guibibi/projects/yankcord/client/src/stores/voice.ts` (413 lines)**\n\n**Purpose:** Solid.js signal-based reactive state store for all voice-related state\n\n**Key Signals:**\n- `joinedVoiceChannelId` - Currently joined voice channel\n- `participantsByChannel` - Track which users are in each channel\n- `speakingByChannel` - Track speaking status per channel/user\n- `voiceActionState` - \"idle\", \"joining\", \"leaving\" state machine\n- `micMuted`, `speakerMuted` - Mute states\n- `cameraEnabled`, `screenShareEnabled` - Media activation states\n- `transportHealth` - Connection health state\n- `videoTiles` - Array of remote video streams\n\n**Key Functions:**\n- `applyVoiceSnapshot()` - Initialize voice presence\n- `applyVoiceJoined/Left/Speaking()` - Update participant state\n- `startVideoTilesSubscription()` / `startConnectionStatusSubscription()` - Subscribe to media state\n- `resetVoiceState()` - Clean slate when disconnecting\n- Health monitoring via `voiceHealthLevel()` that aggregates WebSocket and transport health\n\n**Issues Identified:**\n- No automatic cleanup on component unmount for subscriptions in some cases\n- Multiple unsubscribe refs that could leak if not properly managed\n\n---\n\n### **2.2 Media State Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/state.ts` (144 lines)**\n\n**Purpose:** Module-level state (not reactive) for mediasoup infrastructure\n\n**State Categories:**\n\n1. **Device & Transport**\n   - `device: Device | null` - mediasoup Device instance\n   - `sendTransport, recvTransport: Transport | null` - WebRTC transports\n\n2. **Producer State**\n   - `micProducer, micStream, micTrack` - Microphone\n   - `cameraProducer, cameraStream, cameraTrack` - Camera\n   - `screenProducer, screenStream, screenTrack` - Screen share\n   - `nativeScreenProducerId` - Tauri-native screen capture ID\n\n3. **Consumer State**\n   - `remoteConsumers: Map<string, Consumer>` - Audio/video consumers\n   - `consumerIdByProducerId: Map<string, string>` - Lookup table\n\n4. **Audio Processing**\n   - `micLevelAudioContext, micLevelAnalyserNode, micLevelData` - For voice activity detection\n   - `remotePlaybackAudioContext` - Shared context for remote audio\n\n5. **Volume Control**\n   - `consumerGainNodes, consumerNormalizationNodes` - Per-user volume/compression\n   - `remoteAudioElements: Map<string, HTMLAudioElement>` - Audio playback elements\n\n6. **Metadata**\n   - `producerUsernameById, producerSourceById, producerRoutingModeById` - Track producer metadata\n   - `queuedProducerAnnouncements` - Queue producers until initialized\n\n7. **Health Monitoring**\n   - `transportHealthState` - ICE connection state\n   - `signalListenerInitialized` - Track media signal setup\n\n---\n\n### **2.3 Transport Initialization & Lifecycle**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts` (376 lines)**\n\n**Purpose:** WebRTC transport setup, connection monitoring, and cleanup\n\n**Key Functions:**\n\n1. **`initializeMediaTransports(channelId: string)`** (Line 246-341)\n   - Idempotent initialization with promise-based deduplication\n   - Requests RTP capabilities from server\n   - Creates mediasoup Device and Send/Recv transports\n   - Wires up event handlers (connect, produce, ICE monitoring)\n   - Starts local audio producer immediately\n   - Flushes queued producer announcements\n   - **Pattern: Robust re-entrant guard against multiple concurrent initializations**\n\n2. **`closeTransports()`** (Line 163-244)\n   - Comprehensive cleanup of all resources\n   - Stops all producers (mic, camera, screen) and their tracks\n   - Closes all consumers\n   - Cleans up device change listener\n   - Stops voice activity monitoring\n   - Disposes microphone processing pipeline\n   - **Pattern: Defensive cleanup - removes resources even if already null**\n\n3. **Transport Health Monitoring** (Line 76-83, 101-132)\n   - `updateTransportHealthFromIce()` - Aggregates send/recv transport states\n   - Disconnect recovery with 10-second timeout (Line 119-123)\n   - Notifies all subscribers on state change\n   - States: \"connected\", \"new\", \"closed\", \"disconnected\", \"failed\"\n   - Severity mapping for worst-state calculation\n\n4. **Event Handlers**\n   - `wireTransportConnect()` - DTLS parameter exchange\n   - `wireSendTransportProduce()` - Producer creation signaling\n   - `wireTransportConnectionStateMonitor()` - ICE monitoring with auto-recovery\n\n5. **Mute Functions**\n   - `setMicrophoneMuted(muted)` - Disables track + reports voice activity\n   - `setSpeakersMuted(muted)` - Mutes all remote audio elements\n\n**Issues Identified:**\n- No retry logic if initial transport creation fails\n- Single global `disconnectRecoveryTimer` could theoretically be overwritten\n- Transport state machine could have edge cases with rapid join/leave\n- Audio context resumption error handling is silent (no logs)\n\n---\n\n### **2.4 Producer Management (Sending Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts` (737 lines)**\n\n**Purpose:** Manage outgoing audio, camera, and screen share streams\n\n**Key Producers:**\n\n1. **Microphone Producer** - `startLocalAudioProducer()` (Line 143-223)\n   - Gets user media with constraints (noise suppression, echo cancellation)\n   - Creates processed microphone track via `createProcessedMicrophoneTrack()`\n   - Wraps track in mediasoup Producer\n   - Starts voice activity monitoring\n   - Handles channel switch during startup\n   - **Pattern: Careful track ownership - uses `stopTracks: false` to manage lifecycle separately**\n\n2. **Camera Producer** - `startLocalCameraProducer()` (Line 237-315)\n   - Gets video constraints via `cameraInputConstraint()`\n   - Fallback logic for device availability\n   - H.264 codec preference\n   - Produces with `stopTracks: false`\n   - Error normalization for user display\n\n3. **Screen Share - Two Modes:**\n   - **Browser Mode** - `startBrowserScreenProducer()` (Line 380-490)\n     - Uses `getDisplayMedia()` API\n     - Optional constraint application (resolution, FPS)\n     - Content hint for encoder optimization (motion vs detail)\n     - Codec preference for platform\n     - Bitrate configuration with encoder hints\n   \n   - **Native Tauri Mode** - `startNativeScreenProducer()` (Line 492-643)\n     - Only on Tauri runtime with sourceId selected\n     - Uses RTP sender backend (not WebRTC producer)\n     - H.264 codec only (for compatibility)\n     - Extensive codec negotiation & validation\n     - Fallback monitor (polling every 1s for encoder failures)\n     - Diagnostics reporting to server\n     - **Pattern: Graceful fallback with heartbeat monitoring**\n\n4. **Track Lifecycle**\n   - Cleanup functions: `stopAndReleaseCameraTracks()`, `stopAndReleaseScreenTracks()`\n   - Producer close events trigger automatic cleanup\n   - Track ended events trigger producer closure\n   - Channel switch guards to prevent orphaned producers\n\n5. **Microphone Processing Pipeline**\n   - Volume gain node (for outgoing volume control)\n   - Creates processed track from source\n   - Mute state applied to both source and processed tracks\n\n**Issues Identified:**\n- No timeout for producer creation (could hang if network fails)\n- Screen share codec selection logs to console in debug mode - could be verbose\n- Native capture fallback flag is per-session; user can't retry browser mode once native attempted\n- Multiple try-catch blocks could benefit from unified error logging\n- Producer stats logging `logScreenShareProducerStats()` only logs on screen share start, not continuous\n\n---\n\n### **2.5 Consumer Management (Receiving Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts` (382 lines)**\n\n**Purpose:** Create and manage consuming remote audio/video streams\n\n**Key Functions:**\n\n1. **`consumeRemoteProducer(channelId, producerId)`** (Line 166-295)\n   - Requests consumer from server\n   - Creates consumer via `recvTransport.consume()`\n   - **Audio Path:**\n     - Creates HTMLAudioElement\n     - Sets up audio processing chain: SourceNode → NormalizationCompressor → GainNode → Destination\n     - Applies per-user volume + global incoming volume\n     - Resumes consumer before playback\n     - Retry logic for `audio.play()` (500ms delay + second attempt)\n   - **Video Path:**\n     - Creates RemoteVideoTile entry\n     - Resumes consumer\n     - Queues for tile updates\n   - Event handlers for transport close and track ended\n\n2. **Audio Chain Architecture** (Line 225-244)\n   ```\n   SourceNode (raw consumer track)\n   → NormalizationNode (DynamicsCompressor)\n   → GainNode (per-user volume)\n   → Destination (playback)\n   ```\n   - Normalization threshold: -24dB, knee: 20dB, ratio: 3, attack: 3ms, release: 250ms\n   - Provides consistent volume across speakers\n   - Disabled when `voiceAutoLevelEnabled` is false\n\n3. **Volume Management**\n   - `updateUserGainNodes()` - Updates specific user's volume\n   - `updateIncomingVoiceGainNodes()` - Updates global incoming volume\n   - `updateVoiceNormalizationNodesEnabled()` - Toggle auto-leveling\n   - Per-user volume from settings store\n\n4. **Producer Queuing** - `queueOrConsumeProducer()` (Line 321-353)\n   - If not initialized yet, queues producer announcement\n   - On initialization complete, `flushQueuedProducerAnnouncements()` processes queue\n\n5. **Cleanup** - `disposeRemoteConsumer(consumerId)` (Line 120-164)\n   - Closes consumer\n   - Disconnects all audio nodes\n   - Removes audio element from DOM\n   - Cleans up metadata maps\n   - Possibly closes shared audio context if last consumer\n\n**Issues Identified:**\n- Audio play() retry uses hardcoded 500ms delay - no exponential backoff\n- No per-consumer timeout for requestMediaSignal - could hang indefinitely\n- Consumer track ended detection doesn't distinguish between normal end and network failure\n- NormalizationNode configuration recreated per consumer instead of module-level constant\n- No logging for consumer creation failures - silent error handling\n- Gain node value clamping (0-200%) happens in multiple places - duplication\n\n---\n\n### **2.6 Voice Activity Detection & Speaking Status**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts` (111 lines)**\n\n**Purpose:** Monitor microphone level and report speaking status\n\n**Key Metrics:**\n- FFT size: 512\n- Smoothing time constant: 0.85\n- RMS threshold: 0.04 (4%)\n- Speaking hold duration: 220ms (hold-over to avoid jitter)\n\n**Algorithm:**\n1. Analyser node performs FFT on incoming audio\n2. Calculates RMS (root mean square) of audio samples\n3. If RMS >= threshold AND not muted → set hold-until time\n4. Current time <= hold-until → report speaking=true\n5. Muting immediately reports speaking=false\n\n**Functions:**\n- `startMicLevelMonitoring()` - Creates audio context and starts RAF-based monitor loop\n- `stopMicLevelMonitoring()` - Cleanup and final speaking=false report\n\n**Issues Identified:**\n- Uses `requestAnimationFrame` for 60fps monitoring - unnecessary overhead\n- Should use fixed interval (e.g., 50ms) instead\n- `micSpeakingLastSent` is a boolean flag, not a full state - can't distinguish between not-yet-sent and sent-false\n- No jitter buffer - could spam speaking state changes\n\n---\n\n### **2.7 Microphone Processing Pipeline**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts` (104 lines)**\n\n**Purpose:** Apply outgoing volume control to microphone track\n\n**Architecture:**\n```\nUserMedia Stream\n  → SourceNode\n    → GainNode (volume)\n      → DestinationNode (processed track)\n```\n\n**Lifecycle:**\n- Single active session at a time\n- `createProcessedMicrophoneTrack()` - Creates new session with gain node\n- `activateMicrophoneProcessing()` - Sets session as active (disposes previous)\n- `updateOutgoingMicrophoneGain()` - Changes gain value in active session\n- `updateOutgoingMicrophoneMuted()` - Sets track.enabled on both source and processed\n\n**Issues Identified:**\n- Keeps original sourceTrack around - consumes extra resources\n- No cleanup callback - if active session set but never disposed, resources leak\n- Gain clamping function duplicated from consumers.ts\n- No validation that sourceTrack is still valid before using it\n\n---\n\n### **2.8 Media Signaling (WebSocket Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts` (178 lines)**\n\n**Purpose:** Request-response protocol for media operations (RTC negotiation, producer/consumer management)\n\n**Signal Actions:**\n- `get_router_rtp_capabilities` - Get server's codec capabilities\n- `create_webrtc_transport` - Create send/recv transport\n- `connect_webrtc_transport` - Exchange DTLS parameters\n- `media_produce` - Create producer\n- `media_close_producer` - Close producer\n- `media_consume` - Create consumer\n- `media_resume_consumer` - Resume consumer playback\n- `create_native_sender_session` - RTP sender setup (native capture)\n- `client_diagnostic` - Report native sender metrics\n\n**Request-Response Pattern:**\n- Each request gets unique ID: `media-${Date.now()}-${counter}`\n- 10-second timeout (Line 113-116)\n- Response matched to request by ID\n- Pending requests tracked in Map\n- Server can send unsolicited messages (new_producer, producer_closed, voice_activity)\n\n**Voice Activity Reporting:**\n- `reportVoiceActivity()` - Send speaking=true/false to server\n- Triggered by voice level monitoring\n\n**Diagnostics:**\n- `reportCodecDecision()` - Log codec selection decision\n- `reportNativeSenderDiagnostic()` - Report native sender status/errors\n\n**Issues Identified:**\n- Fixed 10-second timeout for all operations - some might need longer (network dependent)\n- No retry logic - first timeout = failure\n- PendingRequests could accumulate if responses never arrive (timeout cleanup exists, but requests are still lost)\n- No congestion detection - if many requests fail, no backpressure\n\n---\n\n### **2.9 Subscription System**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts` (122 lines)**\n\n**Purpose:** Publisher-subscriber pattern for media state changes\n\n**Subscribers:**\n1. `videoTilesSubscribers` - Remote camera/screen tiles\n2. `cameraStateSubscribers` - Local camera enabled/error/stream\n3. `screenStateSubscribers` - Local screen share enabled/error/stream/routingMode\n4. `transportHealthSubscribers` - Connection health state\n\n**Pattern:**\n- Each subscription function calls subscriber immediately with current state\n- Returns unsubscribe function\n- Used by `voice.ts` store to maintain reactive state\n\n**Issues Identified:**\n- No limits on subscriber count - potential memory leak if many subscriptions created\n- No deduplication - could call subscriber twice if subscribed twice\n- Subscribers called synchronously - blocking if callback is slow\n\n---\n\n### **2.10 Device Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts** (150+ lines)**\n\n**Purpose:** Enumerate and switch audio/video devices at runtime\n\n**Device Enumeration:**\n- `listAudioDevices()` - List microphones & speakers\n- `listCameraDevices()` - List cameras\n- Labels sorted alphabetically with fallback numbering\n\n**Device Selection:**\n- `setPreferredMicrophoneDevice()` - Hot-swap microphone\n  - Gets new user media\n  - Creates new processing session\n  - Replaces producer track if exists, or creates new producer\n  - Manages fallback if device unavailable\n  \n- `setPreferredCameraDevice()` - Hot-swap camera (partial implementation visible)\n- `setPreferredSpeakerDevice()` - Route speaker output\n  - Uses `HTMLAudioElement.setSinkId()` if supported\n  - Applied to all remote audio elements\n\n**Device Change Detection:**\n- `registerDeviceChangeListener()` - Fires when devices added/removed\n- Resets audio devices if current device disappears\n- Prevents duplicate registrations\n\n**Issues Identified:**\n- Device change listener doesn't distinguish between input/output changes\n- Hot-swap has no fallback if getRtpCapabilities changes (rare but possible)\n- Speaker routing set per-element, not globally - new consumers must be manually routed\n- Sorting is expensive on every enumeration - could cache\n\n---\n\n### **2.11 Constraints & Codec Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts` (97 lines)**\n\n**Audio Constraints:**\n```typescript\n{\n  deviceId: { exact: selectedDeviceId },\n  noiseSuppression: voiceNoiseSuppressionEnabled(),\n  echoCancellation: voiceEchoCancellationEnabled(),\n  channelCount: 1  // Mono\n}\n```\n- Uses browser supported constraints API\n- Graceful degradation if constraints unavailable\n\n**Video Constraints (Camera):**\n- Simple exact device ID constraint\n\n**Screen Share Constraints:**\n- Resolution: 720p (1280×720), 1080p (1920×1080), 1440p (2560×1440), 4k (3840×2160)\n- FPS: 30 or 60\n- displaySurface hint: \"monitor\" or \"window\"\n- contentHint: \"motion\" (>=60fps or app) or \"detail\"\n\n**Codec Selection:**\n- Screen share: H.264 > VP8 > VP9 (platform-independent, NVENC hardware support)\n- Native: H.264 only\n\n**Issues Identified:**\n- No support for audio bandwidth constraints\n- Screen share 4K resolution could be very expensive\n- No validation that requested FPS/resolution is supported before attempting\n\n---\n\n### **2.12 Error Handling**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts` (72 lines)**\n\n**Error Normalization:**\n\n1. **Camera Errors:**\n   - Permission denied → \"Camera access was denied...\"\n   - Not found → \"No camera device was found...\"\n   - Not readable/in use → \"Camera is unavailable or in use...\"\n   - Generic → Pass through error message\n\n2. **Screen Share Errors:**\n   - Permission denied → \"Screen share permission was denied...\"\n   - Not found → \"No shareable display source was found...\"\n   - Not readable → \"Screen sharing is unavailable or already in use...\"\n   - Generic → Pass through error message\n\n3. **Device Detection:**\n   - `isMissingDeviceError()` - Check if error is device-not-found\n\n**Issues Identified:**\n- Error messages are user-friendly but not actionable\n- No error codes - difficult to log/debug\n- Generic DOMException handling is catch-all at end\n\n---\n\n### **2.13 Native Screen Capture (Tauri)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/native.ts` (88 lines)**\n\n**Purpose:** Wrap Tauri native screen capture APIs\n\n**Functions:**\n- `listNativeCaptureSources()` - Enumerate windows/screens/apps\n- `nativeCodecCapabilities()` - Check available codecs\n- `startNativeCapture()` - Arm native capture service\n- `stopNativeCapture()` - Disarm service\n- `nativeCaptureStatus()` - Poll for live metrics\n\n**Fallback Monitor:**\n- Polling every 1s for encoder failures\n- Fallback reasons: \"degradation\", \"encoder_failure\", etc.\n- Auto-stops if fallback reason appears\n- Reports diagnostic event to server\n\n**Backend Selection:**\n- Reads encoder_backend (NVENC, OpenH264)\n- Tries requested backend, falls back to other\n- Extensive diagnostics in `NativeCaptureStatus`\n\n**Issues Identified:**\n- Hardcoded 1s poll interval - could miss rapid failures\n- Codec mime type validation string-matching (should use enum)\n- No timeout if native capture hangs\n\n---\n\n## **3. UI COMPONENTS**\n\n### **3.1 Voice Dock Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx` (131 lines)**\n\n**Purpose:** Main control panel for voice channel operations\n\n**Controls:**\n- Disconnect button\n- Mic mute toggle\n- Speaker mute toggle  \n- Camera enable/disable\n- Screen share enable/disable\n\n**Status Display:**\n- Connected channel name\n- Connection health (good/degraded/failed)\n- Health dot indicator + label\n- Camera/screen share error messages\n- Routing mode (SFU)\n\n**Native Debug Panel** (Tauri only, debug mode):\n- Frame queue stats\n- Encoder output rate\n- RTP packet counts\n- Queue backlog & drop counts\n- Encode latency\n- Codec info\n- Transport/producer health\n- Pressure metrics\n- Encoder backend info\n\n**Issues Identified:**\n- No tooltip for health states\n- Debug panel is text-heavy and cramped\n- Retry connection button shown but doesn't explain what will reconnect\n\n---\n\n### **3.2 Video Stage Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx` (78 lines)**\n\n**Purpose:** Display grid of video tiles (camera + screen share)\n\n**Layout:**\n- Local camera (if enabled) in grid\n- Local screen share (if enabled) in grid\n- Remote camera tiles (from videoTiles subscription)\n\n**Features:**\n- Auto-play video elements\n- Muted local streams\n- Username + source labels\n- CSS classes for styling (is-local, is-screen-share)\n\n**Issues Identified:**\n- No pagination/max tile limit (could become unwieldy with many participants)\n- No speaker highlight indicator\n- Order is arbitrary for remote tiles (relies on alphabetical sort in subscriptions.ts)\n- No click-to-focus or fullscreen\n\n---\n\n### **3.3 Voice Settings Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx` (110 lines)**\n\n**Purpose:** User-facing voice settings\n\n**Toggles:**\n- Noise suppression\n- Echo cancellation\n- Auto level incoming voices\n\n**Sliders:**\n- Incoming voice volume (0-200%)\n- Outgoing microphone volume (0-200%)\n\n**Issues Identified:**\n- No input validation (could receive invalid percentages)\n- Help text is generic, no device-specific guidance\n- Volume slider goes to 200% - could cause distortion\n\n---\n\n## **4. INTEGRATION WITH MAIN APPLICATION**\n\n### **4.1 ChannelList Component (Voice Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (1200+ lines)**\n\n**Key Voice Operations:**\n\n1. **Join Voice** - `joinVoiceChannel()`\n   - Sets state to \"joining\"\n   - Sends WebSocket message\n\n2. **Leave Voice** - `leaveVoiceChannel()`\n   - Sets state to \"leaving\"\n   - Sends WebSocket message\n\n3. **Toggle Mic** - `handleToggleMicMuted()`\n   - Updates mute state\n   - Calls `setMicrophoneMuted()`\n\n4. **Toggle Camera** - `handleToggleCamera()`\n   - Idempotent with pending state\n   - Calls `startLocalCameraProducer()` or `stopLocalCameraProducer()`\n   - Shows error toast on failure\n\n5. **Toggle Screen Share** - `handleToggleScreenShare()`\n   - Browser mode: Immediate `startLocalScreenProducer()`\n   - Tauri mode: Opens modal to select source, then starts\n   - Calls `stopLocalScreenProducer()` if already sharing\n\n6. **Voice Presence Events**\n   - `voice_joined` → Initialize transports, restore settings\n   - `voice_left` → Cleanup, reset state\n   - `voice_user_joined` → Play join cue, update participants\n   - `voice_user_left` → Play leave cue, update participants\n   - `voice_user_speaking` → Update speaking indicator\n   - `voice_presence_snapshot` → Initialize on startup\n\n7. **Error Handling**\n   - Error type message → Set action state to idle\n   - Network close → Show rejoin notice + cleanup\n\n8. **Cleanup on Unmount**\n   - Stop subscriptions\n   - Remove event listeners\n   - Clear timers\n   - Stop screen share preview\n\n**Issues Identified:**\n- Error message shown in toast but error details lost\n- No user confirmation for destructive actions (e.g., leaving voice)\n- Native metrics polling (1s interval) runs constantly when screen sharing - could drain battery\n\n---\n\n## **5. STATE FLOW DIAGRAM**\n\n```\nWebSocket Message (voice_joined)\n  ↓\nsetJoinedVoiceChannel(id)\n  ↓\ninitializeMediaTransports(id)\n  ├─ Request RTP capabilities\n  ├─ Load Device with capabilities\n  ├─ Create Send/Recv transports\n  ├─ Wire transport events\n  └─ startLocalAudioProducer()\n      ├─ getUserMedia() with constraints\n      ├─ createProcessedMicrophoneTrack() (gain node)\n      ├─ sendTransport.produce()\n      └─ startMicLevelMonitoring()\n        └─ RAF loop → Calculate RMS → reportVoiceActivity()\n  ├─ registerDeviceChangeListener()\n  └─ flushQueuedProducerAnnouncements()\n      └─ consumeRemoteProducer() for each queued\n\nOn new_producer signal\n  ├─ Record username, source, routingMode\n  └─ queueOrConsumeProducer() → consumeRemoteProducer()\n      ├─ Request consumer from server\n      ├─ Create consumer via recvTransport\n      ├─ If audio: Set up playback chain\n      │   ├─ Create HTMLAudioElement\n      │   ├─ SourceNode → NormalizationCompressor → GainNode → Destination\n      │   └─ audio.play()\n      └─ If video: Create VideoTile + subscribe UI\n\nWebSocket Message (voice_left)\n  ↓\ncleanupMediaTransports()\n  ├─ closeTransports()\n  │   ├─ Dispose all producers & tracks\n  │   ├─ Close all consumers\n  │   ├─ Dispose audio nodes & elements\n  │   └─ Close transports & device\n  └─ Reset all state signals\n```\n\n---\n\n## **6. DETAILED ISSUES & RECOMMENDATIONS**\n\n### **Critical Issues**\n\n1. **No Timeout on Transport Creation**\n   - **Location:** `initializeMediaTransports()` line 279\n   - **Issue:** If server hangs responding to capabilities request, initialization blocks indefinitely\n   - **Fix:** Add 5-second timeout to `requestMediaSignal()` calls in transport init\n\n2. **Silent Audio Play Failure Retry**\n   - **Location:** `consumers.ts` line 247-265\n   - **Issue:** If `audio.play()` fails twice, error is logged but not propagated\n   - **Impact:** User hears silence but no error toast\n   - **Fix:** Throw error after second failure, let caller handle\n\n3. **Microphone Processing Resource Leak**\n   - **Location:** `microphoneProcessing.ts`\n   - **Issue:** If `activateMicrophoneProcessing()` is called without prior cleanup, old session orphaned\n   - **Fix:** Explicit dispose call or use WeakMap for auto-cleanup\n\n4. **Voice Activity Detection Too Sensitive**\n   - **Location:** `voiceActivity.ts` line 77-78\n   - **Issue:** 220ms hold-over can miss natural speech pauses\n   - **Recommendation:** Use 300-400ms, or make configurable\n\n### **High Priority Issues**\n\n5. **Screen Share Fallback Stuck**\n   - **Location:** `producers.ts` line 680-685\n   - **Issue:** Once `nativeCaptureAttempted` set true, user can't retry browser mode\n   - **Fix:** Add UI button to reset flag, or prompt user\n\n6. **Transport Health Monitoring Race Condition**\n   - **Location:** `transports.ts` line 106-112\n   - **Issue:** Multiple transports closing in parallel could set state to wrong value\n   - **Fix:** Use sequence number or lock to ensure ordering\n\n7. **No Reconnection Logic**\n   - **Issue:** If WebSocket reconnects, media transports not re-established\n   - **Fix:** Add auto-reconnect on WS reconnect (currently relies on user clicking Retry)\n\n### **Medium Priority Issues**\n\n8. **Volume Clamping Duplicated**\n   - **Locations:** `consumers.ts` line 39-44, `microphoneProcessing.ts` line 10-15\n   - **Fix:** Export single function from utils module\n\n9. **Consumer Creation Timeout**\n   - **Location:** `consumers.ts` line 184\n   - **Issue:** No timeout on `requestMediaSignal(\"media_consume\")`\n   - **Fix:** Add shorter timeout (3-5s) for per-consumer requests\n\n10. **Device Change Listener Not De-Registered**\n    - **Location:** `transports.ts` line 168\n    - **Issue:** Listener registered in `initializeMediaTransports`, de-registered on close, but no guard\n    - **Fix:** Add state guard to prevent double de-registration\n\n### **Code Quality Issues**\n\n11. **Error Handling Inconsistency**\n    - Some code uses `console.warn`, some uses `console.error`, some uses throw\n    - **Fix:** Standardize on error boundary propagation\n\n12. **Missing JSDoc Comments**\n    - Complex functions like `consumeRemoteProducer` lack documentation\n    - **Fix:** Add JSDoc for public APIs\n\n13. **Magic Numbers**\n    - 10000ms timeout, 220ms hold, 512 FFT size, 0.04 threshold not documented\n    - **Fix:** Extract to named constants with comments\n\n---\n\n## **7. PERFORMANCE CONSIDERATIONS**\n\n1. **Audio Context Lifecycle**\n   - Creates multiple AudioContexts (mic level, remote playback, mic processing)\n   - Browser limits ~10 contexts max - current design uses 3 when at capacity\n   - **Safe but could be optimized:** Reuse single context for monitoring\n\n2. **Voice Activity Detection RAF Loop**\n   - Runs at 60fps (browser refresh rate)\n   - **Issue:** Overkill for voice activity (could be 20fps)\n   - **Fix:** Use 50ms setInterval instead\n\n3. **Storage of All Remote Audio Elements**\n   - `remoteAudioElements` map keeps reference to all audio elements\n   - **Potential issue:** Never cleaned from DOM, only disconnected\n   - **Fix:** Use WeakMap or actively remove elements\n\n4. **Native Sender Metrics Polling**\n   - 1-second interval polling from Rust backend\n   - **Cost:** Continuous IPC calls\n   - **Optimization:** Debounce to 2-3 seconds or on-demand\n\n---\n\n## **8. SECURITY CONSIDERATIONS**\n\n1. **Producer/Consumer Metadata**\n   - Username stored client-side in `producerUsernameById` Map\n   - **Risk:** Could be spoofed if network message forged\n   - **Mitigation:** Server validates all signaling messages\n\n2. **Codec Negotiation**\n   - Accepts codec from server without validation\n   - **Mitigation:** Limited set of supported codecs in device.rtpCapabilities\n\n3. **SinkId Device Selection**\n   - `setSinkId` could fail silently\n   - **Risk:** Audio routed to unexpected output\n   - **Mitigation:** Device selection is user-initiated\n\n---\n\n## **9. SUMMARY TABLE**\n\n| Component | Purpose | Lines | Key Pattern | Risk Level |\n|-----------|---------|-------|-------------|-----------|\n| voice.ts | Reactive state store | 413 | Solid.js signals | Low |\n| state.ts | Module-level state | 144 | Module exports | Low |\n| transports.ts | RTC setup/lifecycle | 376 | Idempotent init + cleanup | Medium |\n| producers.ts | Outgoing media | 737 | Track ownership mgmt | High |\n| consumers.ts | Incoming media | 382 | Audio processing chain | High |\n| voiceActivity.ts | Speaking detection | 111 | RAF-based monitoring | Medium |\n| microphoneProcessing.ts | Outgoing volume | 104 | Single active session | Medium |\n| signaling.ts | WebSocket protocol | 178 | Request-response | Medium |\n| subscriptions.ts | Publisher-subscriber | 122 | Observer pattern | Low |\n| devices.ts | Audio/video devices | 150+ | Hot-swap at runtime | High |\n| constraints.ts | Media constraints | 97 | Constraint generation | Low |\n| errors.ts | Error normalization | 72 | Error mapping | Low |\n| native.ts | Tauri integration | 88 | API wrapper | Medium |\n| VoiceDock.tsx | Control UI | 131 | Component | Low |\n| VideoStage.tsx | Video grid | 78 | Component | Low |\n| VoiceAudioPreferences.tsx | Settings UI | 110 | Component | Low |\n| ChannelList.tsx | Main integration | 1200+ | Orchestration | High |\n\n---\n\n## **10. FILE PATHS (ABSOLUTE)**\n\nAll voice-related files are located at:\n\n- `/home/guibibi/projects/yankcord/client/src/stores/voice.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/index.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/types.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/state.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/codecs.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/native.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media.ts` (re-export wrapper)\n- `/home/guibibi/projects/yankcord/client/src/api/nativeCapture.ts` (Tauri bindings)\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/ScreenShareModal.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (integration)\n- `/home/guibibi/projects/yankcord/client/src/utils/voiceCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/utils/audioCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/ws.ts` (WebSocket definitions)\n\nNative Tauri implementation:\n- `/home/guibibi/projects/yankcord/client/src-tauri/src/` (Rust backend for native capture)\n\nThis concludes the comprehensive exploration of the voice chat system on the client side.","prompt":"Thoroughly explore the voice chat / audio / WebRTC / mediasoup related code in the CLIENT side of this project. The project is at /home/guibibi/projects/yankcord.\n\nLook in client/ directory for:\n1. All voice chat related components, hooks, utilities, services\n2. WebRTC / mediasoup-client integration code\n3. Voice state management (stores, contexts, signals)\n4. UI components for voice channels, voice controls, mute/deafen, etc.\n5. How audio streams are handled (producing, consuming, track management)\n6. Connection lifecycle (join, leave, reconnect logic)\n7. Any Tauri-specific voice integration in client/ or a separate tauri/ directory\n\nSearch broadly using patterns like: voice, audio, webrtc, mediasoup, rtc, transport, producer, consumer, track, mute, deafen, speaking, call, channel.\n\nFor each file found, read it fully and provide:\n- File path and purpose\n- Key functions/components and what they do\n- Any issues, bugs, anti-patterns, or improvements you notice\n- How it connects to other parts of the system\n\nBe very thorough - read every relevant file completely.","result":"Perfect! Now I have a comprehensive view of the voice/audio/WebRTC system. Let me compile my findings:\n\n## Comprehensive Exploration of Voice Chat/WebRTC/Mediasoup Client Implementation\n\nBased on my thorough exploration of the client-side voice chat implementation in `/home/guibibi/projects/yankcord/client`, here's a detailed analysis:\n\n---\n\n## **1. ARCHITECTURE OVERVIEW**\n\nThe voice chat system uses **mediasoup-client** as the WebRTC library with an **SFU (Selective Forwarding Unit)** routing mode. It's a comprehensive implementation with client-side state management, audio/video processing, and native screen capture support via Tauri.\n\n---\n\n## **2. KEY COMPONENTS & FILES**\n\n### **2.1 State Management & Store** \n\n**File: `/home/guibibi/projects/yankcord/client/src/stores/voice.ts` (413 lines)**\n\n**Purpose:** Solid.js signal-based reactive state store for all voice-related state\n\n**Key Signals:**\n- `joinedVoiceChannelId` - Currently joined voice channel\n- `participantsByChannel` - Track which users are in each channel\n- `speakingByChannel` - Track speaking status per channel/user\n- `voiceActionState` - \"idle\", \"joining\", \"leaving\" state machine\n- `micMuted`, `speakerMuted` - Mute states\n- `cameraEnabled`, `screenShareEnabled` - Media activation states\n- `transportHealth` - Connection health state\n- `videoTiles` - Array of remote video streams\n\n**Key Functions:**\n- `applyVoiceSnapshot()` - Initialize voice presence\n- `applyVoiceJoined/Left/Speaking()` - Update participant state\n- `startVideoTilesSubscription()` / `startConnectionStatusSubscription()` - Subscribe to media state\n- `resetVoiceState()` - Clean slate when disconnecting\n- Health monitoring via `voiceHealthLevel()` that aggregates WebSocket and transport health\n\n**Issues Identified:**\n- No automatic cleanup on component unmount for subscriptions in some cases\n- Multiple unsubscribe refs that could leak if not properly managed\n\n---\n\n### **2.2 Media State Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/state.ts` (144 lines)**\n\n**Purpose:** Module-level state (not reactive) for mediasoup infrastructure\n\n**State Categories:**\n\n1. **Device & Transport**\n   - `device: Device | null` - mediasoup Device instance\n   - `sendTransport, recvTransport: Transport | null` - WebRTC transports\n\n2. **Producer State**\n   - `micProducer, micStream, micTrack` - Microphone\n   - `cameraProducer, cameraStream, cameraTrack` - Camera\n   - `screenProducer, screenStream, screenTrack` - Screen share\n   - `nativeScreenProducerId` - Tauri-native screen capture ID\n\n3. **Consumer State**\n   - `remoteConsumers: Map<string, Consumer>` - Audio/video consumers\n   - `consumerIdByProducerId: Map<string, string>` - Lookup table\n\n4. **Audio Processing**\n   - `micLevelAudioContext, micLevelAnalyserNode, micLevelData` - For voice activity detection\n   - `remotePlaybackAudioContext` - Shared context for remote audio\n\n5. **Volume Control**\n   - `consumerGainNodes, consumerNormalizationNodes` - Per-user volume/compression\n   - `remoteAudioElements: Map<string, HTMLAudioElement>` - Audio playback elements\n\n6. **Metadata**\n   - `producerUsernameById, producerSourceById, producerRoutingModeById` - Track producer metadata\n   - `queuedProducerAnnouncements` - Queue producers until initialized\n\n7. **Health Monitoring**\n   - `transportHealthState` - ICE connection state\n   - `signalListenerInitialized` - Track media signal setup\n\n---\n\n### **2.3 Transport Initialization & Lifecycle**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts` (376 lines)**\n\n**Purpose:** WebRTC transport setup, connection monitoring, and cleanup\n\n**Key Functions:**\n\n1. **`initializeMediaTransports(channelId: string)`** (Line 246-341)\n   - Idempotent initialization with promise-based deduplication\n   - Requests RTP capabilities from server\n   - Creates mediasoup Device and Send/Recv transports\n   - Wires up event handlers (connect, produce, ICE monitoring)\n   - Starts local audio producer immediately\n   - Flushes queued producer announcements\n   - **Pattern: Robust re-entrant guard against multiple concurrent initializations**\n\n2. **`closeTransports()`** (Line 163-244)\n   - Comprehensive cleanup of all resources\n   - Stops all producers (mic, camera, screen) and their tracks\n   - Closes all consumers\n   - Cleans up device change listener\n   - Stops voice activity monitoring\n   - Disposes microphone processing pipeline\n   - **Pattern: Defensive cleanup - removes resources even if already null**\n\n3. **Transport Health Monitoring** (Line 76-83, 101-132)\n   - `updateTransportHealthFromIce()` - Aggregates send/recv transport states\n   - Disconnect recovery with 10-second timeout (Line 119-123)\n   - Notifies all subscribers on state change\n   - States: \"connected\", \"new\", \"closed\", \"disconnected\", \"failed\"\n   - Severity mapping for worst-state calculation\n\n4. **Event Handlers**\n   - `wireTransportConnect()` - DTLS parameter exchange\n   - `wireSendTransportProduce()` - Producer creation signaling\n   - `wireTransportConnectionStateMonitor()` - ICE monitoring with auto-recovery\n\n5. **Mute Functions**\n   - `setMicrophoneMuted(muted)` - Disables track + reports voice activity\n   - `setSpeakersMuted(muted)` - Mutes all remote audio elements\n\n**Issues Identified:**\n- No retry logic if initial transport creation fails\n- Single global `disconnectRecoveryTimer` could theoretically be overwritten\n- Transport state machine could have edge cases with rapid join/leave\n- Audio context resumption error handling is silent (no logs)\n\n---\n\n### **2.4 Producer Management (Sending Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts` (737 lines)**\n\n**Purpose:** Manage outgoing audio, camera, and screen share streams\n\n**Key Producers:**\n\n1. **Microphone Producer** - `startLocalAudioProducer()` (Line 143-223)\n   - Gets user media with constraints (noise suppression, echo cancellation)\n   - Creates processed microphone track via `createProcessedMicrophoneTrack()`\n   - Wraps track in mediasoup Producer\n   - Starts voice activity monitoring\n   - Handles channel switch during startup\n   - **Pattern: Careful track ownership - uses `stopTracks: false` to manage lifecycle separately**\n\n2. **Camera Producer** - `startLocalCameraProducer()` (Line 237-315)\n   - Gets video constraints via `cameraInputConstraint()`\n   - Fallback logic for device availability\n   - H.264 codec preference\n   - Produces with `stopTracks: false`\n   - Error normalization for user display\n\n3. **Screen Share - Two Modes:**\n   - **Browser Mode** - `startBrowserScreenProducer()` (Line 380-490)\n     - Uses `getDisplayMedia()` API\n     - Optional constraint application (resolution, FPS)\n     - Content hint for encoder optimization (motion vs detail)\n     - Codec preference for platform\n     - Bitrate configuration with encoder hints\n   \n   - **Native Tauri Mode** - `startNativeScreenProducer()` (Line 492-643)\n     - Only on Tauri runtime with sourceId selected\n     - Uses RTP sender backend (not WebRTC producer)\n     - H.264 codec only (for compatibility)\n     - Extensive codec negotiation & validation\n     - Fallback monitor (polling every 1s for encoder failures)\n     - Diagnostics reporting to server\n     - **Pattern: Graceful fallback with heartbeat monitoring**\n\n4. **Track Lifecycle**\n   - Cleanup functions: `stopAndReleaseCameraTracks()`, `stopAndReleaseScreenTracks()`\n   - Producer close events trigger automatic cleanup\n   - Track ended events trigger producer closure\n   - Channel switch guards to prevent orphaned producers\n\n5. **Microphone Processing Pipeline**\n   - Volume gain node (for outgoing volume control)\n   - Creates processed track from source\n   - Mute state applied to both source and processed tracks\n\n**Issues Identified:**\n- No timeout for producer creation (could hang if network fails)\n- Screen share codec selection logs to console in debug mode - could be verbose\n- Native capture fallback flag is per-session; user can't retry browser mode once native attempted\n- Multiple try-catch blocks could benefit from unified error logging\n- Producer stats logging `logScreenShareProducerStats()` only logs on screen share start, not continuous\n\n---\n\n### **2.5 Consumer Management (Receiving Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts` (382 lines)**\n\n**Purpose:** Create and manage consuming remote audio/video streams\n\n**Key Functions:**\n\n1. **`consumeRemoteProducer(channelId, producerId)`** (Line 166-295)\n   - Requests consumer from server\n   - Creates consumer via `recvTransport.consume()`\n   - **Audio Path:**\n     - Creates HTMLAudioElement\n     - Sets up audio processing chain: SourceNode → NormalizationCompressor → GainNode → Destination\n     - Applies per-user volume + global incoming volume\n     - Resumes consumer before playback\n     - Retry logic for `audio.play()` (500ms delay + second attempt)\n   - **Video Path:**\n     - Creates RemoteVideoTile entry\n     - Resumes consumer\n     - Queues for tile updates\n   - Event handlers for transport close and track ended\n\n2. **Audio Chain Architecture** (Line 225-244)\n   ```\n   SourceNode (raw consumer track)\n   → NormalizationNode (DynamicsCompressor)\n   → GainNode (per-user volume)\n   → Destination (playback)\n   ```\n   - Normalization threshold: -24dB, knee: 20dB, ratio: 3, attack: 3ms, release: 250ms\n   - Provides consistent volume across speakers\n   - Disabled when `voiceAutoLevelEnabled` is false\n\n3. **Volume Management**\n   - `updateUserGainNodes()` - Updates specific user's volume\n   - `updateIncomingVoiceGainNodes()` - Updates global incoming volume\n   - `updateVoiceNormalizationNodesEnabled()` - Toggle auto-leveling\n   - Per-user volume from settings store\n\n4. **Producer Queuing** - `queueOrConsumeProducer()` (Line 321-353)\n   - If not initialized yet, queues producer announcement\n   - On initialization complete, `flushQueuedProducerAnnouncements()` processes queue\n\n5. **Cleanup** - `disposeRemoteConsumer(consumerId)` (Line 120-164)\n   - Closes consumer\n   - Disconnects all audio nodes\n   - Removes audio element from DOM\n   - Cleans up metadata maps\n   - Possibly closes shared audio context if last consumer\n\n**Issues Identified:**\n- Audio play() retry uses hardcoded 500ms delay - no exponential backoff\n- No per-consumer timeout for requestMediaSignal - could hang indefinitely\n- Consumer track ended detection doesn't distinguish between normal end and network failure\n- NormalizationNode configuration recreated per consumer instead of module-level constant\n- No logging for consumer creation failures - silent error handling\n- Gain node value clamping (0-200%) happens in multiple places - duplication\n\n---\n\n### **2.6 Voice Activity Detection & Speaking Status**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts` (111 lines)**\n\n**Purpose:** Monitor microphone level and report speaking status\n\n**Key Metrics:**\n- FFT size: 512\n- Smoothing time constant: 0.85\n- RMS threshold: 0.04 (4%)\n- Speaking hold duration: 220ms (hold-over to avoid jitter)\n\n**Algorithm:**\n1. Analyser node performs FFT on incoming audio\n2. Calculates RMS (root mean square) of audio samples\n3. If RMS >= threshold AND not muted → set hold-until time\n4. Current time <= hold-until → report speaking=true\n5. Muting immediately reports speaking=false\n\n**Functions:**\n- `startMicLevelMonitoring()` - Creates audio context and starts RAF-based monitor loop\n- `stopMicLevelMonitoring()` - Cleanup and final speaking=false report\n\n**Issues Identified:**\n- Uses `requestAnimationFrame` for 60fps monitoring - unnecessary overhead\n- Should use fixed interval (e.g., 50ms) instead\n- `micSpeakingLastSent` is a boolean flag, not a full state - can't distinguish between not-yet-sent and sent-false\n- No jitter buffer - could spam speaking state changes\n\n---\n\n### **2.7 Microphone Processing Pipeline**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts` (104 lines)**\n\n**Purpose:** Apply outgoing volume control to microphone track\n\n**Architecture:**\n```\nUserMedia Stream\n  → SourceNode\n    → GainNode (volume)\n      → DestinationNode (processed track)\n```\n\n**Lifecycle:**\n- Single active session at a time\n- `createProcessedMicrophoneTrack()` - Creates new session with gain node\n- `activateMicrophoneProcessing()` - Sets session as active (disposes previous)\n- `updateOutgoingMicrophoneGain()` - Changes gain value in active session\n- `updateOutgoingMicrophoneMuted()` - Sets track.enabled on both source and processed\n\n**Issues Identified:**\n- Keeps original sourceTrack around - consumes extra resources\n- No cleanup callback - if active session set but never disposed, resources leak\n- Gain clamping function duplicated from consumers.ts\n- No validation that sourceTrack is still valid before using it\n\n---\n\n### **2.8 Media Signaling (WebSocket Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts` (178 lines)**\n\n**Purpose:** Request-response protocol for media operations (RTC negotiation, producer/consumer management)\n\n**Signal Actions:**\n- `get_router_rtp_capabilities` - Get server's codec capabilities\n- `create_webrtc_transport` - Create send/recv transport\n- `connect_webrtc_transport` - Exchange DTLS parameters\n- `media_produce` - Create producer\n- `media_close_producer` - Close producer\n- `media_consume` - Create consumer\n- `media_resume_consumer` - Resume consumer playback\n- `create_native_sender_session` - RTP sender setup (native capture)\n- `client_diagnostic` - Report native sender metrics\n\n**Request-Response Pattern:**\n- Each request gets unique ID: `media-${Date.now()}-${counter}`\n- 10-second timeout (Line 113-116)\n- Response matched to request by ID\n- Pending requests tracked in Map\n- Server can send unsolicited messages (new_producer, producer_closed, voice_activity)\n\n**Voice Activity Reporting:**\n- `reportVoiceActivity()` - Send speaking=true/false to server\n- Triggered by voice level monitoring\n\n**Diagnostics:**\n- `reportCodecDecision()` - Log codec selection decision\n- `reportNativeSenderDiagnostic()` - Report native sender status/errors\n\n**Issues Identified:**\n- Fixed 10-second timeout for all operations - some might need longer (network dependent)\n- No retry logic - first timeout = failure\n- PendingRequests could accumulate if responses never arrive (timeout cleanup exists, but requests are still lost)\n- No congestion detection - if many requests fail, no backpressure\n\n---\n\n### **2.9 Subscription System**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts` (122 lines)**\n\n**Purpose:** Publisher-subscriber pattern for media state changes\n\n**Subscribers:**\n1. `videoTilesSubscribers` - Remote camera/screen tiles\n2. `cameraStateSubscribers` - Local camera enabled/error/stream\n3. `screenStateSubscribers` - Local screen share enabled/error/stream/routingMode\n4. `transportHealthSubscribers` - Connection health state\n\n**Pattern:**\n- Each subscription function calls subscriber immediately with current state\n- Returns unsubscribe function\n- Used by `voice.ts` store to maintain reactive state\n\n**Issues Identified:**\n- No limits on subscriber count - potential memory leak if many subscriptions created\n- No deduplication - could call subscriber twice if subscribed twice\n- Subscribers called synchronously - blocking if callback is slow\n\n---\n\n### **2.10 Device Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts** (150+ lines)**\n\n**Purpose:** Enumerate and switch audio/video devices at runtime\n\n**Device Enumeration:**\n- `listAudioDevices()` - List microphones & speakers\n- `listCameraDevices()` - List cameras\n- Labels sorted alphabetically with fallback numbering\n\n**Device Selection:**\n- `setPreferredMicrophoneDevice()` - Hot-swap microphone\n  - Gets new user media\n  - Creates new processing session\n  - Replaces producer track if exists, or creates new producer\n  - Manages fallback if device unavailable\n  \n- `setPreferredCameraDevice()` - Hot-swap camera (partial implementation visible)\n- `setPreferredSpeakerDevice()` - Route speaker output\n  - Uses `HTMLAudioElement.setSinkId()` if supported\n  - Applied to all remote audio elements\n\n**Device Change Detection:**\n- `registerDeviceChangeListener()` - Fires when devices added/removed\n- Resets audio devices if current device disappears\n- Prevents duplicate registrations\n\n**Issues Identified:**\n- Device change listener doesn't distinguish between input/output changes\n- Hot-swap has no fallback if getRtpCapabilities changes (rare but possible)\n- Speaker routing set per-element, not globally - new consumers must be manually routed\n- Sorting is expensive on every enumeration - could cache\n\n---\n\n### **2.11 Constraints & Codec Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts` (97 lines)**\n\n**Audio Constraints:**\n```typescript\n{\n  deviceId: { exact: selectedDeviceId },\n  noiseSuppression: voiceNoiseSuppressionEnabled(),\n  echoCancellation: voiceEchoCancellationEnabled(),\n  channelCount: 1  // Mono\n}\n```\n- Uses browser supported constraints API\n- Graceful degradation if constraints unavailable\n\n**Video Constraints (Camera):**\n- Simple exact device ID constraint\n\n**Screen Share Constraints:**\n- Resolution: 720p (1280×720), 1080p (1920×1080), 1440p (2560×1440), 4k (3840×2160)\n- FPS: 30 or 60\n- displaySurface hint: \"monitor\" or \"window\"\n- contentHint: \"motion\" (>=60fps or app) or \"detail\"\n\n**Codec Selection:**\n- Screen share: H.264 > VP8 > VP9 (platform-independent, NVENC hardware support)\n- Native: H.264 only\n\n**Issues Identified:**\n- No support for audio bandwidth constraints\n- Screen share 4K resolution could be very expensive\n- No validation that requested FPS/resolution is supported before attempting\n\n---\n\n### **2.12 Error Handling**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts` (72 lines)**\n\n**Error Normalization:**\n\n1. **Camera Errors:**\n   - Permission denied → \"Camera access was denied...\"\n   - Not found → \"No camera device was found...\"\n   - Not readable/in use → \"Camera is unavailable or in use...\"\n   - Generic → Pass through error message\n\n2. **Screen Share Errors:**\n   - Permission denied → \"Screen share permission was denied...\"\n   - Not found → \"No shareable display source was found...\"\n   - Not readable → \"Screen sharing is unavailable or already in use...\"\n   - Generic → Pass through error message\n\n3. **Device Detection:**\n   - `isMissingDeviceError()` - Check if error is device-not-found\n\n**Issues Identified:**\n- Error messages are user-friendly but not actionable\n- No error codes - difficult to log/debug\n- Generic DOMException handling is catch-all at end\n\n---\n\n### **2.13 Native Screen Capture (Tauri)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/native.ts` (88 lines)**\n\n**Purpose:** Wrap Tauri native screen capture APIs\n\n**Functions:**\n- `listNativeCaptureSources()` - Enumerate windows/screens/apps\n- `nativeCodecCapabilities()` - Check available codecs\n- `startNativeCapture()` - Arm native capture service\n- `stopNativeCapture()` - Disarm service\n- `nativeCaptureStatus()` - Poll for live metrics\n\n**Fallback Monitor:**\n- Polling every 1s for encoder failures\n- Fallback reasons: \"degradation\", \"encoder_failure\", etc.\n- Auto-stops if fallback reason appears\n- Reports diagnostic event to server\n\n**Backend Selection:**\n- Reads encoder_backend (NVENC, OpenH264)\n- Tries requested backend, falls back to other\n- Extensive diagnostics in `NativeCaptureStatus`\n\n**Issues Identified:**\n- Hardcoded 1s poll interval - could miss rapid failures\n- Codec mime type validation string-matching (should use enum)\n- No timeout if native capture hangs\n\n---\n\n## **3. UI COMPONENTS**\n\n### **3.1 Voice Dock Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx` (131 lines)**\n\n**Purpose:** Main control panel for voice channel operations\n\n**Controls:**\n- Disconnect button\n- Mic mute toggle\n- Speaker mute toggle  \n- Camera enable/disable\n- Screen share enable/disable\n\n**Status Display:**\n- Connected channel name\n- Connection health (good/degraded/failed)\n- Health dot indicator + label\n- Camera/screen share error messages\n- Routing mode (SFU)\n\n**Native Debug Panel** (Tauri only, debug mode):\n- Frame queue stats\n- Encoder output rate\n- RTP packet counts\n- Queue backlog & drop counts\n- Encode latency\n- Codec info\n- Transport/producer health\n- Pressure metrics\n- Encoder backend info\n\n**Issues Identified:**\n- No tooltip for health states\n- Debug panel is text-heavy and cramped\n- Retry connection button shown but doesn't explain what will reconnect\n\n---\n\n### **3.2 Video Stage Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx` (78 lines)**\n\n**Purpose:** Display grid of video tiles (camera + screen share)\n\n**Layout:**\n- Local camera (if enabled) in grid\n- Local screen share (if enabled) in grid\n- Remote camera tiles (from videoTiles subscription)\n\n**Features:**\n- Auto-play video elements\n- Muted local streams\n- Username + source labels\n- CSS classes for styling (is-local, is-screen-share)\n\n**Issues Identified:**\n- No pagination/max tile limit (could become unwieldy with many participants)\n- No speaker highlight indicator\n- Order is arbitrary for remote tiles (relies on alphabetical sort in subscriptions.ts)\n- No click-to-focus or fullscreen\n\n---\n\n### **3.3 Voice Settings Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx` (110 lines)**\n\n**Purpose:** User-facing voice settings\n\n**Toggles:**\n- Noise suppression\n- Echo cancellation\n- Auto level incoming voices\n\n**Sliders:**\n- Incoming voice volume (0-200%)\n- Outgoing microphone volume (0-200%)\n\n**Issues Identified:**\n- No input validation (could receive invalid percentages)\n- Help text is generic, no device-specific guidance\n- Volume slider goes to 200% - could cause distortion\n\n---\n\n## **4. INTEGRATION WITH MAIN APPLICATION**\n\n### **4.1 ChannelList Component (Voice Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (1200+ lines)**\n\n**Key Voice Operations:**\n\n1. **Join Voice** - `joinVoiceChannel()`\n   - Sets state to \"joining\"\n   - Sends WebSocket message\n\n2. **Leave Voice** - `leaveVoiceChannel()`\n   - Sets state to \"leaving\"\n   - Sends WebSocket message\n\n3. **Toggle Mic** - `handleToggleMicMuted()`\n   - Updates mute state\n   - Calls `setMicrophoneMuted()`\n\n4. **Toggle Camera** - `handleToggleCamera()`\n   - Idempotent with pending state\n   - Calls `startLocalCameraProducer()` or `stopLocalCameraProducer()`\n   - Shows error toast on failure\n\n5. **Toggle Screen Share** - `handleToggleScreenShare()`\n   - Browser mode: Immediate `startLocalScreenProducer()`\n   - Tauri mode: Opens modal to select source, then starts\n   - Calls `stopLocalScreenProducer()` if already sharing\n\n6. **Voice Presence Events**\n   - `voice_joined` → Initialize transports, restore settings\n   - `voice_left` → Cleanup, reset state\n   - `voice_user_joined` → Play join cue, update participants\n   - `voice_user_left` → Play leave cue, update participants\n   - `voice_user_speaking` → Update speaking indicator\n   - `voice_presence_snapshot` → Initialize on startup\n\n7. **Error Handling**\n   - Error type message → Set action state to idle\n   - Network close → Show rejoin notice + cleanup\n\n8. **Cleanup on Unmount**\n   - Stop subscriptions\n   - Remove event listeners\n   - Clear timers\n   - Stop screen share preview\n\n**Issues Identified:**\n- Error message shown in toast but error details lost\n- No user confirmation for destructive actions (e.g., leaving voice)\n- Native metrics polling (1s interval) runs constantly when screen sharing - could drain battery\n\n---\n\n## **5. STATE FLOW DIAGRAM**\n\n```\nWebSocket Message (voice_joined)\n  ↓\nsetJoinedVoiceChannel(id)\n  ↓\ninitializeMediaTransports(id)\n  ├─ Request RTP capabilities\n  ├─ Load Device with capabilities\n  ├─ Create Send/Recv transports\n  ├─ Wire transport events\n  └─ startLocalAudioProducer()\n      ├─ getUserMedia() with constraints\n      ├─ createProcessedMicrophoneTrack() (gain node)\n      ├─ sendTransport.produce()\n      └─ startMicLevelMonitoring()\n        └─ RAF loop → Calculate RMS → reportVoiceActivity()\n  ├─ registerDeviceChangeListener()\n  └─ flushQueuedProducerAnnouncements()\n      └─ consumeRemoteProducer() for each queued\n\nOn new_producer signal\n  ├─ Record username, source, routingMode\n  └─ queueOrConsumeProducer() → consumeRemoteProducer()\n      ├─ Request consumer from server\n      ├─ Create consumer via recvTransport\n      ├─ If audio: Set up playback chain\n      │   ├─ Create HTMLAudioElement\n      │   ├─ SourceNode → NormalizationCompressor → GainNode → Destination\n      │   └─ audio.play()\n      └─ If video: Create VideoTile + subscribe UI\n\nWebSocket Message (voice_left)\n  ↓\ncleanupMediaTransports()\n  ├─ closeTransports()\n  │   ├─ Dispose all producers & tracks\n  │   ├─ Close all consumers\n  │   ├─ Dispose audio nodes & elements\n  │   └─ Close transports & device\n  └─ Reset all state signals\n```\n\n---\n\n## **6. DETAILED ISSUES & RECOMMENDATIONS**\n\n### **Critical Issues**\n\n1. **No Timeout on Transport Creation**\n   - **Location:** `initializeMediaTransports()` line 279\n   - **Issue:** If server hangs responding to capabilities request, initialization blocks indefinitely\n   - **Fix:** Add 5-second timeout to `requestMediaSignal()` calls in transport init\n\n2. **Silent Audio Play Failure Retry**\n   - **Location:** `consumers.ts` line 247-265\n   - **Issue:** If `audio.play()` fails twice, error is logged but not propagated\n   - **Impact:** User hears silence but no error toast\n   - **Fix:** Throw error after second failure, let caller handle\n\n3. **Microphone Processing Resource Leak**\n   - **Location:** `microphoneProcessing.ts`\n   - **Issue:** If `activateMicrophoneProcessing()` is called without prior cleanup, old session orphaned\n   - **Fix:** Explicit dispose call or use WeakMap for auto-cleanup\n\n4. **Voice Activity Detection Too Sensitive**\n   - **Location:** `voiceActivity.ts` line 77-78\n   - **Issue:** 220ms hold-over can miss natural speech pauses\n   - **Recommendation:** Use 300-400ms, or make configurable\n\n### **High Priority Issues**\n\n5. **Screen Share Fallback Stuck**\n   - **Location:** `producers.ts` line 680-685\n   - **Issue:** Once `nativeCaptureAttempted` set true, user can't retry browser mode\n   - **Fix:** Add UI button to reset flag, or prompt user\n\n6. **Transport Health Monitoring Race Condition**\n   - **Location:** `transports.ts` line 106-112\n   - **Issue:** Multiple transports closing in parallel could set state to wrong value\n   - **Fix:** Use sequence number or lock to ensure ordering\n\n7. **No Reconnection Logic**\n   - **Issue:** If WebSocket reconnects, media transports not re-established\n   - **Fix:** Add auto-reconnect on WS reconnect (currently relies on user clicking Retry)\n\n### **Medium Priority Issues**\n\n8. **Volume Clamping Duplicated**\n   - **Locations:** `consumers.ts` line 39-44, `microphoneProcessing.ts` line 10-15\n   - **Fix:** Export single function from utils module\n\n9. **Consumer Creation Timeout**\n   - **Location:** `consumers.ts` line 184\n   - **Issue:** No timeout on `requestMediaSignal(\"media_consume\")`\n   - **Fix:** Add shorter timeout (3-5s) for per-consumer requests\n\n10. **Device Change Listener Not De-Registered**\n    - **Location:** `transports.ts` line 168\n    - **Issue:** Listener registered in `initializeMediaTransports`, de-registered on close, but no guard\n    - **Fix:** Add state guard to prevent double de-registration\n\n### **Code Quality Issues**\n\n11. **Error Handling Inconsistency**\n    - Some code uses `console.warn`, some uses `console.error`, some uses throw\n    - **Fix:** Standardize on error boundary propagation\n\n12. **Missing JSDoc Comments**\n    - Complex functions like `consumeRemoteProducer` lack documentation\n    - **Fix:** Add JSDoc for public APIs\n\n13. **Magic Numbers**\n    - 10000ms timeout, 220ms hold, 512 FFT size, 0.04 threshold not documented\n    - **Fix:** Extract to named constants with comments\n\n---\n\n## **7. PERFORMANCE CONSIDERATIONS**\n\n1. **Audio Context Lifecycle**\n   - Creates multiple AudioContexts (mic level, remote playback, mic processing)\n   - Browser limits ~10 contexts max - current design uses 3 when at capacity\n   - **Safe but could be optimized:** Reuse single context for monitoring\n\n2. **Voice Activity Detection RAF Loop**\n   - Runs at 60fps (browser refresh rate)\n   - **Issue:** Overkill for voice activity (could be 20fps)\n   - **Fix:** Use 50ms setInterval instead\n\n3. **Storage of All Remote Audio Elements**\n   - `remoteAudioElements` map keeps reference to all audio elements\n   - **Potential issue:** Never cleaned from DOM, only disconnected\n   - **Fix:** Use WeakMap or actively remove elements\n\n4. **Native Sender Metrics Polling**\n   - 1-second interval polling from Rust backend\n   - **Cost:** Continuous IPC calls\n   - **Optimization:** Debounce to 2-3 seconds or on-demand\n\n---\n\n## **8. SECURITY CONSIDERATIONS**\n\n1. **Producer/Consumer Metadata**\n   - Username stored client-side in `producerUsernameById` Map\n   - **Risk:** Could be spoofed if network message forged\n   - **Mitigation:** Server validates all signaling messages\n\n2. **Codec Negotiation**\n   - Accepts codec from server without validation\n   - **Mitigation:** Limited set of supported codecs in device.rtpCapabilities\n\n3. **SinkId Device Selection**\n   - `setSinkId` could fail silently\n   - **Risk:** Audio routed to unexpected output\n   - **Mitigation:** Device selection is user-initiated\n\n---\n\n## **9. SUMMARY TABLE**\n\n| Component | Purpose | Lines | Key Pattern | Risk Level |\n|-----------|---------|-------|-------------|-----------|\n| voice.ts | Reactive state store | 413 | Solid.js signals | Low |\n| state.ts | Module-level state | 144 | Module exports | Low |\n| transports.ts | RTC setup/lifecycle | 376 | Idempotent init + cleanup | Medium |\n| producers.ts | Outgoing media | 737 | Track ownership mgmt | High |\n| consumers.ts | Incoming media | 382 | Audio processing chain | High |\n| voiceActivity.ts | Speaking detection | 111 | RAF-based monitoring | Medium |\n| microphoneProcessing.ts | Outgoing volume | 104 | Single active session | Medium |\n| signaling.ts | WebSocket protocol | 178 | Request-response | Medium |\n| subscriptions.ts | Publisher-subscriber | 122 | Observer pattern | Low |\n| devices.ts | Audio/video devices | 150+ | Hot-swap at runtime | High |\n| constraints.ts | Media constraints | 97 | Constraint generation | Low |\n| errors.ts | Error normalization | 72 | Error mapping | Low |\n| native.ts | Tauri integration | 88 | API wrapper | Medium |\n| VoiceDock.tsx | Control UI | 131 | Component | Low |\n| VideoStage.tsx | Video grid | 78 | Component | Low |\n| VoiceAudioPreferences.tsx | Settings UI | 110 | Component | Low |\n| ChannelList.tsx | Main integration | 1200+ | Orchestration | High |\n\n---\n\n## **10. FILE PATHS (ABSOLUTE)**\n\nAll voice-related files are located at:\n\n- `/home/guibibi/projects/yankcord/client/src/stores/voice.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/index.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/types.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/state.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/codecs.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/native.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media.ts` (re-export wrapper)\n- `/home/guibibi/projects/yankcord/client/src/api/nativeCapture.ts` (Tauri bindings)\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/ScreenShareModal.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (integration)\n- `/home/guibibi/projects/yankcord/client/src/utils/voiceCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/utils/audioCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/ws.ts` (WebSocket definitions)\n\nNative Tauri implementation:\n- `/home/guibibi/projects/yankcord/client/src-tauri/src/` (Rust backend for native capture)\n\nThis concludes the comprehensive exploration of the voice chat system on the client side."}},"sourceToolAssistantUUID":"5ff0b289-d04f-4517-8905-9a49cb5c306c"}
{"parentUuid":"2d1abb79-2d88-4c1a-95ae-c7b85e067c9b","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01QA7wiGy7jc35VH99NELAyd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Gw122TzMU9AwCjTY7ZNSHb","name":"TaskOutput","input":{"task_id":"a492c1f","block":true,"timeout":120000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":9436,"cache_read_input_tokens":22767,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9436},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBjL3jVV6XeLDZLBh8k","type":"assistant","uuid":"63b23aaa-aa06-4500-bfc6-18a329a8645d","timestamp":"2026-02-23T14:49:12.311Z"}
{"parentUuid":"63b23aaa-aa06-4500-bfc6-18a329a8645d","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"waiting_for_task","taskDescription":"Explore voice chat server code","taskType":"local_agent"},"toolUseID":"task-output-waiting-1771858152313","parentToolUseID":"toolu_01Gw122TzMU9AwCjTY7ZNSHb","uuid":"1f2f845c-42c4-435d-bcbc-f09f55d96b36","timestamp":"2026-02-23T14:49:12.313Z"}
{"parentUuid":"63b23aaa-aa06-4500-bfc6-18a329a8645d","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Gw122TzMU9AwCjTY7ZNSHb","type":"tool_result","content":"<retrieval_status>success</retrieval_status>\n\n<task_id>a492c1f</task_id>\n\n<task_type>local_agent</task_type>\n\n<status>completed</status>\n\n<output>\nNow I have comprehensive information. Let me create a thorough report:\n\n## COMPREHENSIVE SERVER-SIDE VOICE CHAT / WEBRTC / MEDIASOUP ANALYSIS\n\n### EXECUTIVE SUMMARY\n\nThe Yankcord server implements a complete SFU (Selective Forwarding Unit) architecture for voice communication using mediasoup. The system manages WebRTC connections, audio/video producers and consumers, and maintains voice channel state through a combination of database persistence, in-memory state tracking, and real-time WebSocket signaling.\n\n---\n\n### 1. MEDIASOUP ARCHITECTURE & WORKER LIFECYCLE\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/mod.rs`\n\n#### Key Components:\n\n**MediaService Structure:**\n```rust\npub struct MediaService {\n    workers: Vec<Worker>,\n    routers: Arc<Mutex<HashMap<Uuid, Router>>>,\n    connection_media: Arc<Mutex<HashMap<Uuid, transport::ConnectionMediaState>>>,\n    webrtc_listen_ip: IpAddr,\n    announced_ip: Option<String>,\n    native_rtp_listen_ip: IpAddr,\n    native_rtp_announced_ip: Option<IpAddr>,\n}\n```\n\n**Worker Initialization:**\n- Creates N workers based on `MEDIA_WORKER_COUNT` configuration (default: 2)\n- Workers are created synchronously during server startup\n- Each worker is managed by mediasoup's WorkerManager\n- No documented worker lifecycle management (no restart/health-check logic)\n\n**Router Management:**\n- Routers are cached per channel_id in a HashMap\n- Router assignment uses deterministic worker selection: `channel_id.as_bytes()[0] as usize % self.workers.len()`\n- **Critical Issue**: Router caching means codec settings (opus_bitrate, opus_dtx, opus_fec) set at channel creation time are never updated after router creation, even if channel settings change\n- Routers can be manually invalidated via `invalidate_router()` to force recreation\n\n**Network Configuration:**\n- WebRTC transport listen IP and announced IP are configurable\n- Native RTP (for screen sharing) has separate listen/announced IP configuration\n- Fallback to localhost (127.0.0.1) if IP parsing fails with warnings\n\n---\n\n### 2. ROUTER & CODEC CONFIGURATION\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/router.rs`\n\n#### Opus Configuration:\n```rust\npub struct OpusConfig {\n    pub bitrate: Option<u32>,          // Max average bitrate\n    pub dtx: Option<bool>,              // Discontinuous Transmission\n    pub fec: Option<bool>,              // Forward Error Correction\n}\n```\n\n**Supported Codecs:**\n- **Audio**: Opus (48kHz, stereo, 2 channels)\n  - RTCP Feedback: TransportCc\n  - Parameters: maxaveragebitrate, usedtx, useinbandfec\n- **Video**: VP8, H.264, VP9, AV1\n  - RTCP Feedback: Nack, NackPli, CcmFir, GoogRemb, TransportCc\n  - H.264: packetization-mode=1, profile-level-id=42e01f\n\n**Configuration Concerns:**\n1. Opus parameters are applied at router creation only\n2. No runtime codec parameter updates\n3. Video codec negotiation not fully exposed to clients\n4. Database schema stores opus settings but no per-message codec negotiation\n\n**Database Schema (channels table):**\n```sql\nopus_bitrate INTEGER      -- Max bitrate in bps\nopus_dtx     BOOLEAN      -- Enable DTX\nopus_fec     BOOLEAN      -- Enable FEC\n```\n\n---\n\n### 3. TRANSPORT MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs`\n\n#### ConnectionMediaState Structure:\n```rust\npub struct ConnectionMediaState {\n    pub channel_id: Uuid,\n    pub send_transport_id: Option<String>,\n    pub recv_transport_id: Option<String>,\n    pub transports: HashMap<String, WebRtcTransport>,\n    pub native_transports_by_producer: HashMap<String, PlainTransport>,\n    pub producers: HashMap<String, ProducerEntry>,\n    pub consumers: HashMap<String, Consumer>,\n}\n```\n\n**Transport Creation:**\n1. **SendTransport**: Used for uploading audio/video from client\n   - Created per direction on demand\n   - Replaced if same direction requested again\n   - Uses WebRtcTransport with configured listen IPs\n\n2. **RecvTransport**: Used for downloading media from other participants\n   - Created per direction on demand\n   - Sends existing producers to new recv transport creators\n   - Also uses WebRtcTransport\n\n3. **PlainTransport**: Used for native screen sharing\n   - Created on demand for screen producers\n   - Uses raw RTP/UDP\n   - Comedia enabled (automatic endpoint detection)\n   - RTCP multiplexed (rtcp_mux=true)\n\n**Critical Logic Issues:**\n\n1. **Channel Validation on Send Transport Creation (Lines 154-162):**\n   - If connection switches channels, old ConnectionMediaState is cleared\n   - **Issue**: Session switching doesn't properly validate permissions\n\n2. **Duplicate Producer Check (Lines 266-282, 305-321):**\n   - Checked TWICE: once before creating and once after\n   - Race condition possible between checks\n   - Only one camera and one screen producer allowed per connection\n\n3. **Recv Transport Producer Snapshot (Lines 555-600):**\n   - When recv transport created, sends all existing channel producers\n   - **Issue**: Producer owner username lookup may fail silently (line 570-575)\n   - If owner disconnected, producer info not sent to new consumer\n\n**Producer Lifecycle:**\n```\n1. Client creates send transport\n2. Client connects send transport (DTLS handshake)\n3. Client calls MediaProduce with RTP parameters\n4. Server creates producer on send transport\n5. Producer added to state.producers HashMap\n6. Other clients notified via broadcast (\"new_producer\")\n7. Other clients create consumers on their recv transports\n8. Client can close producer via MediaCloseProducer\n```\n\n---\n\n### 4. PRODUCER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 238-340)\n\n#### ProducerSource Enum:\n```rust\npub enum ProducerSource {\n    Microphone,  // Audio only\n    Camera,      // Video only\n    Screen,      // Video only\n}\n```\n\n#### Validation Constraints:\n1. **One camera per connection**: Prevents multiple camera producers simultaneously\n2. **One screen per connection**: Prevents multiple screen shares\n3. **Microphone**: No per-connection limit (multiple microphone sources possible)\n4. **Kind/Source Validation**: Kind must match source (e.g., \"microphone\" requires kind=\"audio\")\n\n#### Producer Creation Flow:\n```\nClient sends: MediaProduce {\n    kind: \"audio\"|\"video\",\n    source: \"microphone\"|\"camera\"|\"screen\",\n    routing_mode: \"sfu\",\n    rtp_parameters: RtpParameters\n}\n\nServer:\n1. Validates routing_mode (only \"sfu\" allowed, no mesh/hybrid)\n2. Validates source matches kind\n3. Verifies send transport exists\n4. Checks camera/screen limits\n5. Creates producer with mediasoup\n6. Stores in state.producers\n7. Broadcasts to all channel members\n```\n\n---\n\n### 5. CONSUMER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 488-568)\n\n#### Consumer Creation Logic:\n```rust\npub async fn create_consumer_for_connection(\n    connection_id: Uuid,\n    channel_id: Uuid,\n    producer_id: &str,\n    rtp_capabilities: RtpCapabilities,\n) -> Result<CreatedConsumer, String>\n```\n\n**Key Properties:**\n- Created in PAUSED state: `consumer_options.paused = true`\n- Client must call `MediaResumeConsumer` to start receiving\n- RTP parameters negotiated based on client capabilities\n\n**Validations:**\n1. Producer must exist in same channel\n2. Client must be in channel\n3. Client RTP capabilities must be able to consume producer\n4. Router validates compatibility: `router.can_consume()`\n\n**Concerns:**\n- No bitrate limits enforced on consumers\n- No adaptive bitrate control\n- Consumers manually managed (no automatic cleanup on producer close)\n- No bandwidth constraints per channel\n\n---\n\n### 6. NATIVE VIDEO CODEC & SCREEN SHARING\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs`\n\n#### Native Video Codec Support:\n```rust\npub enum NativeVideoCodec {\n    H264,   // Ready - PT 96, clock_rate 90kHz\n    Vp8,    // Ready - PT 98, clock_rate 90kHz\n    Vp9,    // Ready - PT 100, clock_rate 90kHz\n    Av1,    // Ready - PT 102, clock_rate 90kHz\n}\n```\n\n#### Native Sender Session (for Screen Sharing):\n```rust\npub struct NativeSenderSession {\n    pub producer_id: String,\n    pub rtp_target: String,           // Address to send RTP to\n    pub payload_type: u8,\n    pub ssrc: u32,                    // Canonical SSRC from connection_id\n    pub mime_type: String,\n    pub clock_rate: u32,\n    pub packetization_mode: u8,       // H.264 only\n    pub profile_level_id: String,     // H.264 only\n    pub codec: NativeCodecDescriptor,\n    pub available_codecs: Vec<NativeCodecDescriptor>,\n}\n```\n\n#### Screen Sharing Flow:\n1. Client requests `CreateNativeSenderSession` with optional preferred codecs\n2. Server creates PlainTransport with comedia=true\n3. Server creates producer on transport\n4. Returns RTP target endpoint and codec parameters\n5. Client sends raw H.264/VP8/VP9/AV1 RTP packets to target\n6. Server forwards through SFU to consumers\n\n**Configuration:**\n- H.264: Packetization mode 1 (single NAL per RTP packet)\n- SSRC deterministically derived from connection_id (first 4 bytes)\n- RTCP cname formatted as `native-{ssrc:x}`\n\n**Issue**: SSRC derivation is deterministic but could theoretically collide for different connection_ids sharing same first 4 bytes. Fallback seed is 0x4E41_5456 if collision detected.\n\n---\n\n### 7. WEBSOCKET SIGNALING LAYER\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs`\n\n#### Media Signal Protocol:\n\n**Request Format:**\n```json\n{\n  \"action\": \"get_router_rtp_capabilities|create_webrtc_transport|...\",\n  \"request_id\": \"optional-string\",\n  \"...\" : \"other params\"\n}\n```\n\n**Supported Actions:**\n1. `GetRouterRtpCapabilities` - Get channel's codec capabilities\n2. `CreateWebrtcTransport` - Create send/recv transport\n3. `ConnectWebrtcTransport` - Complete DTLS handshake\n4. `MediaProduce` - Create producer\n5. `MediaConsume` - Create consumer\n6. `MediaResumeConsumer` - Resume paused consumer\n7. `MediaCloseProducer` - Close producer\n8. `CreateNativeSenderSession` - Setup screen sharing\n9. `ClientDiagnostic` - Log client diagnostics\n\n#### Rate Limiting:\n```rust\nconst MAX_MEDIA_SIGNAL_EVENTS_PER_WINDOW: u32 = 80;\nconst MEDIA_SIGNAL_RATE_WINDOW: Duration = Duration::from_secs(5);\n```\n\n**Limit**: 80 media signal events per 5-second window per connection\n\n#### Validation:\n- request_id max 128 characters\n- Payload size limit: 32 KB\n- Field constraints: direction (16), transport_id (128), kind (16), source (32), routing_mode (16)\n\n#### Error Handling:\n```rust\npub enum MediaSignalSendOutcome {\n    Delivered,\n    Dropped,    // Serialization failed\n    Disconnect, // Queue full or connection closed\n}\n```\n\n**Policy**: Close connection if outbound queue full (prevents slow-consumer problems)\n\n---\n\n### 8. VOICE CHANNEL STATE MANAGEMENT\n\n**Files:**\n- `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 605-631, 1259-1415)\n- `/home/guibibi/projects/yankcord/server/src/ws/voice.rs`\n- `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` (Lines 318-394)\n\n#### In-Memory State Maps:\n```rust\npub struct AppState {\n    // Voice channel membership\n    pub voice_members_by_connection: Arc<RwLock<HashMap<Uuid, Uuid>>>,\n                                     // connection_id -> channel_id\n    pub voice_members_by_channel: Arc<RwLock<HashMap<Uuid, HashSet<String>>>>,\n                                   // channel_id -> usernames\n    // ... other fields\n}\n```\n\n#### Join Flow:\n```\nClient: JoinVoice { channel_id }\n    ↓\nHandler validates:\n    1. Channel exists\n    2. Channel is voice-enabled\n    3. Get channel's opus config\n    ↓\nUpdate state:\n    1. voice_members_by_connection.insert(connection_id, channel_id)\n    2. If switching channels: remove from old channel, cleanup media\n    3. voice_members_by_channel.entry(channel_id).or_default().insert(username)\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserJoined\n    2. Send to client: VoiceJoined { channel_id, user_id }\n```\n\n#### Leave Flow:\n```\nClient: LeaveVoice { channel_id }\n    ↓\nHandler:\n    1. Remove from voice_members_by_connection\n    2. Remove username from voice_members_by_channel\n    3. Cleanup producers via media.cleanup_connection_media()\n    4. Broadcast closed_producers to channel\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserLeft\n    2. Send to client: VoiceLeft { channel_id, user_id }\n```\n\n#### Disconnect Handling:\nWhen WebSocket connection closes:\n1. `cleanup_connection()` called with connection_id\n2. Removes from voice_members_by_connection and voice_members_by_channel\n3. Calls `media.cleanup_connection_media()` to close all producers/consumers\n4. Broadcasts VoiceUserLeft to all channels\n5. Broadcasts closed producer info to affected channels\n\n**Critical State Issue**: \n- No database persistence of voice channel membership\n- Membership purely in-memory\n- Server restart loses all voice session state\n- Clients must rejoin voice channels after server restart\n\n---\n\n### 9. SPEAKING STATUS & VOICE ACTIVITY\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 611-632)\n\n#### Voice Activity Flow:\n```\nClient: VoiceActivity { channel_id, speaking: bool }\n    ↓\nHandler validates:\n    1. Connection is in the specified channel\n    2. (No rate limiting on speaking events)\n    ↓\nBroadcast:\n    broadcast_voice_activity_to_channel(state, channel_id, username, speaking, None)\n    └─> Sends to all OTHER connections in channel:\n        ServerMessage::VoiceUserSpeaking {\n            channel_id,\n            username,\n            speaking\n        }\n```\n\n**Important Notes:**\n- No database recording of speaking status\n- Purely ephemeral, real-time signaling\n- No speaking history or analytics\n- Clients independently detect voice activity (VAD on client side)\n\n---\n\n### 10. PRODUCER/CONSUMER LIFECYCLE & CLEANUP\n\n**Producer Cleanup:**\n```\nWhen Producer Closed:\n    1. Removed from state.producers\n    2. Removed from native_transports_by_producer (if native)\n    3. Broadcast ClosedProducer message to channel:\n        {\n            \"action\": \"producer_closed\",\n            \"producer_id\": \"...\",\n            \"source\": \"...\",\n            \"routing_mode\": \"...\"\n        }\n```\n\n**Consumer Cleanup:**\n- No explicit cleanup endpoint\n- Consumers auto-close when producer closes\n- Manual close not exposed via WebSocket\n\n**Connection Cleanup:**\n```\nWhen Connection Disconnects:\n    1. state.media.cleanup_connection_media(connection_id)\n       └─> Removes all producers/consumers for this connection\n    2. Returns Vec<ClosedProducer>\n    3. Broadcasts closed_producers to all channels\n```\n\n---\n\n### 11. ISSUES, BUGS & ANTI-PATTERNS\n\n#### CRITICAL ISSUES:\n\n1. **Codec Settings Never Update After Router Creation**\n   - If channel opus_bitrate/dtx/fec changed after first user joins, new users don't get updated settings\n   - Router caching doesn't invalidate on channel update\n   - **Impact**: Codec configuration changes require server restart\n   - **Solution**: Invalidate router when channel settings change\n\n2. **Producer Owner Lookup Silently Fails**\n   - When recv transport created, attempts to get producer owner's username\n   - If owner connection already closed, warns but continues\n   - New consumer doesn't receive \"new_producer\" notification for that producer\n   - **Impact**: Consumer state out of sync with actual producers in channel\n   - **Suggested Fix**: Either cache producer owner info or handle gracefully\n\n3. **No Consumer Auto-Cleanup**\n   - Consumers manually managed, no automatic lifecycle\n   - When producer closes, consumers still exist in HashMap\n   - Consumer close not exposed to client\n   - **Impact**: Memory leak of stale consumers\n   - **Suggested Fix**: Auto-close consumers when producer closes\n\n4. **Duplicate Camera/Screen Check - TOCTOU**\n   - Checked before creation AND after creation\n   - Race condition: two concurrent produce requests could both pass first check\n   - **Impact**: Theoretically could create 2 cameras per connection\n   - **Suggested Fix**: Single atomic check or lock\n\n5. **No Database Persistence of Voice Membership**\n   - Voice state purely in-memory\n   - Server restart loses all state\n   - Clients don't know if they need to rejoin\n   - **Impact**: Broken user experience on server restart\n   - **Suggested Fix**: Persist voice channel membership in database\n\n#### MEDIUM ISSUES:\n\n6. **Slow Consumer Producer Notifications**\n   - When recv transport created, for each producer, sends individual notification\n   - N producers = N separate JSON broadcasts\n   - No batching/bundling of producers list\n   - **Impact**: Inefficient network usage with many producers\n   - **Suggested Fix**: Send producer list in single JSON array\n\n7. **No Bandwidth/Bitrate Enforcement**\n   - Consumers created without bitrate limits\n   - No max-bitrate set on encodings\n   - No congestion control feedback from clients\n   - **Impact**: Network overload possible\n   - **Suggested Fix**: Configure reasonable defaults or per-channel limits\n\n8. **Voice Activity Broadcasting Sends Extra Parameter**\n   - `broadcast_voice_activity_to_channel` sends to ALL except sender\n   - But the exclude_connection_id is set to None\n   - Client sends their own speaking state to themselves too\n   - **Impact**: Redundant message\n   - **Suggested Fix**: Pass Some(connection_id) to exclude self\n\n9. **No Channel Permission Checks**\n   - Join voice doesn't verify user has permission to access channel\n   - No ACL or role-based channel access control for voice\n   - **Impact**: Any authenticated user can join any voice channel\n   - **Suggested Fix**: Add channel permission model\n\n10. **Mediasoup Worker Health Not Monitored**\n    - Workers created at startup, no restart logic\n    - No health checks or deadlock detection\n    - Worker crash would cause silent failures\n    - **Impact**: Server silently stops accepting voice connections\n    - **Suggested Fix**: Add worker health monitoring and auto-restart\n\n#### MINOR ISSUES:\n\n11. **SSRC Derivation Collision Risk**\n    - Canonical SSRC uses only first 4 bytes of UUID\n    - Fallback seed only triggers if exactly 0\n    - **Impact**: Extremely low, but possible SSRC collision\n    - **Suggested Fix**: Use full UUID or CRC32 of full UUID\n\n12. **No Requested Codec Preference Validation**\n    - Client can request any codec, server just filters to ready ones\n    - No limit on preferred_codecs list length\n    - **Impact**: Mild - clients well-behaved, but no server-side guards\n\n13. **Transport Direction Replaced Without Warning**\n    - Creating send transport twice replaces first one\n    - Any media sent on old transport is lost\n    - **Impact**: Client-side bug would lose media\n    - **Suggested Fix**: Return error if transport already exists\n\n14. **Mediasoup Error Messages Exposed**\n    - mediasoup library errors directly sent to client\n    - Could expose internal implementation details\n    - **Impact**: Low security impact, but information disclosure\n\n---\n\n### 12. CONFIGURATION SETTINGS\n\n**File:** `/home/guibibi/projects/yankcord/server/src/config.rs`\n\n```rust\npub struct MediaConfig {\n    pub worker_count: usize,                    // ENV: MEDIA_WORKER_COUNT (default: 2)\n    pub webrtc_listen_ip: String,               // ENV: WEBRTC_LISTEN_IP (default: 0.0.0.0)\n    pub announced_ip: Option<String>,           // ENV: WEBRTC_ANNOUNCED_IP\n    pub native_rtp_listen_ip: String,           // ENV: NATIVE_RTP_LISTEN_IP (default: 127.0.0.1)\n    pub native_rtp_announced_ip: Option<String>,// ENV: NATIVE_RTP_ANNOUNCED_IP\n}\n```\n\n**Environment Variables:**\n- `MEDIA_WORKER_COUNT`: Number of mediasoup workers (must be ≥1)\n- `WEBRTC_LISTEN_IP`: IP for WebRTC transport to listen on\n- `WEBRTC_ANNOUNCED_IP`: Public IP announced in ICE candidates\n- `NATIVE_RTP_LISTEN_IP`: IP for native RTP screen sharing\n- `NATIVE_RTP_ANNOUNCED_IP`: Public IP for native RTP\n\n**WebSocket Configuration (hardcoded):**\n- Outbound queue capacity: 256 messages\n- Idle timeout: 45 seconds\n- Auth timeout: 15 seconds\n- Presence idle (auto-idle status): 5 minutes\n\n**Rate Limiting:**\n- Media signal: 80 events per 5 seconds per connection\n- Payload size limit: 32 KB per media signal\n\n---\n\n### 13. DATABASE SCHEMA FOR VOICE\n\n```sql\n-- Channels table (created in migrations/20260216000001_initial.sql)\nCREATE TABLE channels (\n    id              UUID PRIMARY KEY,\n    name            TEXT NOT NULL,\n    description     TEXT,\n    kind            channel_kind,  -- 'text' or 'voice'\n    position        INT NOT NULL,\n    opus_bitrate    INTEGER,       -- Opus max average bitrate (bps)\n    opus_dtx        BOOLEAN,       -- Opus discontinuous transmission\n    opus_fec        BOOLEAN,       -- Opus forward error correction\n    created_at      TIMESTAMPTZ\n);\n```\n\n**No other voice-specific tables.**\n\n**Missing Features:**\n- No voice history/recording\n- No meeting recordings\n- No voice activity timeline\n- No user voice settings per channel\n- No voice mute/deafen state persistence\n- No voice channel permissions model\n\n---\n\n### 14. KEY FILES & FUNCTIONS SUMMARY\n\n| File | Key Components | Lines |\n|------|-----------------|-------|\n| `/home/guibibi/projects/yankcord/server/src/media/mod.rs` | MediaService, worker/router lifecycle | 177 |\n| `/home/guibibi/projects/yankcord/server/src/media/router.rs` | OpusConfig, codec definitions | 91 |\n| `/home/guibibi/projects/yankcord/server/src/media/transport.rs` | WebRTC transport, producer/consumer lifecycle | 656 |\n| `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs` | Native video codec support, screen sharing | 215 |\n| `/home/guibibi/projects/yankcord/server/src/media/producer.rs` | Producer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/media/consumer.rs` | Consumer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs` | Media signaling protocol handler | 1064 |\n| `/home/guibibi/projects/yankcord/server/src/ws/voice.rs` | Voice broadcast functions | 118 |\n| `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` | Voice join/leave, main WS handler | 1416 |\n| `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` | State cleanup, connection management | 400 |\n| `/home/guibibi/projects/yankcord/server/src/ws/messages.rs` | WebSocket message types | 257 |\n\n---\n\n### 15. ARCHITECTURE DIAGRAM\n\n```\nClient\n  ↓ WebSocket Connection\n┌─────────────────────────────────┐\n│   WebSocket Handler             │\n│   - Authentication              │\n│   - Connection Management       │\n│   - Message Dispatching         │\n└─────────────────────────────────┘\n  ↓\n┌─────────────────────────────────────────────┐\n│   Media Signaling Handler                   │\n│   - Route RTP Capabilities                  │\n│   - Create WebRTC Transport                 │\n│   - Create Producer/Consumer                │\n│   - Rate Limiting (80 events/5s)            │\n└─────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────────────────────┐\n│   MediaService (SFU)                             │\n├──────────────────────────────────────────────────┤\n│  Workers (Vec<Worker>)                           │\n│    ↓                                             │\n│  Routers (HashMap<Uuid, Router>)                 │\n│    ├─ per-channel caching                        │\n│    ├─ codec config (opus, VP8, H264, etc)        │\n│    └─ RTP capability negotiation                 │\n│                                                  │\n│  ConnectionMediaState (HashMap<Uuid, State>)    │\n│    ├─ WebRTC Transports (send/recv)              │\n│    ├─ PlainTransports (native RTP)               │\n│    ├─ Producers (audio/video/screen)             │\n│    └─ Consumers (receive streams)                │\n└──────────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   In-Memory State                │\n├──────────────────────────────────┤\n│  voice_members_by_connection     │\n│    (who's in which channel)      │\n│                                  │\n│  voice_members_by_channel        │\n│    (channel membership list)     │\n│                                  │\n│  media_signal_rate_by_connection │\n│    (rate limiting state)         │\n└──────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   Database                       │\n├──────────────────────────────────┤\n│  channels:                       │\n│    - id, name, kind='voice'      │\n│    - opus_bitrate, opus_dtx,fec  │\n└──────────────────────────────────┘\n```\n\n---\n\n### 16. RECOMMENDATIONS & IMPROVEMENTS\n\n**Priority 1 (Critical):**\n1. Add database persistence for voice channel membership\n2. Invalidate router cache when channel codec settings change\n3. Fix consumer auto-cleanup when producer closes\n4. Add channel permission checks for voice access\n\n**Priority 2 (High):**\n5. Implement worker health monitoring\n6. Batch producer notifications on recv transport creation\n7. Add bitrate enforcement/limits per consumer\n8. Fix producer owner lookup failure handling\n9. Add TOCTOU guard for camera/screen limit checks\n\n**Priority 3 (Medium):**\n10. Implement consumer lifecycle management\n11. Add voice history/analytics database table\n12. Implement voice activity recording\n13. Add per-user voice settings model\n14. Implement voice mute/deafen persistence\n\n**Priority 4 (Nice to Have):**\n15. Add multiple transport error recovery\n16. Implement auto-reconnection guidance\n17. Add voice quality metrics collection\n18. Implement adaptive bitrate adjustment\n19. Support REMB/TWCC congestion control feedback\n\n---\n\n### CONCLUSION\n\nThe Yankcord voice system is a **well-architected SFU implementation** using mediasoup. It handles WebRTC connections, producer/consumer management, and signaling correctly. However, it has **several critical issues** around codec setting persistence, consumer lifecycle management, and state recovery that should be addressed before production use. The architecture is sound but needs hardening for robustness and reliability.\n</output>"}]},"uuid":"442e756c-0dbc-4207-9ca9-1003e721a020","timestamp":"2026-02-23T14:49:12.334Z","toolUseResult":{"retrieval_status":"success","task":{"task_id":"a492c1f","task_type":"local_agent","status":"completed","description":"Explore voice chat server code","output":"Now I have comprehensive information. Let me create a thorough report:\n\n## COMPREHENSIVE SERVER-SIDE VOICE CHAT / WEBRTC / MEDIASOUP ANALYSIS\n\n### EXECUTIVE SUMMARY\n\nThe Yankcord server implements a complete SFU (Selective Forwarding Unit) architecture for voice communication using mediasoup. The system manages WebRTC connections, audio/video producers and consumers, and maintains voice channel state through a combination of database persistence, in-memory state tracking, and real-time WebSocket signaling.\n\n---\n\n### 1. MEDIASOUP ARCHITECTURE & WORKER LIFECYCLE\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/mod.rs`\n\n#### Key Components:\n\n**MediaService Structure:**\n```rust\npub struct MediaService {\n    workers: Vec<Worker>,\n    routers: Arc<Mutex<HashMap<Uuid, Router>>>,\n    connection_media: Arc<Mutex<HashMap<Uuid, transport::ConnectionMediaState>>>,\n    webrtc_listen_ip: IpAddr,\n    announced_ip: Option<String>,\n    native_rtp_listen_ip: IpAddr,\n    native_rtp_announced_ip: Option<IpAddr>,\n}\n```\n\n**Worker Initialization:**\n- Creates N workers based on `MEDIA_WORKER_COUNT` configuration (default: 2)\n- Workers are created synchronously during server startup\n- Each worker is managed by mediasoup's WorkerManager\n- No documented worker lifecycle management (no restart/health-check logic)\n\n**Router Management:**\n- Routers are cached per channel_id in a HashMap\n- Router assignment uses deterministic worker selection: `channel_id.as_bytes()[0] as usize % self.workers.len()`\n- **Critical Issue**: Router caching means codec settings (opus_bitrate, opus_dtx, opus_fec) set at channel creation time are never updated after router creation, even if channel settings change\n- Routers can be manually invalidated via `invalidate_router()` to force recreation\n\n**Network Configuration:**\n- WebRTC transport listen IP and announced IP are configurable\n- Native RTP (for screen sharing) has separate listen/announced IP configuration\n- Fallback to localhost (127.0.0.1) if IP parsing fails with warnings\n\n---\n\n### 2. ROUTER & CODEC CONFIGURATION\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/router.rs`\n\n#### Opus Configuration:\n```rust\npub struct OpusConfig {\n    pub bitrate: Option<u32>,          // Max average bitrate\n    pub dtx: Option<bool>,              // Discontinuous Transmission\n    pub fec: Option<bool>,              // Forward Error Correction\n}\n```\n\n**Supported Codecs:**\n- **Audio**: Opus (48kHz, stereo, 2 channels)\n  - RTCP Feedback: TransportCc\n  - Parameters: maxaveragebitrate, usedtx, useinbandfec\n- **Video**: VP8, H.264, VP9, AV1\n  - RTCP Feedback: Nack, NackPli, CcmFir, GoogRemb, TransportCc\n  - H.264: packetization-mode=1, profile-level-id=42e01f\n\n**Configuration Concerns:**\n1. Opus parameters are applied at router creation only\n2. No runtime codec parameter updates\n3. Video codec negotiation not fully exposed to clients\n4. Database schema stores opus settings but no per-message codec negotiation\n\n**Database Schema (channels table):**\n```sql\nopus_bitrate INTEGER      -- Max bitrate in bps\nopus_dtx     BOOLEAN      -- Enable DTX\nopus_fec     BOOLEAN      -- Enable FEC\n```\n\n---\n\n### 3. TRANSPORT MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs`\n\n#### ConnectionMediaState Structure:\n```rust\npub struct ConnectionMediaState {\n    pub channel_id: Uuid,\n    pub send_transport_id: Option<String>,\n    pub recv_transport_id: Option<String>,\n    pub transports: HashMap<String, WebRtcTransport>,\n    pub native_transports_by_producer: HashMap<String, PlainTransport>,\n    pub producers: HashMap<String, ProducerEntry>,\n    pub consumers: HashMap<String, Consumer>,\n}\n```\n\n**Transport Creation:**\n1. **SendTransport**: Used for uploading audio/video from client\n   - Created per direction on demand\n   - Replaced if same direction requested again\n   - Uses WebRtcTransport with configured listen IPs\n\n2. **RecvTransport**: Used for downloading media from other participants\n   - Created per direction on demand\n   - Sends existing producers to new recv transport creators\n   - Also uses WebRtcTransport\n\n3. **PlainTransport**: Used for native screen sharing\n   - Created on demand for screen producers\n   - Uses raw RTP/UDP\n   - Comedia enabled (automatic endpoint detection)\n   - RTCP multiplexed (rtcp_mux=true)\n\n**Critical Logic Issues:**\n\n1. **Channel Validation on Send Transport Creation (Lines 154-162):**\n   - If connection switches channels, old ConnectionMediaState is cleared\n   - **Issue**: Session switching doesn't properly validate permissions\n\n2. **Duplicate Producer Check (Lines 266-282, 305-321):**\n   - Checked TWICE: once before creating and once after\n   - Race condition possible between checks\n   - Only one camera and one screen producer allowed per connection\n\n3. **Recv Transport Producer Snapshot (Lines 555-600):**\n   - When recv transport created, sends all existing channel producers\n   - **Issue**: Producer owner username lookup may fail silently (line 570-575)\n   - If owner disconnected, producer info not sent to new consumer\n\n**Producer Lifecycle:**\n```\n1. Client creates send transport\n2. Client connects send transport (DTLS handshake)\n3. Client calls MediaProduce with RTP parameters\n4. Server creates producer on send transport\n5. Producer added to state.producers HashMap\n6. Other clients notified via broadcast (\"new_producer\")\n7. Other clients create consumers on their recv transports\n8. Client can close producer via MediaCloseProducer\n```\n\n---\n\n### 4. PRODUCER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 238-340)\n\n#### ProducerSource Enum:\n```rust\npub enum ProducerSource {\n    Microphone,  // Audio only\n    Camera,      // Video only\n    Screen,      // Video only\n}\n```\n\n#### Validation Constraints:\n1. **One camera per connection**: Prevents multiple camera producers simultaneously\n2. **One screen per connection**: Prevents multiple screen shares\n3. **Microphone**: No per-connection limit (multiple microphone sources possible)\n4. **Kind/Source Validation**: Kind must match source (e.g., \"microphone\" requires kind=\"audio\")\n\n#### Producer Creation Flow:\n```\nClient sends: MediaProduce {\n    kind: \"audio\"|\"video\",\n    source: \"microphone\"|\"camera\"|\"screen\",\n    routing_mode: \"sfu\",\n    rtp_parameters: RtpParameters\n}\n\nServer:\n1. Validates routing_mode (only \"sfu\" allowed, no mesh/hybrid)\n2. Validates source matches kind\n3. Verifies send transport exists\n4. Checks camera/screen limits\n5. Creates producer with mediasoup\n6. Stores in state.producers\n7. Broadcasts to all channel members\n```\n\n---\n\n### 5. CONSUMER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 488-568)\n\n#### Consumer Creation Logic:\n```rust\npub async fn create_consumer_for_connection(\n    connection_id: Uuid,\n    channel_id: Uuid,\n    producer_id: &str,\n    rtp_capabilities: RtpCapabilities,\n) -> Result<CreatedConsumer, String>\n```\n\n**Key Properties:**\n- Created in PAUSED state: `consumer_options.paused = true`\n- Client must call `MediaResumeConsumer` to start receiving\n- RTP parameters negotiated based on client capabilities\n\n**Validations:**\n1. Producer must exist in same channel\n2. Client must be in channel\n3. Client RTP capabilities must be able to consume producer\n4. Router validates compatibility: `router.can_consume()`\n\n**Concerns:**\n- No bitrate limits enforced on consumers\n- No adaptive bitrate control\n- Consumers manually managed (no automatic cleanup on producer close)\n- No bandwidth constraints per channel\n\n---\n\n### 6. NATIVE VIDEO CODEC & SCREEN SHARING\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs`\n\n#### Native Video Codec Support:\n```rust\npub enum NativeVideoCodec {\n    H264,   // Ready - PT 96, clock_rate 90kHz\n    Vp8,    // Ready - PT 98, clock_rate 90kHz\n    Vp9,    // Ready - PT 100, clock_rate 90kHz\n    Av1,    // Ready - PT 102, clock_rate 90kHz\n}\n```\n\n#### Native Sender Session (for Screen Sharing):\n```rust\npub struct NativeSenderSession {\n    pub producer_id: String,\n    pub rtp_target: String,           // Address to send RTP to\n    pub payload_type: u8,\n    pub ssrc: u32,                    // Canonical SSRC from connection_id\n    pub mime_type: String,\n    pub clock_rate: u32,\n    pub packetization_mode: u8,       // H.264 only\n    pub profile_level_id: String,     // H.264 only\n    pub codec: NativeCodecDescriptor,\n    pub available_codecs: Vec<NativeCodecDescriptor>,\n}\n```\n\n#### Screen Sharing Flow:\n1. Client requests `CreateNativeSenderSession` with optional preferred codecs\n2. Server creates PlainTransport with comedia=true\n3. Server creates producer on transport\n4. Returns RTP target endpoint and codec parameters\n5. Client sends raw H.264/VP8/VP9/AV1 RTP packets to target\n6. Server forwards through SFU to consumers\n\n**Configuration:**\n- H.264: Packetization mode 1 (single NAL per RTP packet)\n- SSRC deterministically derived from connection_id (first 4 bytes)\n- RTCP cname formatted as `native-{ssrc:x}`\n\n**Issue**: SSRC derivation is deterministic but could theoretically collide for different connection_ids sharing same first 4 bytes. Fallback seed is 0x4E41_5456 if collision detected.\n\n---\n\n### 7. WEBSOCKET SIGNALING LAYER\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs`\n\n#### Media Signal Protocol:\n\n**Request Format:**\n```json\n{\n  \"action\": \"get_router_rtp_capabilities|create_webrtc_transport|...\",\n  \"request_id\": \"optional-string\",\n  \"...\" : \"other params\"\n}\n```\n\n**Supported Actions:**\n1. `GetRouterRtpCapabilities` - Get channel's codec capabilities\n2. `CreateWebrtcTransport` - Create send/recv transport\n3. `ConnectWebrtcTransport` - Complete DTLS handshake\n4. `MediaProduce` - Create producer\n5. `MediaConsume` - Create consumer\n6. `MediaResumeConsumer` - Resume paused consumer\n7. `MediaCloseProducer` - Close producer\n8. `CreateNativeSenderSession` - Setup screen sharing\n9. `ClientDiagnostic` - Log client diagnostics\n\n#### Rate Limiting:\n```rust\nconst MAX_MEDIA_SIGNAL_EVENTS_PER_WINDOW: u32 = 80;\nconst MEDIA_SIGNAL_RATE_WINDOW: Duration = Duration::from_secs(5);\n```\n\n**Limit**: 80 media signal events per 5-second window per connection\n\n#### Validation:\n- request_id max 128 characters\n- Payload size limit: 32 KB\n- Field constraints: direction (16), transport_id (128), kind (16), source (32), routing_mode (16)\n\n#### Error Handling:\n```rust\npub enum MediaSignalSendOutcome {\n    Delivered,\n    Dropped,    // Serialization failed\n    Disconnect, // Queue full or connection closed\n}\n```\n\n**Policy**: Close connection if outbound queue full (prevents slow-consumer problems)\n\n---\n\n### 8. VOICE CHANNEL STATE MANAGEMENT\n\n**Files:**\n- `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 605-631, 1259-1415)\n- `/home/guibibi/projects/yankcord/server/src/ws/voice.rs`\n- `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` (Lines 318-394)\n\n#### In-Memory State Maps:\n```rust\npub struct AppState {\n    // Voice channel membership\n    pub voice_members_by_connection: Arc<RwLock<HashMap<Uuid, Uuid>>>,\n                                     // connection_id -> channel_id\n    pub voice_members_by_channel: Arc<RwLock<HashMap<Uuid, HashSet<String>>>>,\n                                   // channel_id -> usernames\n    // ... other fields\n}\n```\n\n#### Join Flow:\n```\nClient: JoinVoice { channel_id }\n    ↓\nHandler validates:\n    1. Channel exists\n    2. Channel is voice-enabled\n    3. Get channel's opus config\n    ↓\nUpdate state:\n    1. voice_members_by_connection.insert(connection_id, channel_id)\n    2. If switching channels: remove from old channel, cleanup media\n    3. voice_members_by_channel.entry(channel_id).or_default().insert(username)\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserJoined\n    2. Send to client: VoiceJoined { channel_id, user_id }\n```\n\n#### Leave Flow:\n```\nClient: LeaveVoice { channel_id }\n    ↓\nHandler:\n    1. Remove from voice_members_by_connection\n    2. Remove username from voice_members_by_channel\n    3. Cleanup producers via media.cleanup_connection_media()\n    4. Broadcast closed_producers to channel\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserLeft\n    2. Send to client: VoiceLeft { channel_id, user_id }\n```\n\n#### Disconnect Handling:\nWhen WebSocket connection closes:\n1. `cleanup_connection()` called with connection_id\n2. Removes from voice_members_by_connection and voice_members_by_channel\n3. Calls `media.cleanup_connection_media()` to close all producers/consumers\n4. Broadcasts VoiceUserLeft to all channels\n5. Broadcasts closed producer info to affected channels\n\n**Critical State Issue**: \n- No database persistence of voice channel membership\n- Membership purely in-memory\n- Server restart loses all voice session state\n- Clients must rejoin voice channels after server restart\n\n---\n\n### 9. SPEAKING STATUS & VOICE ACTIVITY\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 611-632)\n\n#### Voice Activity Flow:\n```\nClient: VoiceActivity { channel_id, speaking: bool }\n    ↓\nHandler validates:\n    1. Connection is in the specified channel\n    2. (No rate limiting on speaking events)\n    ↓\nBroadcast:\n    broadcast_voice_activity_to_channel(state, channel_id, username, speaking, None)\n    └─> Sends to all OTHER connections in channel:\n        ServerMessage::VoiceUserSpeaking {\n            channel_id,\n            username,\n            speaking\n        }\n```\n\n**Important Notes:**\n- No database recording of speaking status\n- Purely ephemeral, real-time signaling\n- No speaking history or analytics\n- Clients independently detect voice activity (VAD on client side)\n\n---\n\n### 10. PRODUCER/CONSUMER LIFECYCLE & CLEANUP\n\n**Producer Cleanup:**\n```\nWhen Producer Closed:\n    1. Removed from state.producers\n    2. Removed from native_transports_by_producer (if native)\n    3. Broadcast ClosedProducer message to channel:\n        {\n            \"action\": \"producer_closed\",\n            \"producer_id\": \"...\",\n            \"source\": \"...\",\n            \"routing_mode\": \"...\"\n        }\n```\n\n**Consumer Cleanup:**\n- No explicit cleanup endpoint\n- Consumers auto-close when producer closes\n- Manual close not exposed via WebSocket\n\n**Connection Cleanup:**\n```\nWhen Connection Disconnects:\n    1. state.media.cleanup_connection_media(connection_id)\n       └─> Removes all producers/consumers for this connection\n    2. Returns Vec<ClosedProducer>\n    3. Broadcasts closed_producers to all channels\n```\n\n---\n\n### 11. ISSUES, BUGS & ANTI-PATTERNS\n\n#### CRITICAL ISSUES:\n\n1. **Codec Settings Never Update After Router Creation**\n   - If channel opus_bitrate/dtx/fec changed after first user joins, new users don't get updated settings\n   - Router caching doesn't invalidate on channel update\n   - **Impact**: Codec configuration changes require server restart\n   - **Solution**: Invalidate router when channel settings change\n\n2. **Producer Owner Lookup Silently Fails**\n   - When recv transport created, attempts to get producer owner's username\n   - If owner connection already closed, warns but continues\n   - New consumer doesn't receive \"new_producer\" notification for that producer\n   - **Impact**: Consumer state out of sync with actual producers in channel\n   - **Suggested Fix**: Either cache producer owner info or handle gracefully\n\n3. **No Consumer Auto-Cleanup**\n   - Consumers manually managed, no automatic lifecycle\n   - When producer closes, consumers still exist in HashMap\n   - Consumer close not exposed to client\n   - **Impact**: Memory leak of stale consumers\n   - **Suggested Fix**: Auto-close consumers when producer closes\n\n4. **Duplicate Camera/Screen Check - TOCTOU**\n   - Checked before creation AND after creation\n   - Race condition: two concurrent produce requests could both pass first check\n   - **Impact**: Theoretically could create 2 cameras per connection\n   - **Suggested Fix**: Single atomic check or lock\n\n5. **No Database Persistence of Voice Membership**\n   - Voice state purely in-memory\n   - Server restart loses all state\n   - Clients don't know if they need to rejoin\n   - **Impact**: Broken user experience on server restart\n   - **Suggested Fix**: Persist voice channel membership in database\n\n#### MEDIUM ISSUES:\n\n6. **Slow Consumer Producer Notifications**\n   - When recv transport created, for each producer, sends individual notification\n   - N producers = N separate JSON broadcasts\n   - No batching/bundling of producers list\n   - **Impact**: Inefficient network usage with many producers\n   - **Suggested Fix**: Send producer list in single JSON array\n\n7. **No Bandwidth/Bitrate Enforcement**\n   - Consumers created without bitrate limits\n   - No max-bitrate set on encodings\n   - No congestion control feedback from clients\n   - **Impact**: Network overload possible\n   - **Suggested Fix**: Configure reasonable defaults or per-channel limits\n\n8. **Voice Activity Broadcasting Sends Extra Parameter**\n   - `broadcast_voice_activity_to_channel` sends to ALL except sender\n   - But the exclude_connection_id is set to None\n   - Client sends their own speaking state to themselves too\n   - **Impact**: Redundant message\n   - **Suggested Fix**: Pass Some(connection_id) to exclude self\n\n9. **No Channel Permission Checks**\n   - Join voice doesn't verify user has permission to access channel\n   - No ACL or role-based channel access control for voice\n   - **Impact**: Any authenticated user can join any voice channel\n   - **Suggested Fix**: Add channel permission model\n\n10. **Mediasoup Worker Health Not Monitored**\n    - Workers created at startup, no restart logic\n    - No health checks or deadlock detection\n    - Worker crash would cause silent failures\n    - **Impact**: Server silently stops accepting voice connections\n    - **Suggested Fix**: Add worker health monitoring and auto-restart\n\n#### MINOR ISSUES:\n\n11. **SSRC Derivation Collision Risk**\n    - Canonical SSRC uses only first 4 bytes of UUID\n    - Fallback seed only triggers if exactly 0\n    - **Impact**: Extremely low, but possible SSRC collision\n    - **Suggested Fix**: Use full UUID or CRC32 of full UUID\n\n12. **No Requested Codec Preference Validation**\n    - Client can request any codec, server just filters to ready ones\n    - No limit on preferred_codecs list length\n    - **Impact**: Mild - clients well-behaved, but no server-side guards\n\n13. **Transport Direction Replaced Without Warning**\n    - Creating send transport twice replaces first one\n    - Any media sent on old transport is lost\n    - **Impact**: Client-side bug would lose media\n    - **Suggested Fix**: Return error if transport already exists\n\n14. **Mediasoup Error Messages Exposed**\n    - mediasoup library errors directly sent to client\n    - Could expose internal implementation details\n    - **Impact**: Low security impact, but information disclosure\n\n---\n\n### 12. CONFIGURATION SETTINGS\n\n**File:** `/home/guibibi/projects/yankcord/server/src/config.rs`\n\n```rust\npub struct MediaConfig {\n    pub worker_count: usize,                    // ENV: MEDIA_WORKER_COUNT (default: 2)\n    pub webrtc_listen_ip: String,               // ENV: WEBRTC_LISTEN_IP (default: 0.0.0.0)\n    pub announced_ip: Option<String>,           // ENV: WEBRTC_ANNOUNCED_IP\n    pub native_rtp_listen_ip: String,           // ENV: NATIVE_RTP_LISTEN_IP (default: 127.0.0.1)\n    pub native_rtp_announced_ip: Option<String>,// ENV: NATIVE_RTP_ANNOUNCED_IP\n}\n```\n\n**Environment Variables:**\n- `MEDIA_WORKER_COUNT`: Number of mediasoup workers (must be ≥1)\n- `WEBRTC_LISTEN_IP`: IP for WebRTC transport to listen on\n- `WEBRTC_ANNOUNCED_IP`: Public IP announced in ICE candidates\n- `NATIVE_RTP_LISTEN_IP`: IP for native RTP screen sharing\n- `NATIVE_RTP_ANNOUNCED_IP`: Public IP for native RTP\n\n**WebSocket Configuration (hardcoded):**\n- Outbound queue capacity: 256 messages\n- Idle timeout: 45 seconds\n- Auth timeout: 15 seconds\n- Presence idle (auto-idle status): 5 minutes\n\n**Rate Limiting:**\n- Media signal: 80 events per 5 seconds per connection\n- Payload size limit: 32 KB per media signal\n\n---\n\n### 13. DATABASE SCHEMA FOR VOICE\n\n```sql\n-- Channels table (created in migrations/20260216000001_initial.sql)\nCREATE TABLE channels (\n    id              UUID PRIMARY KEY,\n    name            TEXT NOT NULL,\n    description     TEXT,\n    kind            channel_kind,  -- 'text' or 'voice'\n    position        INT NOT NULL,\n    opus_bitrate    INTEGER,       -- Opus max average bitrate (bps)\n    opus_dtx        BOOLEAN,       -- Opus discontinuous transmission\n    opus_fec        BOOLEAN,       -- Opus forward error correction\n    created_at      TIMESTAMPTZ\n);\n```\n\n**No other voice-specific tables.**\n\n**Missing Features:**\n- No voice history/recording\n- No meeting recordings\n- No voice activity timeline\n- No user voice settings per channel\n- No voice mute/deafen state persistence\n- No voice channel permissions model\n\n---\n\n### 14. KEY FILES & FUNCTIONS SUMMARY\n\n| File | Key Components | Lines |\n|------|-----------------|-------|\n| `/home/guibibi/projects/yankcord/server/src/media/mod.rs` | MediaService, worker/router lifecycle | 177 |\n| `/home/guibibi/projects/yankcord/server/src/media/router.rs` | OpusConfig, codec definitions | 91 |\n| `/home/guibibi/projects/yankcord/server/src/media/transport.rs` | WebRTC transport, producer/consumer lifecycle | 656 |\n| `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs` | Native video codec support, screen sharing | 215 |\n| `/home/guibibi/projects/yankcord/server/src/media/producer.rs` | Producer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/media/consumer.rs` | Consumer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs` | Media signaling protocol handler | 1064 |\n| `/home/guibibi/projects/yankcord/server/src/ws/voice.rs` | Voice broadcast functions | 118 |\n| `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` | Voice join/leave, main WS handler | 1416 |\n| `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` | State cleanup, connection management | 400 |\n| `/home/guibibi/projects/yankcord/server/src/ws/messages.rs` | WebSocket message types | 257 |\n\n---\n\n### 15. ARCHITECTURE DIAGRAM\n\n```\nClient\n  ↓ WebSocket Connection\n┌─────────────────────────────────┐\n│   WebSocket Handler             │\n│   - Authentication              │\n│   - Connection Management       │\n│   - Message Dispatching         │\n└─────────────────────────────────┘\n  ↓\n┌─────────────────────────────────────────────┐\n│   Media Signaling Handler                   │\n│   - Route RTP Capabilities                  │\n│   - Create WebRTC Transport                 │\n│   - Create Producer/Consumer                │\n│   - Rate Limiting (80 events/5s)            │\n└─────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────────────────────┐\n│   MediaService (SFU)                             │\n├──────────────────────────────────────────────────┤\n│  Workers (Vec<Worker>)                           │\n│    ↓                                             │\n│  Routers (HashMap<Uuid, Router>)                 │\n│    ├─ per-channel caching                        │\n│    ├─ codec config (opus, VP8, H264, etc)        │\n│    └─ RTP capability negotiation                 │\n│                                                  │\n│  ConnectionMediaState (HashMap<Uuid, State>)    │\n│    ├─ WebRTC Transports (send/recv)              │\n│    ├─ PlainTransports (native RTP)               │\n│    ├─ Producers (audio/video/screen)             │\n│    └─ Consumers (receive streams)                │\n└──────────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   In-Memory State                │\n├──────────────────────────────────┤\n│  voice_members_by_connection     │\n│    (who's in which channel)      │\n│                                  │\n│  voice_members_by_channel        │\n│    (channel membership list)     │\n│                                  │\n│  media_signal_rate_by_connection │\n│    (rate limiting state)         │\n└──────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   Database                       │\n├──────────────────────────────────┤\n│  channels:                       │\n│    - id, name, kind='voice'      │\n│    - opus_bitrate, opus_dtx,fec  │\n└──────────────────────────────────┘\n```\n\n---\n\n### 16. RECOMMENDATIONS & IMPROVEMENTS\n\n**Priority 1 (Critical):**\n1. Add database persistence for voice channel membership\n2. Invalidate router cache when channel codec settings change\n3. Fix consumer auto-cleanup when producer closes\n4. Add channel permission checks for voice access\n\n**Priority 2 (High):**\n5. Implement worker health monitoring\n6. Batch producer notifications on recv transport creation\n7. Add bitrate enforcement/limits per consumer\n8. Fix producer owner lookup failure handling\n9. Add TOCTOU guard for camera/screen limit checks\n\n**Priority 3 (Medium):**\n10. Implement consumer lifecycle management\n11. Add voice history/analytics database table\n12. Implement voice activity recording\n13. Add per-user voice settings model\n14. Implement voice mute/deafen persistence\n\n**Priority 4 (Nice to Have):**\n15. Add multiple transport error recovery\n16. Implement auto-reconnection guidance\n17. Add voice quality metrics collection\n18. Implement adaptive bitrate adjustment\n19. Support REMB/TWCC congestion control feedback\n\n---\n\n### CONCLUSION\n\nThe Yankcord voice system is a **well-architected SFU implementation** using mediasoup. It handles WebRTC connections, producer/consumer management, and signaling correctly. However, it has **several critical issues** around codec setting persistence, consumer lifecycle management, and state recovery that should be addressed before production use. The architecture is sound but needs hardening for robustness and reliability.","prompt":"Thoroughly explore the voice chat / audio / WebRTC / mediasoup related code on the SERVER side of this project. The project is at /home/guibibi/projects/yankcord.\n\nLook in server/ directory for:\n1. All voice/audio related route handlers, services, and modules\n2. Mediasoup server-side integration (workers, routers, transports, producers, consumers)\n3. WebSocket/signaling logic for voice connections\n4. Voice channel state management (who's in which channel, speaking state)\n5. SFU (Selective Forwarding Unit) architecture and configuration\n6. Mediasoup worker/router lifecycle management\n7. Transport creation and connection logic\n8. Any voice-related database models or schemas\n\nSearch broadly using patterns like: voice, audio, webrtc, mediasoup, rtc, transport, producer, consumer, router, worker, rtp, codec, mute, deafen, speaking, channel.\n\nFor each file found, read it fully and provide:\n- File path and purpose\n- Key functions/structures and what they do\n- Any issues, bugs, anti-patterns, or improvements you notice\n- How it connects to other parts of the system\n- Configuration concerns (codecs, bitrates, etc.)\n\nBe very thorough - read every relevant file completely.","result":"Now I have comprehensive information. Let me create a thorough report:\n\n## COMPREHENSIVE SERVER-SIDE VOICE CHAT / WEBRTC / MEDIASOUP ANALYSIS\n\n### EXECUTIVE SUMMARY\n\nThe Yankcord server implements a complete SFU (Selective Forwarding Unit) architecture for voice communication using mediasoup. The system manages WebRTC connections, audio/video producers and consumers, and maintains voice channel state through a combination of database persistence, in-memory state tracking, and real-time WebSocket signaling.\n\n---\n\n### 1. MEDIASOUP ARCHITECTURE & WORKER LIFECYCLE\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/mod.rs`\n\n#### Key Components:\n\n**MediaService Structure:**\n```rust\npub struct MediaService {\n    workers: Vec<Worker>,\n    routers: Arc<Mutex<HashMap<Uuid, Router>>>,\n    connection_media: Arc<Mutex<HashMap<Uuid, transport::ConnectionMediaState>>>,\n    webrtc_listen_ip: IpAddr,\n    announced_ip: Option<String>,\n    native_rtp_listen_ip: IpAddr,\n    native_rtp_announced_ip: Option<IpAddr>,\n}\n```\n\n**Worker Initialization:**\n- Creates N workers based on `MEDIA_WORKER_COUNT` configuration (default: 2)\n- Workers are created synchronously during server startup\n- Each worker is managed by mediasoup's WorkerManager\n- No documented worker lifecycle management (no restart/health-check logic)\n\n**Router Management:**\n- Routers are cached per channel_id in a HashMap\n- Router assignment uses deterministic worker selection: `channel_id.as_bytes()[0] as usize % self.workers.len()`\n- **Critical Issue**: Router caching means codec settings (opus_bitrate, opus_dtx, opus_fec) set at channel creation time are never updated after router creation, even if channel settings change\n- Routers can be manually invalidated via `invalidate_router()` to force recreation\n\n**Network Configuration:**\n- WebRTC transport listen IP and announced IP are configurable\n- Native RTP (for screen sharing) has separate listen/announced IP configuration\n- Fallback to localhost (127.0.0.1) if IP parsing fails with warnings\n\n---\n\n### 2. ROUTER & CODEC CONFIGURATION\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/router.rs`\n\n#### Opus Configuration:\n```rust\npub struct OpusConfig {\n    pub bitrate: Option<u32>,          // Max average bitrate\n    pub dtx: Option<bool>,              // Discontinuous Transmission\n    pub fec: Option<bool>,              // Forward Error Correction\n}\n```\n\n**Supported Codecs:**\n- **Audio**: Opus (48kHz, stereo, 2 channels)\n  - RTCP Feedback: TransportCc\n  - Parameters: maxaveragebitrate, usedtx, useinbandfec\n- **Video**: VP8, H.264, VP9, AV1\n  - RTCP Feedback: Nack, NackPli, CcmFir, GoogRemb, TransportCc\n  - H.264: packetization-mode=1, profile-level-id=42e01f\n\n**Configuration Concerns:**\n1. Opus parameters are applied at router creation only\n2. No runtime codec parameter updates\n3. Video codec negotiation not fully exposed to clients\n4. Database schema stores opus settings but no per-message codec negotiation\n\n**Database Schema (channels table):**\n```sql\nopus_bitrate INTEGER      -- Max bitrate in bps\nopus_dtx     BOOLEAN      -- Enable DTX\nopus_fec     BOOLEAN      -- Enable FEC\n```\n\n---\n\n### 3. TRANSPORT MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs`\n\n#### ConnectionMediaState Structure:\n```rust\npub struct ConnectionMediaState {\n    pub channel_id: Uuid,\n    pub send_transport_id: Option<String>,\n    pub recv_transport_id: Option<String>,\n    pub transports: HashMap<String, WebRtcTransport>,\n    pub native_transports_by_producer: HashMap<String, PlainTransport>,\n    pub producers: HashMap<String, ProducerEntry>,\n    pub consumers: HashMap<String, Consumer>,\n}\n```\n\n**Transport Creation:**\n1. **SendTransport**: Used for uploading audio/video from client\n   - Created per direction on demand\n   - Replaced if same direction requested again\n   - Uses WebRtcTransport with configured listen IPs\n\n2. **RecvTransport**: Used for downloading media from other participants\n   - Created per direction on demand\n   - Sends existing producers to new recv transport creators\n   - Also uses WebRtcTransport\n\n3. **PlainTransport**: Used for native screen sharing\n   - Created on demand for screen producers\n   - Uses raw RTP/UDP\n   - Comedia enabled (automatic endpoint detection)\n   - RTCP multiplexed (rtcp_mux=true)\n\n**Critical Logic Issues:**\n\n1. **Channel Validation on Send Transport Creation (Lines 154-162):**\n   - If connection switches channels, old ConnectionMediaState is cleared\n   - **Issue**: Session switching doesn't properly validate permissions\n\n2. **Duplicate Producer Check (Lines 266-282, 305-321):**\n   - Checked TWICE: once before creating and once after\n   - Race condition possible between checks\n   - Only one camera and one screen producer allowed per connection\n\n3. **Recv Transport Producer Snapshot (Lines 555-600):**\n   - When recv transport created, sends all existing channel producers\n   - **Issue**: Producer owner username lookup may fail silently (line 570-575)\n   - If owner disconnected, producer info not sent to new consumer\n\n**Producer Lifecycle:**\n```\n1. Client creates send transport\n2. Client connects send transport (DTLS handshake)\n3. Client calls MediaProduce with RTP parameters\n4. Server creates producer on send transport\n5. Producer added to state.producers HashMap\n6. Other clients notified via broadcast (\"new_producer\")\n7. Other clients create consumers on their recv transports\n8. Client can close producer via MediaCloseProducer\n```\n\n---\n\n### 4. PRODUCER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 238-340)\n\n#### ProducerSource Enum:\n```rust\npub enum ProducerSource {\n    Microphone,  // Audio only\n    Camera,      // Video only\n    Screen,      // Video only\n}\n```\n\n#### Validation Constraints:\n1. **One camera per connection**: Prevents multiple camera producers simultaneously\n2. **One screen per connection**: Prevents multiple screen shares\n3. **Microphone**: No per-connection limit (multiple microphone sources possible)\n4. **Kind/Source Validation**: Kind must match source (e.g., \"microphone\" requires kind=\"audio\")\n\n#### Producer Creation Flow:\n```\nClient sends: MediaProduce {\n    kind: \"audio\"|\"video\",\n    source: \"microphone\"|\"camera\"|\"screen\",\n    routing_mode: \"sfu\",\n    rtp_parameters: RtpParameters\n}\n\nServer:\n1. Validates routing_mode (only \"sfu\" allowed, no mesh/hybrid)\n2. Validates source matches kind\n3. Verifies send transport exists\n4. Checks camera/screen limits\n5. Creates producer with mediasoup\n6. Stores in state.producers\n7. Broadcasts to all channel members\n```\n\n---\n\n### 5. CONSUMER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 488-568)\n\n#### Consumer Creation Logic:\n```rust\npub async fn create_consumer_for_connection(\n    connection_id: Uuid,\n    channel_id: Uuid,\n    producer_id: &str,\n    rtp_capabilities: RtpCapabilities,\n) -> Result<CreatedConsumer, String>\n```\n\n**Key Properties:**\n- Created in PAUSED state: `consumer_options.paused = true`\n- Client must call `MediaResumeConsumer` to start receiving\n- RTP parameters negotiated based on client capabilities\n\n**Validations:**\n1. Producer must exist in same channel\n2. Client must be in channel\n3. Client RTP capabilities must be able to consume producer\n4. Router validates compatibility: `router.can_consume()`\n\n**Concerns:**\n- No bitrate limits enforced on consumers\n- No adaptive bitrate control\n- Consumers manually managed (no automatic cleanup on producer close)\n- No bandwidth constraints per channel\n\n---\n\n### 6. NATIVE VIDEO CODEC & SCREEN SHARING\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs`\n\n#### Native Video Codec Support:\n```rust\npub enum NativeVideoCodec {\n    H264,   // Ready - PT 96, clock_rate 90kHz\n    Vp8,    // Ready - PT 98, clock_rate 90kHz\n    Vp9,    // Ready - PT 100, clock_rate 90kHz\n    Av1,    // Ready - PT 102, clock_rate 90kHz\n}\n```\n\n#### Native Sender Session (for Screen Sharing):\n```rust\npub struct NativeSenderSession {\n    pub producer_id: String,\n    pub rtp_target: String,           // Address to send RTP to\n    pub payload_type: u8,\n    pub ssrc: u32,                    // Canonical SSRC from connection_id\n    pub mime_type: String,\n    pub clock_rate: u32,\n    pub packetization_mode: u8,       // H.264 only\n    pub profile_level_id: String,     // H.264 only\n    pub codec: NativeCodecDescriptor,\n    pub available_codecs: Vec<NativeCodecDescriptor>,\n}\n```\n\n#### Screen Sharing Flow:\n1. Client requests `CreateNativeSenderSession` with optional preferred codecs\n2. Server creates PlainTransport with comedia=true\n3. Server creates producer on transport\n4. Returns RTP target endpoint and codec parameters\n5. Client sends raw H.264/VP8/VP9/AV1 RTP packets to target\n6. Server forwards through SFU to consumers\n\n**Configuration:**\n- H.264: Packetization mode 1 (single NAL per RTP packet)\n- SSRC deterministically derived from connection_id (first 4 bytes)\n- RTCP cname formatted as `native-{ssrc:x}`\n\n**Issue**: SSRC derivation is deterministic but could theoretically collide for different connection_ids sharing same first 4 bytes. Fallback seed is 0x4E41_5456 if collision detected.\n\n---\n\n### 7. WEBSOCKET SIGNALING LAYER\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs`\n\n#### Media Signal Protocol:\n\n**Request Format:**\n```json\n{\n  \"action\": \"get_router_rtp_capabilities|create_webrtc_transport|...\",\n  \"request_id\": \"optional-string\",\n  \"...\" : \"other params\"\n}\n```\n\n**Supported Actions:**\n1. `GetRouterRtpCapabilities` - Get channel's codec capabilities\n2. `CreateWebrtcTransport` - Create send/recv transport\n3. `ConnectWebrtcTransport` - Complete DTLS handshake\n4. `MediaProduce` - Create producer\n5. `MediaConsume` - Create consumer\n6. `MediaResumeConsumer` - Resume paused consumer\n7. `MediaCloseProducer` - Close producer\n8. `CreateNativeSenderSession` - Setup screen sharing\n9. `ClientDiagnostic` - Log client diagnostics\n\n#### Rate Limiting:\n```rust\nconst MAX_MEDIA_SIGNAL_EVENTS_PER_WINDOW: u32 = 80;\nconst MEDIA_SIGNAL_RATE_WINDOW: Duration = Duration::from_secs(5);\n```\n\n**Limit**: 80 media signal events per 5-second window per connection\n\n#### Validation:\n- request_id max 128 characters\n- Payload size limit: 32 KB\n- Field constraints: direction (16), transport_id (128), kind (16), source (32), routing_mode (16)\n\n#### Error Handling:\n```rust\npub enum MediaSignalSendOutcome {\n    Delivered,\n    Dropped,    // Serialization failed\n    Disconnect, // Queue full or connection closed\n}\n```\n\n**Policy**: Close connection if outbound queue full (prevents slow-consumer problems)\n\n---\n\n### 8. VOICE CHANNEL STATE MANAGEMENT\n\n**Files:**\n- `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 605-631, 1259-1415)\n- `/home/guibibi/projects/yankcord/server/src/ws/voice.rs`\n- `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` (Lines 318-394)\n\n#### In-Memory State Maps:\n```rust\npub struct AppState {\n    // Voice channel membership\n    pub voice_members_by_connection: Arc<RwLock<HashMap<Uuid, Uuid>>>,\n                                     // connection_id -> channel_id\n    pub voice_members_by_channel: Arc<RwLock<HashMap<Uuid, HashSet<String>>>>,\n                                   // channel_id -> usernames\n    // ... other fields\n}\n```\n\n#### Join Flow:\n```\nClient: JoinVoice { channel_id }\n    ↓\nHandler validates:\n    1. Channel exists\n    2. Channel is voice-enabled\n    3. Get channel's opus config\n    ↓\nUpdate state:\n    1. voice_members_by_connection.insert(connection_id, channel_id)\n    2. If switching channels: remove from old channel, cleanup media\n    3. voice_members_by_channel.entry(channel_id).or_default().insert(username)\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserJoined\n    2. Send to client: VoiceJoined { channel_id, user_id }\n```\n\n#### Leave Flow:\n```\nClient: LeaveVoice { channel_id }\n    ↓\nHandler:\n    1. Remove from voice_members_by_connection\n    2. Remove username from voice_members_by_channel\n    3. Cleanup producers via media.cleanup_connection_media()\n    4. Broadcast closed_producers to channel\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserLeft\n    2. Send to client: VoiceLeft { channel_id, user_id }\n```\n\n#### Disconnect Handling:\nWhen WebSocket connection closes:\n1. `cleanup_connection()` called with connection_id\n2. Removes from voice_members_by_connection and voice_members_by_channel\n3. Calls `media.cleanup_connection_media()` to close all producers/consumers\n4. Broadcasts VoiceUserLeft to all channels\n5. Broadcasts closed producer info to affected channels\n\n**Critical State Issue**: \n- No database persistence of voice channel membership\n- Membership purely in-memory\n- Server restart loses all voice session state\n- Clients must rejoin voice channels after server restart\n\n---\n\n### 9. SPEAKING STATUS & VOICE ACTIVITY\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 611-632)\n\n#### Voice Activity Flow:\n```\nClient: VoiceActivity { channel_id, speaking: bool }\n    ↓\nHandler validates:\n    1. Connection is in the specified channel\n    2. (No rate limiting on speaking events)\n    ↓\nBroadcast:\n    broadcast_voice_activity_to_channel(state, channel_id, username, speaking, None)\n    └─> Sends to all OTHER connections in channel:\n        ServerMessage::VoiceUserSpeaking {\n            channel_id,\n            username,\n            speaking\n        }\n```\n\n**Important Notes:**\n- No database recording of speaking status\n- Purely ephemeral, real-time signaling\n- No speaking history or analytics\n- Clients independently detect voice activity (VAD on client side)\n\n---\n\n### 10. PRODUCER/CONSUMER LIFECYCLE & CLEANUP\n\n**Producer Cleanup:**\n```\nWhen Producer Closed:\n    1. Removed from state.producers\n    2. Removed from native_transports_by_producer (if native)\n    3. Broadcast ClosedProducer message to channel:\n        {\n            \"action\": \"producer_closed\",\n            \"producer_id\": \"...\",\n            \"source\": \"...\",\n            \"routing_mode\": \"...\"\n        }\n```\n\n**Consumer Cleanup:**\n- No explicit cleanup endpoint\n- Consumers auto-close when producer closes\n- Manual close not exposed via WebSocket\n\n**Connection Cleanup:**\n```\nWhen Connection Disconnects:\n    1. state.media.cleanup_connection_media(connection_id)\n       └─> Removes all producers/consumers for this connection\n    2. Returns Vec<ClosedProducer>\n    3. Broadcasts closed_producers to all channels\n```\n\n---\n\n### 11. ISSUES, BUGS & ANTI-PATTERNS\n\n#### CRITICAL ISSUES:\n\n1. **Codec Settings Never Update After Router Creation**\n   - If channel opus_bitrate/dtx/fec changed after first user joins, new users don't get updated settings\n   - Router caching doesn't invalidate on channel update\n   - **Impact**: Codec configuration changes require server restart\n   - **Solution**: Invalidate router when channel settings change\n\n2. **Producer Owner Lookup Silently Fails**\n   - When recv transport created, attempts to get producer owner's username\n   - If owner connection already closed, warns but continues\n   - New consumer doesn't receive \"new_producer\" notification for that producer\n   - **Impact**: Consumer state out of sync with actual producers in channel\n   - **Suggested Fix**: Either cache producer owner info or handle gracefully\n\n3. **No Consumer Auto-Cleanup**\n   - Consumers manually managed, no automatic lifecycle\n   - When producer closes, consumers still exist in HashMap\n   - Consumer close not exposed to client\n   - **Impact**: Memory leak of stale consumers\n   - **Suggested Fix**: Auto-close consumers when producer closes\n\n4. **Duplicate Camera/Screen Check - TOCTOU**\n   - Checked before creation AND after creation\n   - Race condition: two concurrent produce requests could both pass first check\n   - **Impact**: Theoretically could create 2 cameras per connection\n   - **Suggested Fix**: Single atomic check or lock\n\n5. **No Database Persistence of Voice Membership**\n   - Voice state purely in-memory\n   - Server restart loses all state\n   - Clients don't know if they need to rejoin\n   - **Impact**: Broken user experience on server restart\n   - **Suggested Fix**: Persist voice channel membership in database\n\n#### MEDIUM ISSUES:\n\n6. **Slow Consumer Producer Notifications**\n   - When recv transport created, for each producer, sends individual notification\n   - N producers = N separate JSON broadcasts\n   - No batching/bundling of producers list\n   - **Impact**: Inefficient network usage with many producers\n   - **Suggested Fix**: Send producer list in single JSON array\n\n7. **No Bandwidth/Bitrate Enforcement**\n   - Consumers created without bitrate limits\n   - No max-bitrate set on encodings\n   - No congestion control feedback from clients\n   - **Impact**: Network overload possible\n   - **Suggested Fix**: Configure reasonable defaults or per-channel limits\n\n8. **Voice Activity Broadcasting Sends Extra Parameter**\n   - `broadcast_voice_activity_to_channel` sends to ALL except sender\n   - But the exclude_connection_id is set to None\n   - Client sends their own speaking state to themselves too\n   - **Impact**: Redundant message\n   - **Suggested Fix**: Pass Some(connection_id) to exclude self\n\n9. **No Channel Permission Checks**\n   - Join voice doesn't verify user has permission to access channel\n   - No ACL or role-based channel access control for voice\n   - **Impact**: Any authenticated user can join any voice channel\n   - **Suggested Fix**: Add channel permission model\n\n10. **Mediasoup Worker Health Not Monitored**\n    - Workers created at startup, no restart logic\n    - No health checks or deadlock detection\n    - Worker crash would cause silent failures\n    - **Impact**: Server silently stops accepting voice connections\n    - **Suggested Fix**: Add worker health monitoring and auto-restart\n\n#### MINOR ISSUES:\n\n11. **SSRC Derivation Collision Risk**\n    - Canonical SSRC uses only first 4 bytes of UUID\n    - Fallback seed only triggers if exactly 0\n    - **Impact**: Extremely low, but possible SSRC collision\n    - **Suggested Fix**: Use full UUID or CRC32 of full UUID\n\n12. **No Requested Codec Preference Validation**\n    - Client can request any codec, server just filters to ready ones\n    - No limit on preferred_codecs list length\n    - **Impact**: Mild - clients well-behaved, but no server-side guards\n\n13. **Transport Direction Replaced Without Warning**\n    - Creating send transport twice replaces first one\n    - Any media sent on old transport is lost\n    - **Impact**: Client-side bug would lose media\n    - **Suggested Fix**: Return error if transport already exists\n\n14. **Mediasoup Error Messages Exposed**\n    - mediasoup library errors directly sent to client\n    - Could expose internal implementation details\n    - **Impact**: Low security impact, but information disclosure\n\n---\n\n### 12. CONFIGURATION SETTINGS\n\n**File:** `/home/guibibi/projects/yankcord/server/src/config.rs`\n\n```rust\npub struct MediaConfig {\n    pub worker_count: usize,                    // ENV: MEDIA_WORKER_COUNT (default: 2)\n    pub webrtc_listen_ip: String,               // ENV: WEBRTC_LISTEN_IP (default: 0.0.0.0)\n    pub announced_ip: Option<String>,           // ENV: WEBRTC_ANNOUNCED_IP\n    pub native_rtp_listen_ip: String,           // ENV: NATIVE_RTP_LISTEN_IP (default: 127.0.0.1)\n    pub native_rtp_announced_ip: Option<String>,// ENV: NATIVE_RTP_ANNOUNCED_IP\n}\n```\n\n**Environment Variables:**\n- `MEDIA_WORKER_COUNT`: Number of mediasoup workers (must be ≥1)\n- `WEBRTC_LISTEN_IP`: IP for WebRTC transport to listen on\n- `WEBRTC_ANNOUNCED_IP`: Public IP announced in ICE candidates\n- `NATIVE_RTP_LISTEN_IP`: IP for native RTP screen sharing\n- `NATIVE_RTP_ANNOUNCED_IP`: Public IP for native RTP\n\n**WebSocket Configuration (hardcoded):**\n- Outbound queue capacity: 256 messages\n- Idle timeout: 45 seconds\n- Auth timeout: 15 seconds\n- Presence idle (auto-idle status): 5 minutes\n\n**Rate Limiting:**\n- Media signal: 80 events per 5 seconds per connection\n- Payload size limit: 32 KB per media signal\n\n---\n\n### 13. DATABASE SCHEMA FOR VOICE\n\n```sql\n-- Channels table (created in migrations/20260216000001_initial.sql)\nCREATE TABLE channels (\n    id              UUID PRIMARY KEY,\n    name            TEXT NOT NULL,\n    description     TEXT,\n    kind            channel_kind,  -- 'text' or 'voice'\n    position        INT NOT NULL,\n    opus_bitrate    INTEGER,       -- Opus max average bitrate (bps)\n    opus_dtx        BOOLEAN,       -- Opus discontinuous transmission\n    opus_fec        BOOLEAN,       -- Opus forward error correction\n    created_at      TIMESTAMPTZ\n);\n```\n\n**No other voice-specific tables.**\n\n**Missing Features:**\n- No voice history/recording\n- No meeting recordings\n- No voice activity timeline\n- No user voice settings per channel\n- No voice mute/deafen state persistence\n- No voice channel permissions model\n\n---\n\n### 14. KEY FILES & FUNCTIONS SUMMARY\n\n| File | Key Components | Lines |\n|------|-----------------|-------|\n| `/home/guibibi/projects/yankcord/server/src/media/mod.rs` | MediaService, worker/router lifecycle | 177 |\n| `/home/guibibi/projects/yankcord/server/src/media/router.rs` | OpusConfig, codec definitions | 91 |\n| `/home/guibibi/projects/yankcord/server/src/media/transport.rs` | WebRTC transport, producer/consumer lifecycle | 656 |\n| `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs` | Native video codec support, screen sharing | 215 |\n| `/home/guibibi/projects/yankcord/server/src/media/producer.rs` | Producer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/media/consumer.rs` | Consumer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs` | Media signaling protocol handler | 1064 |\n| `/home/guibibi/projects/yankcord/server/src/ws/voice.rs` | Voice broadcast functions | 118 |\n| `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` | Voice join/leave, main WS handler | 1416 |\n| `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` | State cleanup, connection management | 400 |\n| `/home/guibibi/projects/yankcord/server/src/ws/messages.rs` | WebSocket message types | 257 |\n\n---\n\n### 15. ARCHITECTURE DIAGRAM\n\n```\nClient\n  ↓ WebSocket Connection\n┌─────────────────────────────────┐\n│   WebSocket Handler             │\n│   - Authentication              │\n│   - Connection Management       │\n│   - Message Dispatching         │\n└─────────────────────────────────┘\n  ↓\n┌─────────────────────────────────────────────┐\n│   Media Signaling Handler                   │\n│   - Route RTP Capabilities                  │\n│   - Create WebRTC Transport                 │\n│   - Create Producer/Consumer                │\n│   - Rate Limiting (80 events/5s)            │\n└─────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────────────────────┐\n│   MediaService (SFU)                             │\n├──────────────────────────────────────────────────┤\n│  Workers (Vec<Worker>)                           │\n│    ↓                                             │\n│  Routers (HashMap<Uuid, Router>)                 │\n│    ├─ per-channel caching                        │\n│    ├─ codec config (opus, VP8, H264, etc)        │\n│    └─ RTP capability negotiation                 │\n│                                                  │\n│  ConnectionMediaState (HashMap<Uuid, State>)    │\n│    ├─ WebRTC Transports (send/recv)              │\n│    ├─ PlainTransports (native RTP)               │\n│    ├─ Producers (audio/video/screen)             │\n│    └─ Consumers (receive streams)                │\n└──────────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   In-Memory State                │\n├──────────────────────────────────┤\n│  voice_members_by_connection     │\n│    (who's in which channel)      │\n│                                  │\n│  voice_members_by_channel        │\n│    (channel membership list)     │\n│                                  │\n│  media_signal_rate_by_connection │\n│    (rate limiting state)         │\n└──────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   Database                       │\n├──────────────────────────────────┤\n│  channels:                       │\n│    - id, name, kind='voice'      │\n│    - opus_bitrate, opus_dtx,fec  │\n└──────────────────────────────────┘\n```\n\n---\n\n### 16. RECOMMENDATIONS & IMPROVEMENTS\n\n**Priority 1 (Critical):**\n1. Add database persistence for voice channel membership\n2. Invalidate router cache when channel codec settings change\n3. Fix consumer auto-cleanup when producer closes\n4. Add channel permission checks for voice access\n\n**Priority 2 (High):**\n5. Implement worker health monitoring\n6. Batch producer notifications on recv transport creation\n7. Add bitrate enforcement/limits per consumer\n8. Fix producer owner lookup failure handling\n9. Add TOCTOU guard for camera/screen limit checks\n\n**Priority 3 (Medium):**\n10. Implement consumer lifecycle management\n11. Add voice history/analytics database table\n12. Implement voice activity recording\n13. Add per-user voice settings model\n14. Implement voice mute/deafen persistence\n\n**Priority 4 (Nice to Have):**\n15. Add multiple transport error recovery\n16. Implement auto-reconnection guidance\n17. Add voice quality metrics collection\n18. Implement adaptive bitrate adjustment\n19. Support REMB/TWCC congestion control feedback\n\n---\n\n### CONCLUSION\n\nThe Yankcord voice system is a **well-architected SFU implementation** using mediasoup. It handles WebRTC connections, producer/consumer management, and signaling correctly. However, it has **several critical issues** around codec setting persistence, consumer lifecycle management, and state recovery that should be addressed before production use. The architecture is sound but needs hardening for robustness and reliability."}},"sourceToolAssistantUUID":"63b23aaa-aa06-4500-bfc6-18a329a8645d"}
{"type":"queue-operation","operation":"enqueue","timestamp":"2026-02-23T14:49:13.720Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","content":"<task-notification>\n<task-id>af8b6d8</task-id>\n<tool-use-id>toolu_01JiBfoph47qJdUduVVbVC9r</tool-use-id>\n<status>completed</status>\n<summary>Agent \"Explore Tauri voice integration\" completed</summary>\n<result>Perfect! Now I have all the information I need. Let me compile my comprehensive findings:\n\n## Comprehensive Exploration: Tauri Desktop Client Voice Chat Module\n\n### Executive Summary\n\nThe Yankcord application uses **WebRTC via mediasoup-client** for voice communication, with **both web and Tauri clients sharing the same audio/voice logic**. The Tauri desktop client does NOT have separate audio handling - instead, it provides **native screen capture for video streaming** while delegating all voice/audio functionality to browser WebRTC APIs through the Chromium-based Tauri webview.\n\n---\n\n### 1. Tauri Backend (Rust) - /home/guibibi/projects/yankcord/client/src-tauri/\n\n#### Structure:\n- **Main entry point**: `/home/guibibi/projects/yankcord/client/src-tauri/src/main.rs` - Minimal Tauri bootstrap\n- **Core logic**: `/home/guibibi/projects/yankcord/client/src-tauri/src/lib.rs`\n\n#### Key Files:\n\n**lib.rs**:\n```rust\npub fn run() {\n    tauri::Builder::default()\n        .manage(capture::service::NativeCaptureService::default())\n        .plugin(tauri_plugin_opener::init())\n        .plugin(tauri_plugin_notification::init())\n        .plugin(tauri_plugin_updater::Builder::new().build())\n        .invoke_handler(tauri::generate_handler![\n            capture::service::list_native_capture_sources,\n            capture::service::native_codec_capabilities,\n            capture::service::start_native_capture,\n            capture::service::stop_native_capture,\n            capture::service::native_capture_status\n        ])\n```\n\n**Tauri Commands Exposed**:\n1. `list_native_capture_sources` - Lists available screens/windows/applications to capture\n2. `native_codec_capabilities` - Reports available video codecs (H264, VP8, VP9, AV1)\n3. `start_native_capture` - Initiates native screen/window capture with specified codec, resolution, FPS, bitrate\n4. `stop_native_capture` - Stops active native capture\n5. `native_capture_status` - Returns detailed metrics on encoding, RTP transmission, performance\n\n**No Tauri Commands for Audio**: The Rust backend provides **zero audio-related Tauri commands**. All voice/audio functionality is handled entirely through browser WebRTC APIs.\n\n#### Dependencies:\n- `tauri = { version = \"2\", features = [] }`\n- `tauri-plugin-opener = \"2\"` - Open URLs/files\n- `tauri-plugin-notification = \"2\"` - Desktop notifications\n- `tauri-plugin-updater = \"2\"` - App auto-updates\n- **No audio libraries** (no cpal, rodio, dasp, etc.)\n\n#### Capabilities:\nFile: `/home/guibibi/projects/yankcord/client/src-tauri/capabilities/default.json`\n\n```json\n{\n  \"permissions\": [\n    \"core:default\",\n    \"core:window:allow-close\",\n    \"core:window:allow-minimize\",\n    \"core:window:allow-toggle-maximize\",\n    \"core:window:allow-start-dragging\",\n    \"opener:default\",\n    \"notification:default\",\n    \"updater:default\"\n  ]\n}\n```\n\n**No WebRTC or audio permissions defined** - Tauri delegates these to the webview's built-in browser permissions system.\n\n---\n\n### 2. Frontend WebRTC Voice Architecture - /home/guibibi/projects/yankcord/client/src/\n\n#### Core Voice Stack:\n- **MediaSoup Client** (`mediasoup-client@3.18.6`) - SFU WebRTC protocol\n- **Web Audio API** - For microphone monitoring and audio processing\n- **getUserMedia API** - For microphone and speaker device enumeration\n- **All audio handled through browser webview** - NO native Rust audio handling\n\n#### Voice-Related Files:\n\n**API Modules** (`/client/src/api/media/`):\n\n1. **nativeCapture.ts** - Tauri bridge for screen capture (NOT audio)\n   - Defines types: `NativeCaptureSource`, `StartNativeCaptureRequest`, `NativeCaptureStatus`\n   - Calls Tauri commands via `invoke()` from `@tauri-apps/api/core`\n   - Used for screen sharing only, not voice\n\n2. **voiceActivity.ts** - Microphone level monitoring and speaking detection\n   ```typescript\n   export function startMicLevelMonitoring(channelId: string, stream: MediaStream) {\n     const audioContext = new AudioContext();\n     const analyserNode = audioContext.createAnalyser();\n     analyserNode.fftSize = 512;\n     analyserNode.smoothingTimeConstant = 0.85;\n     \n     // Monitors RMS level, reports speaking activity via reportVoiceActivity()\n   }\n   ```\n   - Detects voice activity using RMS (root mean square) analysis\n   - Reports to server via WebSocket signaling\n   - **Platform agnostic** - same code for web and Tauri\n\n3. **microphoneProcessing.ts** - Audio gain/volume control\n   ```typescript\n   export function createProcessedMicrophoneTrack(\n     stream: MediaStream, \n     volume: number, \n     muted: boolean\n   ): MicrophoneProcessingSession\n   ```\n   - Creates AudioContext with GainNode for outgoing volume adjustment\n   - Applies muting/unmuting to source and processed tracks\n   - **Pure Web Audio API** - zero native code\n\n4. **devices.ts** - Microphone and speaker device management\n   ```typescript\n   export async function listAudioDevices(): Promise<AudioDeviceInventory> {\n     const devices = await navigator.mediaDevices.enumerateDevices();\n   }\n   \n   export async function setPreferredMicrophoneDevice(deviceId: string | null) {\n     const nextStream = await navigator.mediaDevices.getUserMedia({\n       audio: audioInputConstraint(deviceId)\n     });\n   }\n   ```\n   - Uses standard `navigator.mediaDevices` APIs\n   - Supports speaker selection via `audio.setSinkId()` when available\n   - **Zero Tauri-specific code**\n\n5. **constraints.ts** - MediaTrackConstraints builder\n   ```typescript\n   export function audioInputConstraint(deviceId: string | null): MediaTrackConstraints | boolean {\n     const constraints: MediaTrackConstraints = {};\n     const supportedConstraints = navigator.mediaDevices?.getSupportedConstraints?.();\n     \n     if (supportedConstraints?.noiseSuppression) {\n       constraints.noiseSuppression = voiceNoiseSuppressionEnabled();\n     }\n     if (supportedConstraints?.echoCancellation) {\n       constraints.echoCancellation = voiceEchoCancellationEnabled();\n     }\n   }\n   ```\n   - Applies noise suppression (via WebRTC's libwebrtc)\n   - Applies echo cancellation (via browser's built-in AEC)\n   - Channel count: mono (1 channel)\n\n6. **consumers.ts** - Remote audio playback (remote participants)\n   - Creates HTML audio elements for each remote participant\n   - Routes audio through Web Audio API for per-user volume control\n   - Uses DynamicsCompressorNode for \"auto level incoming voices\" feature\n   ```typescript\n   function configureNormalizationNode(node: DynamicsCompressorNode, enabled: boolean) {\n     if (enabled) {\n       node.threshold.value = -24;\n       node.knee.value = 20;\n       node.ratio.value = 3;\n       node.attack.value = 0.003;\n       node.release.value = 0.25;\n     }\n   }\n   ```\n\n7. **producers.ts** - Local audio/video producer setup\n   - Creates microphone producer via `sendTransport.produce()`\n   - Creates camera producer for video\n   - Creates screen share producer (uses native Tauri capture on desktop)\n\n8. **signaling.ts** - WebSocket protocol for media negotiation\n   - Reports voice activity to server\n   - Requests media signal for producer/consumer setup\n   - No direct audio signaling\n\n9. **transports.ts** - WebRTC transport (DTLS/ICE) initialization\n   - Handles DTLS parameter negotiation\n   - Monitors transport health\n   - Cleanup on disconnect\n\n10. **codecs.ts** - Codec selection\n    ```typescript\n    export function selectScreenShareCodecForPlatform(): ProduceCodec | undefined {\n      // Prefers H264 > VP8 > VP9\n      // Platform-aware but applies to screen share only\n    }\n    \n    export function nativePreferredCodecsFor(): string[] {\n      return [\"video/H264\"]; // For native Tauri screen capture\n    }\n    ```\n\n#### Voice Settings Storage:\nFile: `/client/src/stores/settings.ts`\n\n```typescript\nconst AUDIO_INPUT_KEY = \"yankcord_audio_input_device_id\";\nconst AUDIO_OUTPUT_KEY = \"yankcord_audio_output_device_id\";\nconst VOICE_AUTO_LEVEL_ENABLED_KEY = \"yankcord_voice_auto_level_enabled\";\nconst VOICE_NOISE_SUPPRESSION_ENABLED_KEY = \"yankcord_voice_noise_suppression_enabled\";\nconst VOICE_ECHO_CANCELLATION_ENABLED_KEY = \"yankcord_voice_echo_cancellation_enabled\";\nconst VOICE_INCOMING_VOLUME_KEY = \"yankcord_voice_incoming_volume\";\nconst VOICE_OUTGOING_VOLUME_KEY = \"yankcord_voice_outgoing_volume\";\n```\n\nAll settings stored in **localStorage** - same for web and Tauri.\n\n#### Voice State Management:\nFile: `/client/src/stores/voice.ts` - Tracks:\n- `joinedVoiceChannelId` - Current voice channel\n- `participantsByChannel` - Who's in each channel\n- `speakingByChannel` - Who's currently speaking\n- `voiceActionState` - \"idle\" | \"joining\" | \"leaving\"\n- `micMuted` - Local mute state\n- `speakerMuted` - Remote audio mute\n- `cameraEnabled`, `screenShareEnabled` - Video states\n- `transportHealth` - WebRTC connection quality\n- Video tile subscriptions for remote video streams\n\n#### Voice UI Components:\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice channel participant display\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings UI\n- Noise suppression, echo cancellation, volume controls (both incoming/outgoing)\n\n---\n\n### 3. Key Differences Between Web and Tauri Clients\n\n#### Audio/Voice:\n- **Web Client**: Uses browser WebRTC, browser's audio device enumeration\n- **Tauri Client**: **Identical** - Same WebRTC via Tauri's Chromium webview, browser audio device enumeration\n- **No difference** in how voices are captured, processed, or transmitted\n\n#### Screen Sharing:\n- **Web Client**: Uses `navigator.mediaDevices.getDisplayMedia()` (browser picker)\n- **Tauri Client**: Uses native Tauri commands for screen/window capture, can pass native source IDs, supports hardware-accelerated H264/NVENC encoding\n  - Fallback to browser capture if native fails\n  - Native capture is **video-only** (no audio)\n\n#### Platform Detection:\nFile: `/client/src/utils/platform.ts`\n\n```typescript\nexport function isTauriRuntime(): boolean {\n  return typeof window.__TAURI_INTERNALS__ !== \"undefined\";\n}\n```\n\nUsed to:\n1. Attempt native screen capture first on Tauri\n2. Check Windows platform for codec preferences\n3. Enable NVENC hardware encoding feature flags\n\n---\n\n### 4. Native Audio Handling - Summary\n\n**There is NO native audio handling in the Tauri client.**\n\nAudio flows:\n1. **Outgoing**: \n   - `navigator.mediaDevices.getUserMedia()` → microphone stream\n   - WebAudioAPI GainNode for volume adjustment\n   - Sent to server via WebRTC (mediasoup)\n\n2. **Incoming**:\n   - Received via WebRTC consumer\n   - Routed to HTML audio element\n   - Optional Web Audio API GainNode for per-user volume control\n   - Optional DynamicsCompressorNode for auto-normalization\n\n3. **Processing**:\n   - Noise suppression: Browser's WebRTC libwebrtc (constraint-based)\n   - Echo cancellation: Browser's WebRTC libwebrtc (constraint-based)\n   - Voice activity detection: Custom JavaScript using Web Audio API FFT analysis\n\n---\n\n### 5. Recent Voice Improvements\n\nRecent commit: **4cd8bfa** (\"feat: improve voice connectivity\")\n\nChanges include:\n- Improved transport health monitoring\n- Better consumer audio routing\n- Enhanced subscription system for media state\n- Per-user volume control via DynamicsCompressor normalization\n- Auto-level incoming voices feature\n\n**No Tauri-specific changes** - all improvements are browser-level WebRTC optimizations.\n\n---\n\n### 6. Tauri Configuration\n\nFile: `/client/src-tauri/tauri.conf.json`\n\n```json\n{\n  \"app\": {\n    \"windows\": [{\n      \"title\": \"Yankcord\",\n      \"decorations\": false,\n      \"width\": 1280,\n      \"height\": 800\n    }],\n    \"security\": {\n      \"csp\": \"default-src 'self'; connect-src 'self' https: http: wss: ws:; img-src 'self' data: blob: https: http:; style-src 'self' 'unsafe-inline'\"\n    }\n  }\n}\n```\n\n**CSP allows**:\n- WebSocket connections (wss: ws:) - for voice signaling\n- HTTPS/HTTP - for API calls\n- Blob resources - for media streams\n\n**No WebRTC-specific CSP rules** - Tauri's webview handles this internally.\n\n---\n\n### 7. Files Summary\n\n#### Tauri Rust Code (NO voice/audio):\n- `/client/src-tauri/src/main.rs` - Entry point (181 bytes)\n- `/client/src-tauri/src/lib.rs` - Tauri app setup, command handlers (764 bytes)\n- `/client/src-tauri/src/capture/` - Screen capture backend (video only)\n  - No audio dependencies or code\n\n#### Frontend Voice Code (Browser WebRTC):\n- `/client/src/api/media/` - 15 files, all platform-agnostic WebRTC/Web Audio\n- `/client/src/api/nativeCapture.ts` - Tauri bridge (screen capture only)\n- `/client/src/stores/voice.ts` - Voice state management\n- `/client/src/stores/settings.ts` - Audio preferences storage\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice UI\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings panel\n\n#### Configuration:\n- `/client/src-tauri/Cargo.toml` - No audio libraries\n- `/client/src-tauri/capabilities/default.json` - No WebRTC permissions (delegated to webview)\n- `/client/package.json` - Only `@tauri-apps/api` used, not for audio\n\n---\n\n### Conclusion\n\nThe Tauri desktop client **reuses 100% of the web client's voice implementation**. There are no separate audio capture, processing, or transmission paths. The Tauri backend provides:\n\n1. **Native screen capture for video** (not audio)\n2. **Standard Tauri plugins** (notifications, updates, opener)\n3. **No audio-specific functionality**\n\nAll voice/audio features use the browser's WebRTC stack through Tauri's Chromium webview:\n- Device enumeration via `navigator.mediaDevices`\n- Audio processing via Web Audio API\n- Transmission via mediasoup-client\n- Noise suppression/echo cancellation via browser's libwebrtc constraints\n\nThis is a **correct and efficient architecture** - native audio APIs would add complexity without benefit, as WebRTC already provides optimized audio capture and processing.</result>\n<usage><total_tokens>68069</total_tokens><tool_uses>44</tool_uses><duration_ms>143681</duration_ms></usage>\n</task-notification>\nFull transcript available at: REDACTED.output"}
{"parentUuid":"442e756c-0dbc-4207-9ca9-1003e721a020","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_019cUodk9CS9suZ11wqTGAfd","type":"message","role":"assistant","content":[{"type":"text","text":"Good, client and server reports are in. Let me get the Tauri agent's results too."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7585,"cache_read_input_tokens":32203,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7585},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBjbNUgJJ9CskF946PN","type":"assistant","uuid":"a1dfef2b-d2d1-4129-a33f-51e8dcd1f0c7","timestamp":"2026-02-23T14:49:15.902Z"}
{"parentUuid":"a1dfef2b-d2d1-4129-a33f-51e8dcd1f0c7","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_019cUodk9CS9suZ11wqTGAfd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0197Vng2seNzRhpTFHyajkUh","name":"TaskOutput","input":{"task_id":"af8b6d8","block":true,"timeout":120000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7585,"cache_read_input_tokens":32203,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7585},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBjbNUgJJ9CskF946PN","type":"assistant","uuid":"a90bcf10-27ba-4d8f-83dd-c560af5ee9cd","timestamp":"2026-02-23T14:49:16.636Z"}
{"parentUuid":"a90bcf10-27ba-4d8f-83dd-c560af5ee9cd","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"waiting_for_task","taskDescription":"Explore Tauri voice integration","taskType":"local_agent"},"toolUseID":"task-output-waiting-1771858156638","parentToolUseID":"toolu_0197Vng2seNzRhpTFHyajkUh","uuid":"4993cdcf-d616-4715-9c5c-50f880583d60","timestamp":"2026-02-23T14:49:16.638Z"}
{"parentUuid":"a90bcf10-27ba-4d8f-83dd-c560af5ee9cd","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0197Vng2seNzRhpTFHyajkUh","type":"tool_result","content":"<retrieval_status>success</retrieval_status>\n\n<task_id>af8b6d8</task_id>\n\n<task_type>local_agent</task_type>\n\n<status>completed</status>\n\n<output>\nPerfect! Now I have all the information I need. Let me compile my comprehensive findings:\n\n## Comprehensive Exploration: Tauri Desktop Client Voice Chat Module\n\n### Executive Summary\n\nThe Yankcord application uses **WebRTC via mediasoup-client** for voice communication, with **both web and Tauri clients sharing the same audio/voice logic**. The Tauri desktop client does NOT have separate audio handling - instead, it provides **native screen capture for video streaming** while delegating all voice/audio functionality to browser WebRTC APIs through the Chromium-based Tauri webview.\n\n---\n\n### 1. Tauri Backend (Rust) - /home/guibibi/projects/yankcord/client/src-tauri/\n\n#### Structure:\n- **Main entry point**: `/home/guibibi/projects/yankcord/client/src-tauri/src/main.rs` - Minimal Tauri bootstrap\n- **Core logic**: `/home/guibibi/projects/yankcord/client/src-tauri/src/lib.rs`\n\n#### Key Files:\n\n**lib.rs**:\n```rust\npub fn run() {\n    tauri::Builder::default()\n        .manage(capture::service::NativeCaptureService::default())\n        .plugin(tauri_plugin_opener::init())\n        .plugin(tauri_plugin_notification::init())\n        .plugin(tauri_plugin_updater::Builder::new().build())\n        .invoke_handler(tauri::generate_handler![\n            capture::service::list_native_capture_sources,\n            capture::service::native_codec_capabilities,\n            capture::service::start_native_capture,\n            capture::service::stop_native_capture,\n            capture::service::native_capture_status\n        ])\n```\n\n**Tauri Commands Exposed**:\n1. `list_native_capture_sources` - Lists available screens/windows/applications to capture\n2. `native_codec_capabilities` - Reports available video codecs (H264, VP8, VP9, AV1)\n3. `start_native_capture` - Initiates native screen/window capture with specified codec, resolution, FPS, bitrate\n4. `stop_native_capture` - Stops active native capture\n5. `native_capture_status` - Returns detailed metrics on encoding, RTP transmission, performance\n\n**No Tauri Commands for Audio**: The Rust backend provides **zero audio-related Tauri commands**. All voice/audio functionality is handled entirely through browser WebRTC APIs.\n\n#### Dependencies:\n- `tauri = { version = \"2\", features = [] }`\n- `tauri-plugin-opener = \"2\"` - Open URLs/files\n- `tauri-plugin-notification = \"2\"` - Desktop notifications\n- `tauri-plugin-updater = \"2\"` - App auto-updates\n- **No audio libraries** (no cpal, rodio, dasp, etc.)\n\n#### Capabilities:\nFile: `/home/guibibi/projects/yankcord/client/src-tauri/capabilities/default.json`\n\n```json\n{\n  \"permissions\": [\n    \"core:default\",\n    \"core:window:allow-close\",\n    \"core:window:allow-minimize\",\n    \"core:window:allow-toggle-maximize\",\n    \"core:window:allow-start-dragging\",\n    \"opener:default\",\n    \"notification:default\",\n    \"updater:default\"\n  ]\n}\n```\n\n**No WebRTC or audio permissions defined** - Tauri delegates these to the webview's built-in browser permissions system.\n\n---\n\n### 2. Frontend WebRTC Voice Architecture - /home/guibibi/projects/yankcord/client/src/\n\n#### Core Voice Stack:\n- **MediaSoup Client** (`mediasoup-client@3.18.6`) - SFU WebRTC protocol\n- **Web Audio API** - For microphone monitoring and audio processing\n- **getUserMedia API** - For microphone and speaker device enumeration\n- **All audio handled through browser webview** - NO native Rust audio handling\n\n#### Voice-Related Files:\n\n**API Modules** (`/client/src/api/media/`):\n\n1. **nativeCapture.ts** - Tauri bridge for screen capture (NOT audio)\n   - Defines types: `NativeCaptureSource`, `StartNativeCaptureRequest`, `NativeCaptureStatus`\n   - Calls Tauri commands via `invoke()` from `@tauri-apps/api/core`\n   - Used for screen sharing only, not voice\n\n2. **voiceActivity.ts** - Microphone level monitoring and speaking detection\n   ```typescript\n   export function startMicLevelMonitoring(channelId: string, stream: MediaStream) {\n     const audioContext = new AudioContext();\n     const analyserNode = audioContext.createAnalyser();\n     analyserNode.fftSize = 512;\n     analyserNode.smoothingTimeConstant = 0.85;\n     \n     // Monitors RMS level, reports speaking activity via reportVoiceActivity()\n   }\n   ```\n   - Detects voice activity using RMS (root mean square) analysis\n   - Reports to server via WebSocket signaling\n   - **Platform agnostic** - same code for web and Tauri\n\n3. **microphoneProcessing.ts** - Audio gain/volume control\n   ```typescript\n   export function createProcessedMicrophoneTrack(\n     stream: MediaStream, \n     volume: number, \n     muted: boolean\n   ): MicrophoneProcessingSession\n   ```\n   - Creates AudioContext with GainNode for outgoing volume adjustment\n   - Applies muting/unmuting to source and processed tracks\n   - **Pure Web Audio API** - zero native code\n\n4. **devices.ts** - Microphone and speaker device management\n   ```typescript\n   export async function listAudioDevices(): Promise<AudioDeviceInventory> {\n     const devices = await navigator.mediaDevices.enumerateDevices();\n   }\n   \n   export async function setPreferredMicrophoneDevice(deviceId: string | null) {\n     const nextStream = await navigator.mediaDevices.getUserMedia({\n       audio: audioInputConstraint(deviceId)\n     });\n   }\n   ```\n   - Uses standard `navigator.mediaDevices` APIs\n   - Supports speaker selection via `audio.setSinkId()` when available\n   - **Zero Tauri-specific code**\n\n5. **constraints.ts** - MediaTrackConstraints builder\n   ```typescript\n   export function audioInputConstraint(deviceId: string | null): MediaTrackConstraints | boolean {\n     const constraints: MediaTrackConstraints = {};\n     const supportedConstraints = navigator.mediaDevices?.getSupportedConstraints?.();\n     \n     if (supportedConstraints?.noiseSuppression) {\n       constraints.noiseSuppression = voiceNoiseSuppressionEnabled();\n     }\n     if (supportedConstraints?.echoCancellation) {\n       constraints.echoCancellation = voiceEchoCancellationEnabled();\n     }\n   }\n   ```\n   - Applies noise suppression (via WebRTC's libwebrtc)\n   - Applies echo cancellation (via browser's built-in AEC)\n   - Channel count: mono (1 channel)\n\n6. **consumers.ts** - Remote audio playback (remote participants)\n   - Creates HTML audio elements for each remote participant\n   - Routes audio through Web Audio API for per-user volume control\n   - Uses DynamicsCompressorNode for \"auto level incoming voices\" feature\n   ```typescript\n   function configureNormalizationNode(node: DynamicsCompressorNode, enabled: boolean) {\n     if (enabled) {\n       node.threshold.value = -24;\n       node.knee.value = 20;\n       node.ratio.value = 3;\n       node.attack.value = 0.003;\n       node.release.value = 0.25;\n     }\n   }\n   ```\n\n7. **producers.ts** - Local audio/video producer setup\n   - Creates microphone producer via `sendTransport.produce()`\n   - Creates camera producer for video\n   - Creates screen share producer (uses native Tauri capture on desktop)\n\n8. **signaling.ts** - WebSocket protocol for media negotiation\n   - Reports voice activity to server\n   - Requests media signal for producer/consumer setup\n   - No direct audio signaling\n\n9. **transports.ts** - WebRTC transport (DTLS/ICE) initialization\n   - Handles DTLS parameter negotiation\n   - Monitors transport health\n   - Cleanup on disconnect\n\n10. **codecs.ts** - Codec selection\n    ```typescript\n    export function selectScreenShareCodecForPlatform(): ProduceCodec | undefined {\n      // Prefers H264 > VP8 > VP9\n      // Platform-aware but applies to screen share only\n    }\n    \n    export function nativePreferredCodecsFor(): string[] {\n      return [\"video/H264\"]; // For native Tauri screen capture\n    }\n    ```\n\n#### Voice Settings Storage:\nFile: `/client/src/stores/settings.ts`\n\n```typescript\nconst AUDIO_INPUT_KEY = \"yankcord_audio_input_device_id\";\nconst AUDIO_OUTPUT_KEY = \"yankcord_audio_output_device_id\";\nconst VOICE_AUTO_LEVEL_ENABLED_KEY = \"yankcord_voice_auto_level_enabled\";\nconst VOICE_NOISE_SUPPRESSION_ENABLED_KEY = \"yankcord_voice_noise_suppression_enabled\";\nconst VOICE_ECHO_CANCELLATION_ENABLED_KEY = \"yankcord_voice_echo_cancellation_enabled\";\nconst VOICE_INCOMING_VOLUME_KEY = \"yankcord_voice_incoming_volume\";\nconst VOICE_OUTGOING_VOLUME_KEY = \"yankcord_voice_outgoing_volume\";\n```\n\nAll settings stored in **localStorage** - same for web and Tauri.\n\n#### Voice State Management:\nFile: `/client/src/stores/voice.ts` - Tracks:\n- `joinedVoiceChannelId` - Current voice channel\n- `participantsByChannel` - Who's in each channel\n- `speakingByChannel` - Who's currently speaking\n- `voiceActionState` - \"idle\" | \"joining\" | \"leaving\"\n- `micMuted` - Local mute state\n- `speakerMuted` - Remote audio mute\n- `cameraEnabled`, `screenShareEnabled` - Video states\n- `transportHealth` - WebRTC connection quality\n- Video tile subscriptions for remote video streams\n\n#### Voice UI Components:\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice channel participant display\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings UI\n- Noise suppression, echo cancellation, volume controls (both incoming/outgoing)\n\n---\n\n### 3. Key Differences Between Web and Tauri Clients\n\n#### Audio/Voice:\n- **Web Client**: Uses browser WebRTC, browser's audio device enumeration\n- **Tauri Client**: **Identical** - Same WebRTC via Tauri's Chromium webview, browser audio device enumeration\n- **No difference** in how voices are captured, processed, or transmitted\n\n#### Screen Sharing:\n- **Web Client**: Uses `navigator.mediaDevices.getDisplayMedia()` (browser picker)\n- **Tauri Client**: Uses native Tauri commands for screen/window capture, can pass native source IDs, supports hardware-accelerated H264/NVENC encoding\n  - Fallback to browser capture if native fails\n  - Native capture is **video-only** (no audio)\n\n#### Platform Detection:\nFile: `/client/src/utils/platform.ts`\n\n```typescript\nexport function isTauriRuntime(): boolean {\n  return typeof window.__TAURI_INTERNALS__ !== \"undefined\";\n}\n```\n\nUsed to:\n1. Attempt native screen capture first on Tauri\n2. Check Windows platform for codec preferences\n3. Enable NVENC hardware encoding feature flags\n\n---\n\n### 4. Native Audio Handling - Summary\n\n**There is NO native audio handling in the Tauri client.**\n\nAudio flows:\n1. **Outgoing**: \n   - `navigator.mediaDevices.getUserMedia()` → microphone stream\n   - WebAudioAPI GainNode for volume adjustment\n   - Sent to server via WebRTC (mediasoup)\n\n2. **Incoming**:\n   - Received via WebRTC consumer\n   - Routed to HTML audio element\n   - Optional Web Audio API GainNode for per-user volume control\n   - Optional DynamicsCompressorNode for auto-normalization\n\n3. **Processing**:\n   - Noise suppression: Browser's WebRTC libwebrtc (constraint-based)\n   - Echo cancellation: Browser's WebRTC libwebrtc (constraint-based)\n   - Voice activity detection: Custom JavaScript using Web Audio API FFT analysis\n\n---\n\n### 5. Recent Voice Improvements\n\nRecent commit: **4cd8bfa** (\"feat: improve voice connectivity\")\n\nChanges include:\n- Improved transport health monitoring\n- Better consumer audio routing\n- Enhanced subscription system for media state\n- Per-user volume control via DynamicsCompressor normalization\n- Auto-level incoming voices feature\n\n**No Tauri-specific changes** - all improvements are browser-level WebRTC optimizations.\n\n---\n\n### 6. Tauri Configuration\n\nFile: `/client/src-tauri/tauri.conf.json`\n\n```json\n{\n  \"app\": {\n    \"windows\": [{\n      \"title\": \"Yankcord\",\n      \"decorations\": false,\n      \"width\": 1280,\n      \"height\": 800\n    }],\n    \"security\": {\n      \"csp\": \"default-src 'self'; connect-src 'self' https: http: wss: ws:; img-src 'self' data: blob: https: http:; style-src 'self' 'unsafe-inline'\"\n    }\n  }\n}\n```\n\n**CSP allows**:\n- WebSocket connections (wss: ws:) - for voice signaling\n- HTTPS/HTTP - for API calls\n- Blob resources - for media streams\n\n**No WebRTC-specific CSP rules** - Tauri's webview handles this internally.\n\n---\n\n### 7. Files Summary\n\n#### Tauri Rust Code (NO voice/audio):\n- `/client/src-tauri/src/main.rs` - Entry point (181 bytes)\n- `/client/src-tauri/src/lib.rs` - Tauri app setup, command handlers (764 bytes)\n- `/client/src-tauri/src/capture/` - Screen capture backend (video only)\n  - No audio dependencies or code\n\n#### Frontend Voice Code (Browser WebRTC):\n- `/client/src/api/media/` - 15 files, all platform-agnostic WebRTC/Web Audio\n- `/client/src/api/nativeCapture.ts` - Tauri bridge (screen capture only)\n- `/client/src/stores/voice.ts` - Voice state management\n- `/client/src/stores/settings.ts` - Audio preferences storage\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice UI\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings panel\n\n#### Configuration:\n- `/client/src-tauri/Cargo.toml` - No audio libraries\n- `/client/src-tauri/capabilities/default.json` - No WebRTC permissions (delegated to webview)\n- `/client/package.json` - Only `@tauri-apps/api` used, not for audio\n\n---\n\n### Conclusion\n\nThe Tauri desktop client **reuses 100% of the web client's voice implementation**. There are no separate audio capture, processing, or transmission paths. The Tauri backend provides:\n\n1. **Native screen capture for video** (not audio)\n2. **Standard Tauri plugins** (notifications, updates, opener)\n3. **No audio-specific functionality**\n\nAll voice/audio features use the browser's WebRTC stack through Tauri's Chromium webview:\n- Device enumeration via `navigator.mediaDevices`\n- Audio processing via Web Audio API\n- Transmission via mediasoup-client\n- Noise suppression/echo cancellation via browser's libwebrtc constraints\n\nThis is a **correct and efficient architecture** - native audio APIs would add complexity without benefit, as WebRTC already provides optimized audio capture and processing.\n</output>"}]},"uuid":"caefb757-c8dd-4da6-9a06-9ec23cb0e304","timestamp":"2026-02-23T14:49:16.675Z","toolUseResult":{"retrieval_status":"success","task":{"task_id":"af8b6d8","task_type":"local_agent","status":"completed","description":"Explore Tauri voice integration","output":"Perfect! Now I have all the information I need. Let me compile my comprehensive findings:\n\n## Comprehensive Exploration: Tauri Desktop Client Voice Chat Module\n\n### Executive Summary\n\nThe Yankcord application uses **WebRTC via mediasoup-client** for voice communication, with **both web and Tauri clients sharing the same audio/voice logic**. The Tauri desktop client does NOT have separate audio handling - instead, it provides **native screen capture for video streaming** while delegating all voice/audio functionality to browser WebRTC APIs through the Chromium-based Tauri webview.\n\n---\n\n### 1. Tauri Backend (Rust) - /home/guibibi/projects/yankcord/client/src-tauri/\n\n#### Structure:\n- **Main entry point**: `/home/guibibi/projects/yankcord/client/src-tauri/src/main.rs` - Minimal Tauri bootstrap\n- **Core logic**: `/home/guibibi/projects/yankcord/client/src-tauri/src/lib.rs`\n\n#### Key Files:\n\n**lib.rs**:\n```rust\npub fn run() {\n    tauri::Builder::default()\n        .manage(capture::service::NativeCaptureService::default())\n        .plugin(tauri_plugin_opener::init())\n        .plugin(tauri_plugin_notification::init())\n        .plugin(tauri_plugin_updater::Builder::new().build())\n        .invoke_handler(tauri::generate_handler![\n            capture::service::list_native_capture_sources,\n            capture::service::native_codec_capabilities,\n            capture::service::start_native_capture,\n            capture::service::stop_native_capture,\n            capture::service::native_capture_status\n        ])\n```\n\n**Tauri Commands Exposed**:\n1. `list_native_capture_sources` - Lists available screens/windows/applications to capture\n2. `native_codec_capabilities` - Reports available video codecs (H264, VP8, VP9, AV1)\n3. `start_native_capture` - Initiates native screen/window capture with specified codec, resolution, FPS, bitrate\n4. `stop_native_capture` - Stops active native capture\n5. `native_capture_status` - Returns detailed metrics on encoding, RTP transmission, performance\n\n**No Tauri Commands for Audio**: The Rust backend provides **zero audio-related Tauri commands**. All voice/audio functionality is handled entirely through browser WebRTC APIs.\n\n#### Dependencies:\n- `tauri = { version = \"2\", features = [] }`\n- `tauri-plugin-opener = \"2\"` - Open URLs/files\n- `tauri-plugin-notification = \"2\"` - Desktop notifications\n- `tauri-plugin-updater = \"2\"` - App auto-updates\n- **No audio libraries** (no cpal, rodio, dasp, etc.)\n\n#### Capabilities:\nFile: `/home/guibibi/projects/yankcord/client/src-tauri/capabilities/default.json`\n\n```json\n{\n  \"permissions\": [\n    \"core:default\",\n    \"core:window:allow-close\",\n    \"core:window:allow-minimize\",\n    \"core:window:allow-toggle-maximize\",\n    \"core:window:allow-start-dragging\",\n    \"opener:default\",\n    \"notification:default\",\n    \"updater:default\"\n  ]\n}\n```\n\n**No WebRTC or audio permissions defined** - Tauri delegates these to the webview's built-in browser permissions system.\n\n---\n\n### 2. Frontend WebRTC Voice Architecture - /home/guibibi/projects/yankcord/client/src/\n\n#### Core Voice Stack:\n- **MediaSoup Client** (`mediasoup-client@3.18.6`) - SFU WebRTC protocol\n- **Web Audio API** - For microphone monitoring and audio processing\n- **getUserMedia API** - For microphone and speaker device enumeration\n- **All audio handled through browser webview** - NO native Rust audio handling\n\n#### Voice-Related Files:\n\n**API Modules** (`/client/src/api/media/`):\n\n1. **nativeCapture.ts** - Tauri bridge for screen capture (NOT audio)\n   - Defines types: `NativeCaptureSource`, `StartNativeCaptureRequest`, `NativeCaptureStatus`\n   - Calls Tauri commands via `invoke()` from `@tauri-apps/api/core`\n   - Used for screen sharing only, not voice\n\n2. **voiceActivity.ts** - Microphone level monitoring and speaking detection\n   ```typescript\n   export function startMicLevelMonitoring(channelId: string, stream: MediaStream) {\n     const audioContext = new AudioContext();\n     const analyserNode = audioContext.createAnalyser();\n     analyserNode.fftSize = 512;\n     analyserNode.smoothingTimeConstant = 0.85;\n     \n     // Monitors RMS level, reports speaking activity via reportVoiceActivity()\n   }\n   ```\n   - Detects voice activity using RMS (root mean square) analysis\n   - Reports to server via WebSocket signaling\n   - **Platform agnostic** - same code for web and Tauri\n\n3. **microphoneProcessing.ts** - Audio gain/volume control\n   ```typescript\n   export function createProcessedMicrophoneTrack(\n     stream: MediaStream, \n     volume: number, \n     muted: boolean\n   ): MicrophoneProcessingSession\n   ```\n   - Creates AudioContext with GainNode for outgoing volume adjustment\n   - Applies muting/unmuting to source and processed tracks\n   - **Pure Web Audio API** - zero native code\n\n4. **devices.ts** - Microphone and speaker device management\n   ```typescript\n   export async function listAudioDevices(): Promise<AudioDeviceInventory> {\n     const devices = await navigator.mediaDevices.enumerateDevices();\n   }\n   \n   export async function setPreferredMicrophoneDevice(deviceId: string | null) {\n     const nextStream = await navigator.mediaDevices.getUserMedia({\n       audio: audioInputConstraint(deviceId)\n     });\n   }\n   ```\n   - Uses standard `navigator.mediaDevices` APIs\n   - Supports speaker selection via `audio.setSinkId()` when available\n   - **Zero Tauri-specific code**\n\n5. **constraints.ts** - MediaTrackConstraints builder\n   ```typescript\n   export function audioInputConstraint(deviceId: string | null): MediaTrackConstraints | boolean {\n     const constraints: MediaTrackConstraints = {};\n     const supportedConstraints = navigator.mediaDevices?.getSupportedConstraints?.();\n     \n     if (supportedConstraints?.noiseSuppression) {\n       constraints.noiseSuppression = voiceNoiseSuppressionEnabled();\n     }\n     if (supportedConstraints?.echoCancellation) {\n       constraints.echoCancellation = voiceEchoCancellationEnabled();\n     }\n   }\n   ```\n   - Applies noise suppression (via WebRTC's libwebrtc)\n   - Applies echo cancellation (via browser's built-in AEC)\n   - Channel count: mono (1 channel)\n\n6. **consumers.ts** - Remote audio playback (remote participants)\n   - Creates HTML audio elements for each remote participant\n   - Routes audio through Web Audio API for per-user volume control\n   - Uses DynamicsCompressorNode for \"auto level incoming voices\" feature\n   ```typescript\n   function configureNormalizationNode(node: DynamicsCompressorNode, enabled: boolean) {\n     if (enabled) {\n       node.threshold.value = -24;\n       node.knee.value = 20;\n       node.ratio.value = 3;\n       node.attack.value = 0.003;\n       node.release.value = 0.25;\n     }\n   }\n   ```\n\n7. **producers.ts** - Local audio/video producer setup\n   - Creates microphone producer via `sendTransport.produce()`\n   - Creates camera producer for video\n   - Creates screen share producer (uses native Tauri capture on desktop)\n\n8. **signaling.ts** - WebSocket protocol for media negotiation\n   - Reports voice activity to server\n   - Requests media signal for producer/consumer setup\n   - No direct audio signaling\n\n9. **transports.ts** - WebRTC transport (DTLS/ICE) initialization\n   - Handles DTLS parameter negotiation\n   - Monitors transport health\n   - Cleanup on disconnect\n\n10. **codecs.ts** - Codec selection\n    ```typescript\n    export function selectScreenShareCodecForPlatform(): ProduceCodec | undefined {\n      // Prefers H264 > VP8 > VP9\n      // Platform-aware but applies to screen share only\n    }\n    \n    export function nativePreferredCodecsFor(): string[] {\n      return [\"video/H264\"]; // For native Tauri screen capture\n    }\n    ```\n\n#### Voice Settings Storage:\nFile: `/client/src/stores/settings.ts`\n\n```typescript\nconst AUDIO_INPUT_KEY = \"yankcord_audio_input_device_id\";\nconst AUDIO_OUTPUT_KEY = \"yankcord_audio_output_device_id\";\nconst VOICE_AUTO_LEVEL_ENABLED_KEY = \"yankcord_voice_auto_level_enabled\";\nconst VOICE_NOISE_SUPPRESSION_ENABLED_KEY = \"yankcord_voice_noise_suppression_enabled\";\nconst VOICE_ECHO_CANCELLATION_ENABLED_KEY = \"yankcord_voice_echo_cancellation_enabled\";\nconst VOICE_INCOMING_VOLUME_KEY = \"yankcord_voice_incoming_volume\";\nconst VOICE_OUTGOING_VOLUME_KEY = \"yankcord_voice_outgoing_volume\";\n```\n\nAll settings stored in **localStorage** - same for web and Tauri.\n\n#### Voice State Management:\nFile: `/client/src/stores/voice.ts` - Tracks:\n- `joinedVoiceChannelId` - Current voice channel\n- `participantsByChannel` - Who's in each channel\n- `speakingByChannel` - Who's currently speaking\n- `voiceActionState` - \"idle\" | \"joining\" | \"leaving\"\n- `micMuted` - Local mute state\n- `speakerMuted` - Remote audio mute\n- `cameraEnabled`, `screenShareEnabled` - Video states\n- `transportHealth` - WebRTC connection quality\n- Video tile subscriptions for remote video streams\n\n#### Voice UI Components:\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice channel participant display\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings UI\n- Noise suppression, echo cancellation, volume controls (both incoming/outgoing)\n\n---\n\n### 3. Key Differences Between Web and Tauri Clients\n\n#### Audio/Voice:\n- **Web Client**: Uses browser WebRTC, browser's audio device enumeration\n- **Tauri Client**: **Identical** - Same WebRTC via Tauri's Chromium webview, browser audio device enumeration\n- **No difference** in how voices are captured, processed, or transmitted\n\n#### Screen Sharing:\n- **Web Client**: Uses `navigator.mediaDevices.getDisplayMedia()` (browser picker)\n- **Tauri Client**: Uses native Tauri commands for screen/window capture, can pass native source IDs, supports hardware-accelerated H264/NVENC encoding\n  - Fallback to browser capture if native fails\n  - Native capture is **video-only** (no audio)\n\n#### Platform Detection:\nFile: `/client/src/utils/platform.ts`\n\n```typescript\nexport function isTauriRuntime(): boolean {\n  return typeof window.__TAURI_INTERNALS__ !== \"undefined\";\n}\n```\n\nUsed to:\n1. Attempt native screen capture first on Tauri\n2. Check Windows platform for codec preferences\n3. Enable NVENC hardware encoding feature flags\n\n---\n\n### 4. Native Audio Handling - Summary\n\n**There is NO native audio handling in the Tauri client.**\n\nAudio flows:\n1. **Outgoing**: \n   - `navigator.mediaDevices.getUserMedia()` → microphone stream\n   - WebAudioAPI GainNode for volume adjustment\n   - Sent to server via WebRTC (mediasoup)\n\n2. **Incoming**:\n   - Received via WebRTC consumer\n   - Routed to HTML audio element\n   - Optional Web Audio API GainNode for per-user volume control\n   - Optional DynamicsCompressorNode for auto-normalization\n\n3. **Processing**:\n   - Noise suppression: Browser's WebRTC libwebrtc (constraint-based)\n   - Echo cancellation: Browser's WebRTC libwebrtc (constraint-based)\n   - Voice activity detection: Custom JavaScript using Web Audio API FFT analysis\n\n---\n\n### 5. Recent Voice Improvements\n\nRecent commit: **4cd8bfa** (\"feat: improve voice connectivity\")\n\nChanges include:\n- Improved transport health monitoring\n- Better consumer audio routing\n- Enhanced subscription system for media state\n- Per-user volume control via DynamicsCompressor normalization\n- Auto-level incoming voices feature\n\n**No Tauri-specific changes** - all improvements are browser-level WebRTC optimizations.\n\n---\n\n### 6. Tauri Configuration\n\nFile: `/client/src-tauri/tauri.conf.json`\n\n```json\n{\n  \"app\": {\n    \"windows\": [{\n      \"title\": \"Yankcord\",\n      \"decorations\": false,\n      \"width\": 1280,\n      \"height\": 800\n    }],\n    \"security\": {\n      \"csp\": \"default-src 'self'; connect-src 'self' https: http: wss: ws:; img-src 'self' data: blob: https: http:; style-src 'self' 'unsafe-inline'\"\n    }\n  }\n}\n```\n\n**CSP allows**:\n- WebSocket connections (wss: ws:) - for voice signaling\n- HTTPS/HTTP - for API calls\n- Blob resources - for media streams\n\n**No WebRTC-specific CSP rules** - Tauri's webview handles this internally.\n\n---\n\n### 7. Files Summary\n\n#### Tauri Rust Code (NO voice/audio):\n- `/client/src-tauri/src/main.rs` - Entry point (181 bytes)\n- `/client/src-tauri/src/lib.rs` - Tauri app setup, command handlers (764 bytes)\n- `/client/src-tauri/src/capture/` - Screen capture backend (video only)\n  - No audio dependencies or code\n\n#### Frontend Voice Code (Browser WebRTC):\n- `/client/src/api/media/` - 15 files, all platform-agnostic WebRTC/Web Audio\n- `/client/src/api/nativeCapture.ts` - Tauri bridge (screen capture only)\n- `/client/src/stores/voice.ts` - Voice state management\n- `/client/src/stores/settings.ts` - Audio preferences storage\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice UI\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings panel\n\n#### Configuration:\n- `/client/src-tauri/Cargo.toml` - No audio libraries\n- `/client/src-tauri/capabilities/default.json` - No WebRTC permissions (delegated to webview)\n- `/client/package.json` - Only `@tauri-apps/api` used, not for audio\n\n---\n\n### Conclusion\n\nThe Tauri desktop client **reuses 100% of the web client's voice implementation**. There are no separate audio capture, processing, or transmission paths. The Tauri backend provides:\n\n1. **Native screen capture for video** (not audio)\n2. **Standard Tauri plugins** (notifications, updates, opener)\n3. **No audio-specific functionality**\n\nAll voice/audio features use the browser's WebRTC stack through Tauri's Chromium webview:\n- Device enumeration via `navigator.mediaDevices`\n- Audio processing via Web Audio API\n- Transmission via mediasoup-client\n- Noise suppression/echo cancellation via browser's libwebrtc constraints\n\nThis is a **correct and efficient architecture** - native audio APIs would add complexity without benefit, as WebRTC already provides optimized audio capture and processing.","prompt":"Explore the Tauri desktop client side of the voice chat module in /home/guibibi/projects/yankcord.\n\nLook for:\n1. Any tauri/ or src-tauri/ directory with Rust backend code related to voice/audio\n2. Tauri commands or plugins for audio device management\n3. Any native audio handling (not via browser WebRTC)\n4. Tauri-specific configuration for WebRTC permissions or audio\n5. Any differences between how the web client and Tauri client handle voice\n\nSearch in all directories for tauri-related voice code. Also check for any shared types or protocols between the Tauri app and the web frontend regarding voice.\n\nRead all relevant files completely and report what you find.","result":"Perfect! Now I have all the information I need. Let me compile my comprehensive findings:\n\n## Comprehensive Exploration: Tauri Desktop Client Voice Chat Module\n\n### Executive Summary\n\nThe Yankcord application uses **WebRTC via mediasoup-client** for voice communication, with **both web and Tauri clients sharing the same audio/voice logic**. The Tauri desktop client does NOT have separate audio handling - instead, it provides **native screen capture for video streaming** while delegating all voice/audio functionality to browser WebRTC APIs through the Chromium-based Tauri webview.\n\n---\n\n### 1. Tauri Backend (Rust) - /home/guibibi/projects/yankcord/client/src-tauri/\n\n#### Structure:\n- **Main entry point**: `/home/guibibi/projects/yankcord/client/src-tauri/src/main.rs` - Minimal Tauri bootstrap\n- **Core logic**: `/home/guibibi/projects/yankcord/client/src-tauri/src/lib.rs`\n\n#### Key Files:\n\n**lib.rs**:\n```rust\npub fn run() {\n    tauri::Builder::default()\n        .manage(capture::service::NativeCaptureService::default())\n        .plugin(tauri_plugin_opener::init())\n        .plugin(tauri_plugin_notification::init())\n        .plugin(tauri_plugin_updater::Builder::new().build())\n        .invoke_handler(tauri::generate_handler![\n            capture::service::list_native_capture_sources,\n            capture::service::native_codec_capabilities,\n            capture::service::start_native_capture,\n            capture::service::stop_native_capture,\n            capture::service::native_capture_status\n        ])\n```\n\n**Tauri Commands Exposed**:\n1. `list_native_capture_sources` - Lists available screens/windows/applications to capture\n2. `native_codec_capabilities` - Reports available video codecs (H264, VP8, VP9, AV1)\n3. `start_native_capture` - Initiates native screen/window capture with specified codec, resolution, FPS, bitrate\n4. `stop_native_capture` - Stops active native capture\n5. `native_capture_status` - Returns detailed metrics on encoding, RTP transmission, performance\n\n**No Tauri Commands for Audio**: The Rust backend provides **zero audio-related Tauri commands**. All voice/audio functionality is handled entirely through browser WebRTC APIs.\n\n#### Dependencies:\n- `tauri = { version = \"2\", features = [] }`\n- `tauri-plugin-opener = \"2\"` - Open URLs/files\n- `tauri-plugin-notification = \"2\"` - Desktop notifications\n- `tauri-plugin-updater = \"2\"` - App auto-updates\n- **No audio libraries** (no cpal, rodio, dasp, etc.)\n\n#### Capabilities:\nFile: `/home/guibibi/projects/yankcord/client/src-tauri/capabilities/default.json`\n\n```json\n{\n  \"permissions\": [\n    \"core:default\",\n    \"core:window:allow-close\",\n    \"core:window:allow-minimize\",\n    \"core:window:allow-toggle-maximize\",\n    \"core:window:allow-start-dragging\",\n    \"opener:default\",\n    \"notification:default\",\n    \"updater:default\"\n  ]\n}\n```\n\n**No WebRTC or audio permissions defined** - Tauri delegates these to the webview's built-in browser permissions system.\n\n---\n\n### 2. Frontend WebRTC Voice Architecture - /home/guibibi/projects/yankcord/client/src/\n\n#### Core Voice Stack:\n- **MediaSoup Client** (`mediasoup-client@3.18.6`) - SFU WebRTC protocol\n- **Web Audio API** - For microphone monitoring and audio processing\n- **getUserMedia API** - For microphone and speaker device enumeration\n- **All audio handled through browser webview** - NO native Rust audio handling\n\n#### Voice-Related Files:\n\n**API Modules** (`/client/src/api/media/`):\n\n1. **nativeCapture.ts** - Tauri bridge for screen capture (NOT audio)\n   - Defines types: `NativeCaptureSource`, `StartNativeCaptureRequest`, `NativeCaptureStatus`\n   - Calls Tauri commands via `invoke()` from `@tauri-apps/api/core`\n   - Used for screen sharing only, not voice\n\n2. **voiceActivity.ts** - Microphone level monitoring and speaking detection\n   ```typescript\n   export function startMicLevelMonitoring(channelId: string, stream: MediaStream) {\n     const audioContext = new AudioContext();\n     const analyserNode = audioContext.createAnalyser();\n     analyserNode.fftSize = 512;\n     analyserNode.smoothingTimeConstant = 0.85;\n     \n     // Monitors RMS level, reports speaking activity via reportVoiceActivity()\n   }\n   ```\n   - Detects voice activity using RMS (root mean square) analysis\n   - Reports to server via WebSocket signaling\n   - **Platform agnostic** - same code for web and Tauri\n\n3. **microphoneProcessing.ts** - Audio gain/volume control\n   ```typescript\n   export function createProcessedMicrophoneTrack(\n     stream: MediaStream, \n     volume: number, \n     muted: boolean\n   ): MicrophoneProcessingSession\n   ```\n   - Creates AudioContext with GainNode for outgoing volume adjustment\n   - Applies muting/unmuting to source and processed tracks\n   - **Pure Web Audio API** - zero native code\n\n4. **devices.ts** - Microphone and speaker device management\n   ```typescript\n   export async function listAudioDevices(): Promise<AudioDeviceInventory> {\n     const devices = await navigator.mediaDevices.enumerateDevices();\n   }\n   \n   export async function setPreferredMicrophoneDevice(deviceId: string | null) {\n     const nextStream = await navigator.mediaDevices.getUserMedia({\n       audio: audioInputConstraint(deviceId)\n     });\n   }\n   ```\n   - Uses standard `navigator.mediaDevices` APIs\n   - Supports speaker selection via `audio.setSinkId()` when available\n   - **Zero Tauri-specific code**\n\n5. **constraints.ts** - MediaTrackConstraints builder\n   ```typescript\n   export function audioInputConstraint(deviceId: string | null): MediaTrackConstraints | boolean {\n     const constraints: MediaTrackConstraints = {};\n     const supportedConstraints = navigator.mediaDevices?.getSupportedConstraints?.();\n     \n     if (supportedConstraints?.noiseSuppression) {\n       constraints.noiseSuppression = voiceNoiseSuppressionEnabled();\n     }\n     if (supportedConstraints?.echoCancellation) {\n       constraints.echoCancellation = voiceEchoCancellationEnabled();\n     }\n   }\n   ```\n   - Applies noise suppression (via WebRTC's libwebrtc)\n   - Applies echo cancellation (via browser's built-in AEC)\n   - Channel count: mono (1 channel)\n\n6. **consumers.ts** - Remote audio playback (remote participants)\n   - Creates HTML audio elements for each remote participant\n   - Routes audio through Web Audio API for per-user volume control\n   - Uses DynamicsCompressorNode for \"auto level incoming voices\" feature\n   ```typescript\n   function configureNormalizationNode(node: DynamicsCompressorNode, enabled: boolean) {\n     if (enabled) {\n       node.threshold.value = -24;\n       node.knee.value = 20;\n       node.ratio.value = 3;\n       node.attack.value = 0.003;\n       node.release.value = 0.25;\n     }\n   }\n   ```\n\n7. **producers.ts** - Local audio/video producer setup\n   - Creates microphone producer via `sendTransport.produce()`\n   - Creates camera producer for video\n   - Creates screen share producer (uses native Tauri capture on desktop)\n\n8. **signaling.ts** - WebSocket protocol for media negotiation\n   - Reports voice activity to server\n   - Requests media signal for producer/consumer setup\n   - No direct audio signaling\n\n9. **transports.ts** - WebRTC transport (DTLS/ICE) initialization\n   - Handles DTLS parameter negotiation\n   - Monitors transport health\n   - Cleanup on disconnect\n\n10. **codecs.ts** - Codec selection\n    ```typescript\n    export function selectScreenShareCodecForPlatform(): ProduceCodec | undefined {\n      // Prefers H264 > VP8 > VP9\n      // Platform-aware but applies to screen share only\n    }\n    \n    export function nativePreferredCodecsFor(): string[] {\n      return [\"video/H264\"]; // For native Tauri screen capture\n    }\n    ```\n\n#### Voice Settings Storage:\nFile: `/client/src/stores/settings.ts`\n\n```typescript\nconst AUDIO_INPUT_KEY = \"yankcord_audio_input_device_id\";\nconst AUDIO_OUTPUT_KEY = \"yankcord_audio_output_device_id\";\nconst VOICE_AUTO_LEVEL_ENABLED_KEY = \"yankcord_voice_auto_level_enabled\";\nconst VOICE_NOISE_SUPPRESSION_ENABLED_KEY = \"yankcord_voice_noise_suppression_enabled\";\nconst VOICE_ECHO_CANCELLATION_ENABLED_KEY = \"yankcord_voice_echo_cancellation_enabled\";\nconst VOICE_INCOMING_VOLUME_KEY = \"yankcord_voice_incoming_volume\";\nconst VOICE_OUTGOING_VOLUME_KEY = \"yankcord_voice_outgoing_volume\";\n```\n\nAll settings stored in **localStorage** - same for web and Tauri.\n\n#### Voice State Management:\nFile: `/client/src/stores/voice.ts` - Tracks:\n- `joinedVoiceChannelId` - Current voice channel\n- `participantsByChannel` - Who's in each channel\n- `speakingByChannel` - Who's currently speaking\n- `voiceActionState` - \"idle\" | \"joining\" | \"leaving\"\n- `micMuted` - Local mute state\n- `speakerMuted` - Remote audio mute\n- `cameraEnabled`, `screenShareEnabled` - Video states\n- `transportHealth` - WebRTC connection quality\n- Video tile subscriptions for remote video streams\n\n#### Voice UI Components:\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice channel participant display\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings UI\n- Noise suppression, echo cancellation, volume controls (both incoming/outgoing)\n\n---\n\n### 3. Key Differences Between Web and Tauri Clients\n\n#### Audio/Voice:\n- **Web Client**: Uses browser WebRTC, browser's audio device enumeration\n- **Tauri Client**: **Identical** - Same WebRTC via Tauri's Chromium webview, browser audio device enumeration\n- **No difference** in how voices are captured, processed, or transmitted\n\n#### Screen Sharing:\n- **Web Client**: Uses `navigator.mediaDevices.getDisplayMedia()` (browser picker)\n- **Tauri Client**: Uses native Tauri commands for screen/window capture, can pass native source IDs, supports hardware-accelerated H264/NVENC encoding\n  - Fallback to browser capture if native fails\n  - Native capture is **video-only** (no audio)\n\n#### Platform Detection:\nFile: `/client/src/utils/platform.ts`\n\n```typescript\nexport function isTauriRuntime(): boolean {\n  return typeof window.__TAURI_INTERNALS__ !== \"undefined\";\n}\n```\n\nUsed to:\n1. Attempt native screen capture first on Tauri\n2. Check Windows platform for codec preferences\n3. Enable NVENC hardware encoding feature flags\n\n---\n\n### 4. Native Audio Handling - Summary\n\n**There is NO native audio handling in the Tauri client.**\n\nAudio flows:\n1. **Outgoing**: \n   - `navigator.mediaDevices.getUserMedia()` → microphone stream\n   - WebAudioAPI GainNode for volume adjustment\n   - Sent to server via WebRTC (mediasoup)\n\n2. **Incoming**:\n   - Received via WebRTC consumer\n   - Routed to HTML audio element\n   - Optional Web Audio API GainNode for per-user volume control\n   - Optional DynamicsCompressorNode for auto-normalization\n\n3. **Processing**:\n   - Noise suppression: Browser's WebRTC libwebrtc (constraint-based)\n   - Echo cancellation: Browser's WebRTC libwebrtc (constraint-based)\n   - Voice activity detection: Custom JavaScript using Web Audio API FFT analysis\n\n---\n\n### 5. Recent Voice Improvements\n\nRecent commit: **4cd8bfa** (\"feat: improve voice connectivity\")\n\nChanges include:\n- Improved transport health monitoring\n- Better consumer audio routing\n- Enhanced subscription system for media state\n- Per-user volume control via DynamicsCompressor normalization\n- Auto-level incoming voices feature\n\n**No Tauri-specific changes** - all improvements are browser-level WebRTC optimizations.\n\n---\n\n### 6. Tauri Configuration\n\nFile: `/client/src-tauri/tauri.conf.json`\n\n```json\n{\n  \"app\": {\n    \"windows\": [{\n      \"title\": \"Yankcord\",\n      \"decorations\": false,\n      \"width\": 1280,\n      \"height\": 800\n    }],\n    \"security\": {\n      \"csp\": \"default-src 'self'; connect-src 'self' https: http: wss: ws:; img-src 'self' data: blob: https: http:; style-src 'self' 'unsafe-inline'\"\n    }\n  }\n}\n```\n\n**CSP allows**:\n- WebSocket connections (wss: ws:) - for voice signaling\n- HTTPS/HTTP - for API calls\n- Blob resources - for media streams\n\n**No WebRTC-specific CSP rules** - Tauri's webview handles this internally.\n\n---\n\n### 7. Files Summary\n\n#### Tauri Rust Code (NO voice/audio):\n- `/client/src-tauri/src/main.rs` - Entry point (181 bytes)\n- `/client/src-tauri/src/lib.rs` - Tauri app setup, command handlers (764 bytes)\n- `/client/src-tauri/src/capture/` - Screen capture backend (video only)\n  - No audio dependencies or code\n\n#### Frontend Voice Code (Browser WebRTC):\n- `/client/src/api/media/` - 15 files, all platform-agnostic WebRTC/Web Audio\n- `/client/src/api/nativeCapture.ts` - Tauri bridge (screen capture only)\n- `/client/src/stores/voice.ts` - Voice state management\n- `/client/src/stores/settings.ts` - Audio preferences storage\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice UI\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings panel\n\n#### Configuration:\n- `/client/src-tauri/Cargo.toml` - No audio libraries\n- `/client/src-tauri/capabilities/default.json` - No WebRTC permissions (delegated to webview)\n- `/client/package.json` - Only `@tauri-apps/api` used, not for audio\n\n---\n\n### Conclusion\n\nThe Tauri desktop client **reuses 100% of the web client's voice implementation**. There are no separate audio capture, processing, or transmission paths. The Tauri backend provides:\n\n1. **Native screen capture for video** (not audio)\n2. **Standard Tauri plugins** (notifications, updates, opener)\n3. **No audio-specific functionality**\n\nAll voice/audio features use the browser's WebRTC stack through Tauri's Chromium webview:\n- Device enumeration via `navigator.mediaDevices`\n- Audio processing via Web Audio API\n- Transmission via mediasoup-client\n- Noise suppression/echo cancellation via browser's libwebrtc constraints\n\nThis is a **correct and efficient architecture** - native audio APIs would add complexity without benefit, as WebRTC already provides optimized audio capture and processing."}},"sourceToolAssistantUUID":"a90bcf10-27ba-4d8f-83dd-c560af5ee9cd"}
{"parentUuid":"caefb757-c8dd-4da6-9a06-9ec23cb0e304","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01SWJGUnw1B2xvq4N8GSPuqr","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"All three agents have completed. Now I need to compile a comprehensive voice chat report text file. Let me create a well-structured report combining all findings from:\n\n1. Client-side (web + shared code)\n2. Server-side (Rust + mediasoup)\n3. Tauri-specific\n\nLet me write this to a file.","signature":"EsEDCkYICxgCKkDPk9X/mPoOliLjIRazZ5Mow+J5UR21EcE28odCs5YwEpyIE+c/T1SJfdogrgp2LAqjcaOxdNq9uljjkMTO36rkEgyVTZPM5V0VrVbbeBsaDBJ0aI7kVD5YkmEzrSIwJnejd1rpVdR+st3IbNkVR+/nkq28J98UxQ8GOWktJI1H5W7wIgnUrCn4bOxQ+3ziKqgC3hJGvK3BrGbfVJqKSnB9hBRW+VlIzrjkLpBJasCT3UdgBOJ1tg0lcYGvuKsOZz2pZ/pb0BlU5vEynsfuiKs0JLYBbSQHYpmaSNJRWivG55tQFxIEwOJ1zocvZ2DFwBqFcdTBw4X7lISd1q9ta+Lvd4f58ijGM6vTIuRhR8Ch+HW1OGZYMhwXk53ybwEMdtf8dYNLpAGWyaVrBicX5AJis15nPIHK8D0L50v2oIKJUjo7lA6S7Rpvf5vvCLHzRvEz3wyghhWgp19dpWJ0JVRt68f2oK7Kn7ehKFmySPv3bT3v0j8OKG67RipvPC0lnfJidHy8aw7pS8vfNSijgl+AHFbGyQ0rbB0dyZm7cd6HdAFGO5RT5+ATYUoB41NKt0LKsze5Ok90+i8YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4272,"cache_read_input_tokens":39788,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4272},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBjumGU8XJXvR735siq","type":"assistant","uuid":"f377e697-981a-4de6-a74f-daefaf0210da","timestamp":"2026-02-23T14:49:20.507Z"}
{"parentUuid":"f377e697-981a-4de6-a74f-daefaf0210da","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01SWJGUnw1B2xvq4N8GSPuqr","type":"message","role":"assistant","content":[{"type":"text","text":"All three explorations are complete. Let me now compile the comprehensive report."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4272,"cache_read_input_tokens":39788,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4272},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBjumGU8XJXvR735siq","type":"assistant","uuid":"6597ac39-0676-4256-9ae3-c65c005b40a9","timestamp":"2026-02-23T14:49:21.154Z"}
{"parentUuid":"6597ac39-0676-4256-9ae3-c65c005b40a9","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01SWJGUnw1B2xvq4N8GSPuqr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LuHhXXJo8MRCfyfgjcHETT","name":"Write","input":{"file_path":"REDACTED.md","content":"# Yankcord Voice Chat Module - Comprehensive Review\n\n## Executive Summary\n\nThe voice system implements a **Selective Forwarding Unit (SFU)** architecture using **mediasoup** on both client and server. The Rust server manages mediasoup workers, routers, and transports. The TypeScript client uses `mediasoup-client` with the Web Audio API for audio processing. The Tauri desktop client **reuses 100% of the web client's voice code** through its Chromium webview, adding only native screen capture (video-only) via Rust.\n\n**Architecture is sound.** The codebase demonstrates clean separation of concerns, proper resource lifecycle management, and a well-designed signaling protocol. However, there are several critical and high-priority issues that need attention for production readiness.\n\n---\n\n## 1. Architecture Overview\n\n```\n                         CLIENT (Web / Tauri)\n┌──────────────────────────────────────────────────────────────┐\n│  ChannelList.tsx (orchestration)                             │\n│    ├─ VoiceDock.tsx (controls UI)                            │\n│    ├─ VideoStage.tsx (video grid)                            │\n│    └─ voice.ts store (reactive state via SolidJS signals)    │\n│                                                              │\n│  api/media/ (15 modules)                                     │\n│    ├─ transports.ts   (WebRTC send/recv transport lifecycle) │\n│    ├─ producers.ts    (mic, camera, screen share outgoing)   │\n│    ├─ consumers.ts    (remote audio/video incoming)          │\n│    ├─ signaling.ts    (request-response over WebSocket)      │\n│    ├─ voiceActivity.ts(VAD via FFT/RMS analysis)             │\n│    ├─ microphoneProcessing.ts (outgoing gain control)        │\n│    ├─ devices.ts      (hot-swap mic/camera/speaker)          │\n│    ├─ constraints.ts  (media constraints builder)            │\n│    ├─ codecs.ts       (codec selection & preference)         │\n│    ├─ native.ts       (Tauri screen capture bridge)          │\n│    ├─ subscriptions.ts(pub-sub for media state changes)      │\n│    ├─ errors.ts       (user-friendly error messages)         │\n│    └─ state.ts        (module-level non-reactive state)      │\n└──────────────────────────────────────────────────────────────┘\n                              │\n                    WebSocket + WebRTC\n                              │\n                          SERVER (Rust)\n┌──────────────────────────────────────────────────────────────┐\n│  ws/handler.rs     (voice join/leave, speaking events)       │\n│  ws/media_signal.rs(signaling protocol, 9 action types)      │\n│  ws/voice.rs       (broadcast helpers)                       │\n│  ws/broadcast.rs   (cleanup, state management)               │\n│                                                              │\n│  media/                                                      │\n│    ├─ mod.rs          (MediaService, workers, router cache)  │\n│    ├─ router.rs       (opus config, codec definitions)       │\n│    ├─ transport.rs    (transport/producer/consumer mgmt)     │\n│    └─ native_codec.rs (native RTP screen sharing)            │\n│                                                              │\n│  In-Memory State:                                            │\n│    voice_members_by_connection: HashMap<ConnId, ChannelId>   │\n│    voice_members_by_channel: HashMap<ChannelId, Set<User>>   │\n│                                                              │\n│  Database: channels table (opus_bitrate, opus_dtx, opus_fec) │\n└──────────────────────────────────────────────────────────────┘\n```\n\n### Connection Lifecycle\n\n```\n1. Client sends JoinVoice { channel_id } over WebSocket\n2. Server validates channel, updates in-memory state, broadcasts VoiceUserJoined\n3. Server sends VoiceJoined back to client\n4. Client calls initializeMediaTransports(channelId):\n   a. Requests RTP capabilities from server\n   b. Loads mediasoup Device\n   c. Creates Send + Recv WebRTC transports\n   d. Wires DTLS connect + ICE monitoring\n   e. Starts local audio producer (getUserMedia → gain → produce)\n   f. Starts voice activity monitoring (FFT/RMS loop)\n   g. Flushes queued remote producer announcements → consume each\n5. On new_producer signal: consumeRemoteProducer()\n   - Audio: HTMLAudioElement → SourceNode → Compressor → GainNode → Destination\n   - Video: RemoteVideoTile entry\n6. On LeaveVoice: closeTransports() → cleanup all resources → reset state\n```\n\n---\n\n## 2. Client-Side Review\n\n### 2.1 File Inventory\n\n| File | Purpose | Lines | Risk |\n|------|---------|-------|------|\n| `stores/voice.ts` | Reactive state (SolidJS signals) | 413 | Low |\n| `api/media/state.ts` | Module-level non-reactive state | 144 | Low |\n| `api/media/transports.ts` | WebRTC transport setup & lifecycle | 376 | Medium |\n| `api/media/producers.ts` | Outgoing audio/video/screen | 737 | High |\n| `api/media/consumers.ts` | Incoming audio/video playback | 382 | High |\n| `api/media/voiceActivity.ts` | Speaking detection (VAD) | 111 | Medium |\n| `api/media/microphoneProcessing.ts` | Outgoing volume gain | 104 | Medium |\n| `api/media/signaling.ts` | WebSocket request-response | 178 | Medium |\n| `api/media/subscriptions.ts` | Publisher-subscriber pattern | 122 | Low |\n| `api/media/devices.ts` | Audio/video device management | 150+ | High |\n| `api/media/constraints.ts` | Media constraints builder | 97 | Low |\n| `api/media/codecs.ts` | Codec selection & preference | ~80 | Low |\n| `api/media/errors.ts` | Error normalization | 72 | Low |\n| `api/media/native.ts` | Tauri screen capture bridge | 88 | Medium |\n| `components/channel-list/VoiceDock.tsx` | Voice control panel UI | 131 | Low |\n| `components/VideoStage.tsx` | Video tile grid | 78 | Low |\n| `components/settings/VoiceAudioPreferences.tsx` | Voice settings UI | 110 | Low |\n| `components/ChannelList.tsx` | Main voice integration/orchestration | 1200+ | High |\n\n### 2.2 Audio Processing Chain\n\n**Outgoing (microphone):**\n```\ngetUserMedia(constraints)\n  → SourceNode\n    → GainNode (outgoing volume 0-200%)\n      → MediaStreamDestination (processed track)\n        → mediasoup Producer\n```\n\n**Incoming (remote participants):**\n```\nmediasoup Consumer track\n  → MediaStreamSource\n    → DynamicsCompressorNode (auto-level normalization)\n      → GainNode (per-user volume 0-200%)\n        → AudioContext.destination\n          → HTMLAudioElement (playback)\n```\n\nNormalization settings: threshold -24dB, knee 20dB, ratio 3:1, attack 3ms, release 250ms.\n\n### 2.3 Voice Activity Detection\n\n- FFT size: 512 samples\n- Smoothing: 0.85 time constant\n- Speaking threshold: RMS >= 0.04 (4%)\n- Hold duration: 220ms (prevents jitter between speech segments)\n- Runs via `requestAnimationFrame` (60fps)\n\n### 2.4 Screen Share - Two Modes\n\n**Browser mode** (web + Tauri fallback):\n- Uses `getDisplayMedia()` API\n- Supports 720p/1080p/1440p/4K at 30/60 FPS\n- Codec preference: H.264 > VP8 > VP9\n- Content hint: \"motion\" (high FPS) or \"detail\" (low FPS)\n\n**Native Tauri mode** (desktop only):\n- Uses Rust backend RTP sender\n- H.264 only (NVENC hardware acceleration when available)\n- Fallback monitoring every 1s for encoder failures\n- Diagnostics reported to server\n- Falls back to browser mode if native fails\n\n### 2.5 Device Management\n\n- Hot-swap microphone at runtime (replaces producer track)\n- Hot-swap camera (replaces producer track)\n- Speaker routing via `HTMLAudioElement.setSinkId()`\n- Device change detection via `navigator.mediaDevices.ondevicechange`\n- Automatic reset if current device disappears\n\n---\n\n## 3. Server-Side Review\n\n### 3.1 File Inventory\n\n| File | Purpose | Lines | Risk |\n|------|---------|-------|------|\n| `media/mod.rs` | MediaService, worker/router lifecycle | 177 | High |\n| `media/router.rs` | Opus config, codec definitions | 91 | Medium |\n| `media/transport.rs` | Transport/producer/consumer management | 656 | High |\n| `media/native_codec.rs` | Native video codec, screen sharing | 215 | Medium |\n| `ws/media_signal.rs` | Media signaling protocol handler | 1064 | High |\n| `ws/voice.rs` | Voice broadcast functions | 118 | Low |\n| `ws/handler.rs` | Voice join/leave, main WS handler | 1416 | High |\n| `ws/broadcast.rs` | State cleanup, connection management | 400 | Medium |\n\n### 3.2 MediaService Architecture\n\n- **Workers**: Configurable count via `MEDIA_WORKER_COUNT` (default: 2)\n- **Router caching**: Per-channel, deterministic worker assignment via `channel_id.as_bytes()[0] % worker_count`\n- **Transport types**: WebRtcTransport (send/recv) + PlainTransport (native RTP)\n- **Rate limiting**: 80 media signal events per 5-second window per connection\n- **Payload limit**: 32 KB per media signal\n\n### 3.3 Supported Codecs\n\n**Audio**: Opus (48kHz, stereo, 2ch) with configurable bitrate/DTX/FEC per channel\n**Video**: VP8, H.264 (packetization-mode=1, profile 42e01f), VP9, AV1\n**RTCP Feedback**: Nack, NackPli, CcmFir, GoogRemb, TransportCc\n\n### 3.4 Signaling Protocol\n\n9 action types over WebSocket:\n\n| Action | Purpose |\n|--------|---------|\n| `GetRouterRtpCapabilities` | Get channel's codec capabilities |\n| `CreateWebrtcTransport` | Create send or recv transport |\n| `ConnectWebrtcTransport` | Complete DTLS handshake |\n| `MediaProduce` | Create audio/video producer |\n| `MediaConsume` | Create consumer for remote producer |\n| `MediaResumeConsumer` | Resume paused consumer |\n| `MediaCloseProducer` | Close a producer |\n| `CreateNativeSenderSession` | Setup native RTP screen sharing |\n| `ClientDiagnostic` | Log client diagnostic data |\n\nRequest-response pattern with unique IDs (`media-{timestamp}-{counter}`), 10-second timeout.\n\n### 3.5 In-Memory Voice State\n\n```rust\nvoice_members_by_connection: HashMap<Uuid, Uuid>         // connection -> channel\nvoice_members_by_channel: HashMap<Uuid, HashSet<String>>  // channel -> usernames\n```\n\nNo database persistence. Server restart loses all voice sessions.\n\n### 3.6 Producer Constraints\n\n- One camera producer per connection\n- One screen producer per connection\n- No limit on microphone producers\n- Kind must match source (audio ↔ microphone, video ↔ camera/screen)\n- Only \"sfu\" routing mode supported\n\n---\n\n## 4. Tauri Desktop Client\n\n### What Tauri Adds\n\nThe Tauri Rust backend provides **only video capture** commands:\n1. `list_native_capture_sources` - Enumerate screens/windows/apps\n2. `native_codec_capabilities` - Report available video codecs\n3. `start_native_capture` - Start hardware-accelerated screen capture\n4. `stop_native_capture` - Stop capture\n5. `native_capture_status` - Encoding/RTP metrics\n\n### What Tauri Does NOT Do\n\n- **No native audio capture** (no cpal, rodio, or dasp)\n- **No native audio processing** (no noise suppression or echo cancellation)\n- **No audio device management** (all via `navigator.mediaDevices`)\n- **No separate voice transport** (same WebRTC via Chromium webview)\n\n### Correct Architecture Choice\n\nThis is the right approach. Tauri's Chromium webview provides full WebRTC with optimized audio (libwebrtc's AEC, NS, AGC), making native audio redundant. Native screen capture adds value because `getDisplayMedia()` has limitations on desktop (no NVENC, limited window selection).\n\n---\n\n## 5. Issues & Recommendations\n\n### CRITICAL\n\n| # | Issue | Location | Impact |\n|---|-------|----------|--------|\n| C1 | **No voice membership persistence** | Server in-memory only | Server restart drops all voice sessions silently. Clients have no mechanism to detect and rejoin. |\n| C2 | **Router codec settings never update** | `media/mod.rs` router cache | Changing channel opus_bitrate/dtx/fec after first user joins has no effect until server restart. |\n| C3 | **No consumer auto-cleanup on producer close** | `media/transport.rs` | Consumers remain in HashMap after producer closes, causing memory leak over time. |\n| C4 | **No timeout on transport creation** | `transports.ts:279` | If server hangs responding to capabilities request, `initializeMediaTransports()` blocks indefinitely. |\n| C5 | **Silent audio playback failure** | `consumers.ts:247-265` | If `audio.play()` fails twice, error is logged but user hears silence with no UI feedback. |\n\n### HIGH\n\n| # | Issue | Location | Impact |\n|---|-------|----------|--------|\n| H1 | **No channel permission checks for voice** | `ws/handler.rs` | Any authenticated user can join any voice channel. No ACL or role-based access control. |\n| H2 | **TOCTOU race on camera/screen limit** | `transport.rs:266-321` | Duplicate producer check happens twice with a gap. Concurrent requests could both pass. |\n| H3 | **Producer owner lookup silently fails** | `transport.rs:555-600` | When recv transport created and owner disconnected, consumer doesn't receive producer notification. |\n| H4 | **No mediasoup worker health monitoring** | `media/mod.rs` | Worker crash causes silent failure. No restart logic, no health checks. |\n| H5 | **No reconnection logic** | Client transports | If WebSocket reconnects, media transports are not re-established automatically. User must manually retry. |\n| H6 | **Screen share native fallback is sticky** | `producers.ts:680-685` | Once `nativeCaptureAttempted` set true, user can't retry browser mode without page reload. |\n| H7 | **No bandwidth/bitrate enforcement** | Server consumers | Consumers created without bitrate limits. No congestion control feedback. Network overload possible. |\n\n### MEDIUM\n\n| # | Issue | Location | Impact |\n|---|-------|----------|--------|\n| M1 | **VAD uses requestAnimationFrame** | `voiceActivity.ts` | 60fps monitoring is overkill. A 50ms `setInterval` (~20fps) would suffice and save CPU. |\n| M2 | **Slow producer notification batching** | `transport.rs:555-600` | N producers = N separate JSON messages on recv transport creation. Should batch. |\n| M3 | **Voice activity broadcast includes self** | `ws/handler.rs:611-632` | `exclude_connection_id` is None — client receives its own speaking event. |\n| M4 | **VAD hold duration too short** | `voiceActivity.ts:77-78` | 220ms can miss natural speech pauses. 300-400ms or configurable would be better. |\n| M5 | **Audio play() retry is naive** | `consumers.ts` | Hardcoded 500ms delay, no exponential backoff, only 2 attempts. |\n| M6 | **Transport health race condition** | `transports.ts:106-112` | Multiple transports closing in parallel could set health state to wrong value. |\n| M7 | **Microphone processing resource leak** | `microphoneProcessing.ts` | If `activateMicrophoneProcessing()` called without prior cleanup, old session is orphaned. |\n| M8 | **No signaling retry logic** | `signaling.ts` | First 10-second timeout = permanent failure. No retry for transient network issues. |\n| M9 | **Transport direction silently replaced** | `transport.rs` | Creating send transport twice replaces first without error. |\n| M10 | **Mediasoup errors exposed to client** | `ws/media_signal.rs` | Internal error messages sent directly, potential information disclosure. |\n\n### LOW / CODE QUALITY\n\n| # | Issue | Location |\n|---|-------|----------|\n| L1 | Volume clamping function duplicated | `consumers.ts` + `microphoneProcessing.ts` |\n| L2 | Magic numbers not extracted to constants | Multiple files (10000ms, 220ms, 512 FFT, 0.04 threshold) |\n| L3 | Inconsistent error handling | Mix of `console.warn`, `console.error`, and throw |\n| L4 | No subscriber count limits | `subscriptions.ts` — potential memory leak |\n| L5 | NormalizationNode config recreated per consumer | `consumers.ts` — should be module constant |\n| L6 | No video tile pagination | `VideoStage.tsx` — unwieldy with many participants |\n| L7 | Native metrics polling always 1s | `VoiceDock.tsx` — constant IPC overhead during screen share |\n\n---\n\n## 6. Performance Notes\n\n### Audio Contexts\nThe system creates up to 3 AudioContexts simultaneously (mic level monitoring, remote playback, mic processing). Browsers limit to ~10 contexts, so this is safe but could be consolidated.\n\n### Voice Activity Detection\nRunning at 60fps via RAF is wasteful. Voice detection at 20fps (50ms interval) would be indistinguishable to users and reduce CPU usage by ~66%.\n\n### Native Screen Capture Polling\n1-second interval polling from Rust backend for metrics runs constantly during screen sharing. Could debounce to 2-3 seconds.\n\n### Remote Audio Elements\n`remoteAudioElements` map keeps references to all audio elements. Elements are disconnected on cleanup but not removed from DOM in all paths.\n\n---\n\n## 7. Security Considerations\n\n| Area | Status | Notes |\n|------|--------|-------|\n| Rate limiting | Good | 80 events/5s per connection, 32KB payload limit |\n| Payload validation | Good | Field length constraints on all signaling inputs |\n| Codec negotiation | Adequate | Server validates against supported codec set |\n| Channel permissions | Missing | No ACL — any authenticated user can join any voice channel |\n| Transport auth | Good | DTLS parameters exchanged per-connection |\n| Error exposure | Minor | Internal mediasoup errors forwarded to client |\n\n---\n\n## 8. Recommended Priority Order\n\n### Phase 1 — Stability (Critical)\n1. Add timeout to `initializeMediaTransports()` RPC calls\n2. Surface audio playback failures to UI (toast/notification)\n3. Invalidate router cache when channel codec settings change\n4. Add consumer cleanup when producer closes (server-side)\n5. Add auto-reconnect when WebSocket recovers\n\n### Phase 2 — Security & Robustness (High)\n6. Implement channel permission checks for voice join\n7. Fix TOCTOU race on camera/screen producer limits (use lock)\n8. Add mediasoup worker health monitoring + auto-restart\n9. Handle producer owner lookup failures gracefully\n10. Add bitrate enforcement on consumers\n\n### Phase 3 — Optimization (Medium)\n11. Switch VAD from RAF to 50ms setInterval\n12. Batch producer notifications on recv transport creation\n13. Add signaling retry with exponential backoff\n14. Fix voice activity self-broadcast (exclude sender)\n15. Make VAD hold duration configurable (default 300ms)\n16. Consider voice membership DB persistence for crash recovery\n\n### Phase 4 — Polish (Low)\n17. Extract magic numbers to named constants\n18. Consolidate volume clamping utility\n19. Add video tile pagination for large groups\n20. Debounce native capture metrics polling\n\n---\n\n*Report generated: 2026-02-23*\n*Scope: client/src/api/media/*, client/src/stores/voice.ts, client/src/components/, client/src-tauri/, server/src/media/*, server/src/ws/*\n"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4272,"cache_read_input_tokens":39788,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4272},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRBjumGU8XJXvR735siq","type":"assistant","uuid":"d073fcde-d8fd-4171-b360-7e4d7e02289c","timestamp":"2026-02-23T14:51:07.048Z"}
{"type":"file-history-snapshot","messageId":"d073fcde-d8fd-4171-b360-7e4d7e02289c","snapshot":{"messageId":"e80e1af5-319b-47b1-bd2f-035936002109","trackedFileBackups":{"VOICE-CHAT-REVIEW.md":{"backupFileName":null,"version":1,"backupTime":"2026-02-23T15:19:58.333Z"}},"timestamp":"2026-02-23T14:48:03.554Z"},"isSnapshotUpdate":true}
{"parentUuid":"d073fcde-d8fd-4171-b360-7e4d7e02289c","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Write","command":"callback"},"parentToolUseID":"toolu_01LuHhXXJo8MRCfyfgjcHETT","toolUseID":"toolu_01LuHhXXJo8MRCfyfgjcHETT","timestamp":"2026-02-23T15:19:58.758Z","uuid":"86d4e91b-7b79-4354-bb5e-32c860e4c10b"}
{"parentUuid":"d073fcde-d8fd-4171-b360-7e4d7e02289c","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LuHhXXJo8MRCfyfgjcHETT","type":"tool_result","content":"File created successfully at: REDACTED.md"}]},"uuid":"00a8fd63-6f37-4a16-981f-344a71cd1c34","timestamp":"2026-02-23T15:19:58.755Z","toolUseResult":{"type":"create","filePath":"REDACTED.md","content":"# Yankcord Voice Chat Module - Comprehensive Review\n\n## Executive Summary\n\nThe voice system implements a **Selective Forwarding Unit (SFU)** architecture using **mediasoup** on both client and server. The Rust server manages mediasoup workers, routers, and transports. The TypeScript client uses `mediasoup-client` with the Web Audio API for audio processing. The Tauri desktop client **reuses 100% of the web client's voice code** through its Chromium webview, adding only native screen capture (video-only) via Rust.\n\n**Architecture is sound.** The codebase demonstrates clean separation of concerns, proper resource lifecycle management, and a well-designed signaling protocol. However, there are several critical and high-priority issues that need attention for production readiness.\n\n---\n\n## 1. Architecture Overview\n\n```\n                         CLIENT (Web / Tauri)\n┌──────────────────────────────────────────────────────────────┐\n│  ChannelList.tsx (orchestration)                             │\n│    ├─ VoiceDock.tsx (controls UI)                            │\n│    ├─ VideoStage.tsx (video grid)                            │\n│    └─ voice.ts store (reactive state via SolidJS signals)    │\n│                                                              │\n│  api/media/ (15 modules)                                     │\n│    ├─ transports.ts   (WebRTC send/recv transport lifecycle) │\n│    ├─ producers.ts    (mic, camera, screen share outgoing)   │\n│    ├─ consumers.ts    (remote audio/video incoming)          │\n│    ├─ signaling.ts    (request-response over WebSocket)      │\n│    ├─ voiceActivity.ts(VAD via FFT/RMS analysis)             │\n│    ├─ microphoneProcessing.ts (outgoing gain control)        │\n│    ├─ devices.ts      (hot-swap mic/camera/speaker)          │\n│    ├─ constraints.ts  (media constraints builder)            │\n│    ├─ codecs.ts       (codec selection & preference)         │\n│    ├─ native.ts       (Tauri screen capture bridge)          │\n│    ├─ subscriptions.ts(pub-sub for media state changes)      │\n│    ├─ errors.ts       (user-friendly error messages)         │\n│    └─ state.ts        (module-level non-reactive state)      │\n└──────────────────────────────────────────────────────────────┘\n                              │\n                    WebSocket + WebRTC\n                              │\n                          SERVER (Rust)\n┌──────────────────────────────────────────────────────────────┐\n│  ws/handler.rs     (voice join/leave, speaking events)       │\n│  ws/media_signal.rs(signaling protocol, 9 action types)      │\n│  ws/voice.rs       (broadcast helpers)                       │\n│  ws/broadcast.rs   (cleanup, state management)               │\n│                                                              │\n│  media/                                                      │\n│    ├─ mod.rs          (MediaService, workers, router cache)  │\n│    ├─ router.rs       (opus config, codec definitions)       │\n│    ├─ transport.rs    (transport/producer/consumer mgmt)     │\n│    └─ native_codec.rs (native RTP screen sharing)            │\n│                                                              │\n│  In-Memory State:                                            │\n│    voice_members_by_connection: HashMap<ConnId, ChannelId>   │\n│    voice_members_by_channel: HashMap<ChannelId, Set<User>>   │\n│                                                              │\n│  Database: channels table (opus_bitrate, opus_dtx, opus_fec) │\n└──────────────────────────────────────────────────────────────┘\n```\n\n### Connection Lifecycle\n\n```\n1. Client sends JoinVoice { channel_id } over WebSocket\n2. Server validates channel, updates in-memory state, broadcasts VoiceUserJoined\n3. Server sends VoiceJoined back to client\n4. Client calls initializeMediaTransports(channelId):\n   a. Requests RTP capabilities from server\n   b. Loads mediasoup Device\n   c. Creates Send + Recv WebRTC transports\n   d. Wires DTLS connect + ICE monitoring\n   e. Starts local audio producer (getUserMedia → gain → produce)\n   f. Starts voice activity monitoring (FFT/RMS loop)\n   g. Flushes queued remote producer announcements → consume each\n5. On new_producer signal: consumeRemoteProducer()\n   - Audio: HTMLAudioElement → SourceNode → Compressor → GainNode → Destination\n   - Video: RemoteVideoTile entry\n6. On LeaveVoice: closeTransports() → cleanup all resources → reset state\n```\n\n---\n\n## 2. Client-Side Review\n\n### 2.1 File Inventory\n\n| File | Purpose | Lines | Risk |\n|------|---------|-------|------|\n| `stores/voice.ts` | Reactive state (SolidJS signals) | 413 | Low |\n| `api/media/state.ts` | Module-level non-reactive state | 144 | Low |\n| `api/media/transports.ts` | WebRTC transport setup & lifecycle | 376 | Medium |\n| `api/media/producers.ts` | Outgoing audio/video/screen | 737 | High |\n| `api/media/consumers.ts` | Incoming audio/video playback | 382 | High |\n| `api/media/voiceActivity.ts` | Speaking detection (VAD) | 111 | Medium |\n| `api/media/microphoneProcessing.ts` | Outgoing volume gain | 104 | Medium |\n| `api/media/signaling.ts` | WebSocket request-response | 178 | Medium |\n| `api/media/subscriptions.ts` | Publisher-subscriber pattern | 122 | Low |\n| `api/media/devices.ts` | Audio/video device management | 150+ | High |\n| `api/media/constraints.ts` | Media constraints builder | 97 | Low |\n| `api/media/codecs.ts` | Codec selection & preference | ~80 | Low |\n| `api/media/errors.ts` | Error normalization | 72 | Low |\n| `api/media/native.ts` | Tauri screen capture bridge | 88 | Medium |\n| `components/channel-list/VoiceDock.tsx` | Voice control panel UI | 131 | Low |\n| `components/VideoStage.tsx` | Video tile grid | 78 | Low |\n| `components/settings/VoiceAudioPreferences.tsx` | Voice settings UI | 110 | Low |\n| `components/ChannelList.tsx` | Main voice integration/orchestration | 1200+ | High |\n\n### 2.2 Audio Processing Chain\n\n**Outgoing (microphone):**\n```\ngetUserMedia(constraints)\n  → SourceNode\n    → GainNode (outgoing volume 0-200%)\n      → MediaStreamDestination (processed track)\n        → mediasoup Producer\n```\n\n**Incoming (remote participants):**\n```\nmediasoup Consumer track\n  → MediaStreamSource\n    → DynamicsCompressorNode (auto-level normalization)\n      → GainNode (per-user volume 0-200%)\n        → AudioContext.destination\n          → HTMLAudioElement (playback)\n```\n\nNormalization settings: threshold -24dB, knee 20dB, ratio 3:1, attack 3ms, release 250ms.\n\n### 2.3 Voice Activity Detection\n\n- FFT size: 512 samples\n- Smoothing: 0.85 time constant\n- Speaking threshold: RMS >= 0.04 (4%)\n- Hold duration: 220ms (prevents jitter between speech segments)\n- Runs via `requestAnimationFrame` (60fps)\n\n### 2.4 Screen Share - Two Modes\n\n**Browser mode** (web + Tauri fallback):\n- Uses `getDisplayMedia()` API\n- Supports 720p/1080p/1440p/4K at 30/60 FPS\n- Codec preference: H.264 > VP8 > VP9\n- Content hint: \"motion\" (high FPS) or \"detail\" (low FPS)\n\n**Native Tauri mode** (desktop only):\n- Uses Rust backend RTP sender\n- H.264 only (NVENC hardware acceleration when available)\n- Fallback monitoring every 1s for encoder failures\n- Diagnostics reported to server\n- Falls back to browser mode if native fails\n\n### 2.5 Device Management\n\n- Hot-swap microphone at runtime (replaces producer track)\n- Hot-swap camera (replaces producer track)\n- Speaker routing via `HTMLAudioElement.setSinkId()`\n- Device change detection via `navigator.mediaDevices.ondevicechange`\n- Automatic reset if current device disappears\n\n---\n\n## 3. Server-Side Review\n\n### 3.1 File Inventory\n\n| File | Purpose | Lines | Risk |\n|------|---------|-------|------|\n| `media/mod.rs` | MediaService, worker/router lifecycle | 177 | High |\n| `media/router.rs` | Opus config, codec definitions | 91 | Medium |\n| `media/transport.rs` | Transport/producer/consumer management | 656 | High |\n| `media/native_codec.rs` | Native video codec, screen sharing | 215 | Medium |\n| `ws/media_signal.rs` | Media signaling protocol handler | 1064 | High |\n| `ws/voice.rs` | Voice broadcast functions | 118 | Low |\n| `ws/handler.rs` | Voice join/leave, main WS handler | 1416 | High |\n| `ws/broadcast.rs` | State cleanup, connection management | 400 | Medium |\n\n### 3.2 MediaService Architecture\n\n- **Workers**: Configurable count via `MEDIA_WORKER_COUNT` (default: 2)\n- **Router caching**: Per-channel, deterministic worker assignment via `channel_id.as_bytes()[0] % worker_count`\n- **Transport types**: WebRtcTransport (send/recv) + PlainTransport (native RTP)\n- **Rate limiting**: 80 media signal events per 5-second window per connection\n- **Payload limit**: 32 KB per media signal\n\n### 3.3 Supported Codecs\n\n**Audio**: Opus (48kHz, stereo, 2ch) with configurable bitrate/DTX/FEC per channel\n**Video**: VP8, H.264 (packetization-mode=1, profile 42e01f), VP9, AV1\n**RTCP Feedback**: Nack, NackPli, CcmFir, GoogRemb, TransportCc\n\n### 3.4 Signaling Protocol\n\n9 action types over WebSocket:\n\n| Action | Purpose |\n|--------|---------|\n| `GetRouterRtpCapabilities` | Get channel's codec capabilities |\n| `CreateWebrtcTransport` | Create send or recv transport |\n| `ConnectWebrtcTransport` | Complete DTLS handshake |\n| `MediaProduce` | Create audio/video producer |\n| `MediaConsume` | Create consumer for remote producer |\n| `MediaResumeConsumer` | Resume paused consumer |\n| `MediaCloseProducer` | Close a producer |\n| `CreateNativeSenderSession` | Setup native RTP screen sharing |\n| `ClientDiagnostic` | Log client diagnostic data |\n\nRequest-response pattern with unique IDs (`media-{timestamp}-{counter}`), 10-second timeout.\n\n### 3.5 In-Memory Voice State\n\n```rust\nvoice_members_by_connection: HashMap<Uuid, Uuid>         // connection -> channel\nvoice_members_by_channel: HashMap<Uuid, HashSet<String>>  // channel -> usernames\n```\n\nNo database persistence. Server restart loses all voice sessions.\n\n### 3.6 Producer Constraints\n\n- One camera producer per connection\n- One screen producer per connection\n- No limit on microphone producers\n- Kind must match source (audio ↔ microphone, video ↔ camera/screen)\n- Only \"sfu\" routing mode supported\n\n---\n\n## 4. Tauri Desktop Client\n\n### What Tauri Adds\n\nThe Tauri Rust backend provides **only video capture** commands:\n1. `list_native_capture_sources` - Enumerate screens/windows/apps\n2. `native_codec_capabilities` - Report available video codecs\n3. `start_native_capture` - Start hardware-accelerated screen capture\n4. `stop_native_capture` - Stop capture\n5. `native_capture_status` - Encoding/RTP metrics\n\n### What Tauri Does NOT Do\n\n- **No native audio capture** (no cpal, rodio, or dasp)\n- **No native audio processing** (no noise suppression or echo cancellation)\n- **No audio device management** (all via `navigator.mediaDevices`)\n- **No separate voice transport** (same WebRTC via Chromium webview)\n\n### Correct Architecture Choice\n\nThis is the right approach. Tauri's Chromium webview provides full WebRTC with optimized audio (libwebrtc's AEC, NS, AGC), making native audio redundant. Native screen capture adds value because `getDisplayMedia()` has limitations on desktop (no NVENC, limited window selection).\n\n---\n\n## 5. Issues & Recommendations\n\n### CRITICAL\n\n| # | Issue | Location | Impact |\n|---|-------|----------|--------|\n| C1 | **No voice membership persistence** | Server in-memory only | Server restart drops all voice sessions silently. Clients have no mechanism to detect and rejoin. |\n| C2 | **Router codec settings never update** | `media/mod.rs` router cache | Changing channel opus_bitrate/dtx/fec after first user joins has no effect until server restart. |\n| C3 | **No consumer auto-cleanup on producer close** | `media/transport.rs` | Consumers remain in HashMap after producer closes, causing memory leak over time. |\n| C4 | **No timeout on transport creation** | `transports.ts:279` | If server hangs responding to capabilities request, `initializeMediaTransports()` blocks indefinitely. |\n| C5 | **Silent audio playback failure** | `consumers.ts:247-265` | If `audio.play()` fails twice, error is logged but user hears silence with no UI feedback. |\n\n### HIGH\n\n| # | Issue | Location | Impact |\n|---|-------|----------|--------|\n| H1 | **No channel permission checks for voice** | `ws/handler.rs` | Any authenticated user can join any voice channel. No ACL or role-based access control. |\n| H2 | **TOCTOU race on camera/screen limit** | `transport.rs:266-321` | Duplicate producer check happens twice with a gap. Concurrent requests could both pass. |\n| H3 | **Producer owner lookup silently fails** | `transport.rs:555-600` | When recv transport created and owner disconnected, consumer doesn't receive producer notification. |\n| H4 | **No mediasoup worker health monitoring** | `media/mod.rs` | Worker crash causes silent failure. No restart logic, no health checks. |\n| H5 | **No reconnection logic** | Client transports | If WebSocket reconnects, media transports are not re-established automatically. User must manually retry. |\n| H6 | **Screen share native fallback is sticky** | `producers.ts:680-685` | Once `nativeCaptureAttempted` set true, user can't retry browser mode without page reload. |\n| H7 | **No bandwidth/bitrate enforcement** | Server consumers | Consumers created without bitrate limits. No congestion control feedback. Network overload possible. |\n\n### MEDIUM\n\n| # | Issue | Location | Impact |\n|---|-------|----------|--------|\n| M1 | **VAD uses requestAnimationFrame** | `voiceActivity.ts` | 60fps monitoring is overkill. A 50ms `setInterval` (~20fps) would suffice and save CPU. |\n| M2 | **Slow producer notification batching** | `transport.rs:555-600` | N producers = N separate JSON messages on recv transport creation. Should batch. |\n| M3 | **Voice activity broadcast includes self** | `ws/handler.rs:611-632` | `exclude_connection_id` is None — client receives its own speaking event. |\n| M4 | **VAD hold duration too short** | `voiceActivity.ts:77-78` | 220ms can miss natural speech pauses. 300-400ms or configurable would be better. |\n| M5 | **Audio play() retry is naive** | `consumers.ts` | Hardcoded 500ms delay, no exponential backoff, only 2 attempts. |\n| M6 | **Transport health race condition** | `transports.ts:106-112` | Multiple transports closing in parallel could set health state to wrong value. |\n| M7 | **Microphone processing resource leak** | `microphoneProcessing.ts` | If `activateMicrophoneProcessing()` called without prior cleanup, old session is orphaned. |\n| M8 | **No signaling retry logic** | `signaling.ts` | First 10-second timeout = permanent failure. No retry for transient network issues. |\n| M9 | **Transport direction silently replaced** | `transport.rs` | Creating send transport twice replaces first without error. |\n| M10 | **Mediasoup errors exposed to client** | `ws/media_signal.rs` | Internal error messages sent directly, potential information disclosure. |\n\n### LOW / CODE QUALITY\n\n| # | Issue | Location |\n|---|-------|----------|\n| L1 | Volume clamping function duplicated | `consumers.ts` + `microphoneProcessing.ts` |\n| L2 | Magic numbers not extracted to constants | Multiple files (10000ms, 220ms, 512 FFT, 0.04 threshold) |\n| L3 | Inconsistent error handling | Mix of `console.warn`, `console.error`, and throw |\n| L4 | No subscriber count limits | `subscriptions.ts` — potential memory leak |\n| L5 | NormalizationNode config recreated per consumer | `consumers.ts` — should be module constant |\n| L6 | No video tile pagination | `VideoStage.tsx` — unwieldy with many participants |\n| L7 | Native metrics polling always 1s | `VoiceDock.tsx` — constant IPC overhead during screen share |\n\n---\n\n## 6. Performance Notes\n\n### Audio Contexts\nThe system creates up to 3 AudioContexts simultaneously (mic level monitoring, remote playback, mic processing). Browsers limit to ~10 contexts, so this is safe but could be consolidated.\n\n### Voice Activity Detection\nRunning at 60fps via RAF is wasteful. Voice detection at 20fps (50ms interval) would be indistinguishable to users and reduce CPU usage by ~66%.\n\n### Native Screen Capture Polling\n1-second interval polling from Rust backend for metrics runs constantly during screen sharing. Could debounce to 2-3 seconds.\n\n### Remote Audio Elements\n`remoteAudioElements` map keeps references to all audio elements. Elements are disconnected on cleanup but not removed from DOM in all paths.\n\n---\n\n## 7. Security Considerations\n\n| Area | Status | Notes |\n|------|--------|-------|\n| Rate limiting | Good | 80 events/5s per connection, 32KB payload limit |\n| Payload validation | Good | Field length constraints on all signaling inputs |\n| Codec negotiation | Adequate | Server validates against supported codec set |\n| Channel permissions | Missing | No ACL — any authenticated user can join any voice channel |\n| Transport auth | Good | DTLS parameters exchanged per-connection |\n| Error exposure | Minor | Internal mediasoup errors forwarded to client |\n\n---\n\n## 8. Recommended Priority Order\n\n### Phase 1 — Stability (Critical)\n1. Add timeout to `initializeMediaTransports()` RPC calls\n2. Surface audio playback failures to UI (toast/notification)\n3. Invalidate router cache when channel codec settings change\n4. Add consumer cleanup when producer closes (server-side)\n5. Add auto-reconnect when WebSocket recovers\n\n### Phase 2 — Security & Robustness (High)\n6. Implement channel permission checks for voice join\n7. Fix TOCTOU race on camera/screen producer limits (use lock)\n8. Add mediasoup worker health monitoring + auto-restart\n9. Handle producer owner lookup failures gracefully\n10. Add bitrate enforcement on consumers\n\n### Phase 3 — Optimization (Medium)\n11. Switch VAD from RAF to 50ms setInterval\n12. Batch producer notifications on recv transport creation\n13. Add signaling retry with exponential backoff\n14. Fix voice activity self-broadcast (exclude sender)\n15. Make VAD hold duration configurable (default 300ms)\n16. Consider voice membership DB persistence for crash recovery\n\n### Phase 4 — Polish (Low)\n17. Extract magic numbers to named constants\n18. Consolidate volume clamping utility\n19. Add video tile pagination for large groups\n20. Debounce native capture metrics polling\n\n---\n\n*Report generated: 2026-02-23*\n*Scope: client/src/api/media/*, client/src/stores/voice.ts, client/src/components/, client/src-tauri/, server/src/media/*, server/src/ws/*\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"d073fcde-d8fd-4171-b360-7e4d7e02289c"}
{"parentUuid":"00a8fd63-6f37-4a16-981f-344a71cd1c34","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_016vaZC7kDxmuTzUYiRtmqzX","type":"message","role":"assistant","content":[{"type":"text","text":"Done. The report has been written to **`VOICE-CHAT-REVIEW.md`** at the project root.\n\n### Summary of findings:\n\n**Architecture**: Well-designed SFU using mediasoup, clean separation between signaling (WebSocket) and media (WebRTC). Tauri correctly reuses the web client's voice code entirely, only adding native screen capture.\n\n**5 Critical issues** found:\n- No voice membership persistence (server restart drops all sessions)\n- Router codec cache never invalidates on settings change\n- Consumer memory leak when producers close\n- No timeout on transport initialization\n- Silent audio playback failures\n\n**7 High priority issues** including missing channel permissions for voice, TOCTOU race conditions on producer limits, no worker health monitoring, and no auto-reconnect.\n\n**10 Medium issues** including VAD running at 60fps (wasteful), no signaling retry logic, and voice activity broadcast including the sender.\n\nThe report includes a prioritized 4-phase remediation plan."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5506,"cache_read_input_tokens":44060,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":5506},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRE5hfHU9xh9hi65hore","type":"assistant","uuid":"ff13c945-5c99-4b34-9fc2-f2ccabd2529e","timestamp":"2026-02-23T15:20:06.632Z"}
{"parentUuid":"ff13c945-5c99-4b34-9fc2-f2ccabd2529e","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"ff319a91-52d1-45d6-a68a-7320304d6677","toolUseID":"ff319a91-52d1-45d6-a68a-7320304d6677","timestamp":"2026-02-23T15:20:06.650Z","uuid":"a66bc5a3-44e6-48cd-91b0-20f2002ad728"}
{"type":"queue-operation","operation":"dequeue","timestamp":"2026-02-23T15:20:17.943Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c"}
{"parentUuid":"a66bc5a3-44e6-48cd-91b0-20f2002ad728","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":3989}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-23T15:20:10.640Z","uuid":"e079ff2a-b713-47ff-baa9-9e09b32c9484","toolUseID":"ff319a91-52d1-45d6-a68a-7320304d6677"}
{"parentUuid":"e079ff2a-b713-47ff-baa9-9e09b32c9484","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"system","subtype":"turn_duration","durationMs":203201,"timestamp":"2026-02-23T15:20:17.925Z","uuid":"e4209178-def0-4ba4-8aa3-69705a3f350a","isMeta":false}
{"parentUuid":"e4209178-def0-4ba4-8aa3-69705a3f350a","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":"<task-notification>\n<task-id>a492c1f</task-id>\n<tool-use-id>toolu_01NPHycHRM9WQH7WoLj71rUN</tool-use-id>\n<status>completed</status>\n<summary>Agent \"Explore voice chat server code\" completed</summary>\n<result>Now I have comprehensive information. Let me create a thorough report:\n\n## COMPREHENSIVE SERVER-SIDE VOICE CHAT / WEBRTC / MEDIASOUP ANALYSIS\n\n### EXECUTIVE SUMMARY\n\nThe Yankcord server implements a complete SFU (Selective Forwarding Unit) architecture for voice communication using mediasoup. The system manages WebRTC connections, audio/video producers and consumers, and maintains voice channel state through a combination of database persistence, in-memory state tracking, and real-time WebSocket signaling.\n\n---\n\n### 1. MEDIASOUP ARCHITECTURE & WORKER LIFECYCLE\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/mod.rs`\n\n#### Key Components:\n\n**MediaService Structure:**\n```rust\npub struct MediaService {\n    workers: Vec<Worker>,\n    routers: Arc<Mutex<HashMap<Uuid, Router>>>,\n    connection_media: Arc<Mutex<HashMap<Uuid, transport::ConnectionMediaState>>>,\n    webrtc_listen_ip: IpAddr,\n    announced_ip: Option<String>,\n    native_rtp_listen_ip: IpAddr,\n    native_rtp_announced_ip: Option<IpAddr>,\n}\n```\n\n**Worker Initialization:**\n- Creates N workers based on `MEDIA_WORKER_COUNT` configuration (default: 2)\n- Workers are created synchronously during server startup\n- Each worker is managed by mediasoup's WorkerManager\n- No documented worker lifecycle management (no restart/health-check logic)\n\n**Router Management:**\n- Routers are cached per channel_id in a HashMap\n- Router assignment uses deterministic worker selection: `channel_id.as_bytes()[0] as usize % self.workers.len()`\n- **Critical Issue**: Router caching means codec settings (opus_bitrate, opus_dtx, opus_fec) set at channel creation time are never updated after router creation, even if channel settings change\n- Routers can be manually invalidated via `invalidate_router()` to force recreation\n\n**Network Configuration:**\n- WebRTC transport listen IP and announced IP are configurable\n- Native RTP (for screen sharing) has separate listen/announced IP configuration\n- Fallback to localhost (127.0.0.1) if IP parsing fails with warnings\n\n---\n\n### 2. ROUTER & CODEC CONFIGURATION\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/router.rs`\n\n#### Opus Configuration:\n```rust\npub struct OpusConfig {\n    pub bitrate: Option<u32>,          // Max average bitrate\n    pub dtx: Option<bool>,              // Discontinuous Transmission\n    pub fec: Option<bool>,              // Forward Error Correction\n}\n```\n\n**Supported Codecs:**\n- **Audio**: Opus (48kHz, stereo, 2 channels)\n  - RTCP Feedback: TransportCc\n  - Parameters: maxaveragebitrate, usedtx, useinbandfec\n- **Video**: VP8, H.264, VP9, AV1\n  - RTCP Feedback: Nack, NackPli, CcmFir, GoogRemb, TransportCc\n  - H.264: packetization-mode=1, profile-level-id=42e01f\n\n**Configuration Concerns:**\n1. Opus parameters are applied at router creation only\n2. No runtime codec parameter updates\n3. Video codec negotiation not fully exposed to clients\n4. Database schema stores opus settings but no per-message codec negotiation\n\n**Database Schema (channels table):**\n```sql\nopus_bitrate INTEGER      -- Max bitrate in bps\nopus_dtx     BOOLEAN      -- Enable DTX\nopus_fec     BOOLEAN      -- Enable FEC\n```\n\n---\n\n### 3. TRANSPORT MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs`\n\n#### ConnectionMediaState Structure:\n```rust\npub struct ConnectionMediaState {\n    pub channel_id: Uuid,\n    pub send_transport_id: Option<String>,\n    pub recv_transport_id: Option<String>,\n    pub transports: HashMap<String, WebRtcTransport>,\n    pub native_transports_by_producer: HashMap<String, PlainTransport>,\n    pub producers: HashMap<String, ProducerEntry>,\n    pub consumers: HashMap<String, Consumer>,\n}\n```\n\n**Transport Creation:**\n1. **SendTransport**: Used for uploading audio/video from client\n   - Created per direction on demand\n   - Replaced if same direction requested again\n   - Uses WebRtcTransport with configured listen IPs\n\n2. **RecvTransport**: Used for downloading media from other participants\n   - Created per direction on demand\n   - Sends existing producers to new recv transport creators\n   - Also uses WebRtcTransport\n\n3. **PlainTransport**: Used for native screen sharing\n   - Created on demand for screen producers\n   - Uses raw RTP/UDP\n   - Comedia enabled (automatic endpoint detection)\n   - RTCP multiplexed (rtcp_mux=true)\n\n**Critical Logic Issues:**\n\n1. **Channel Validation on Send Transport Creation (Lines 154-162):**\n   - If connection switches channels, old ConnectionMediaState is cleared\n   - **Issue**: Session switching doesn't properly validate permissions\n\n2. **Duplicate Producer Check (Lines 266-282, 305-321):**\n   - Checked TWICE: once before creating and once after\n   - Race condition possible between checks\n   - Only one camera and one screen producer allowed per connection\n\n3. **Recv Transport Producer Snapshot (Lines 555-600):**\n   - When recv transport created, sends all existing channel producers\n   - **Issue**: Producer owner username lookup may fail silently (line 570-575)\n   - If owner disconnected, producer info not sent to new consumer\n\n**Producer Lifecycle:**\n```\n1. Client creates send transport\n2. Client connects send transport (DTLS handshake)\n3. Client calls MediaProduce with RTP parameters\n4. Server creates producer on send transport\n5. Producer added to state.producers HashMap\n6. Other clients notified via broadcast (\"new_producer\")\n7. Other clients create consumers on their recv transports\n8. Client can close producer via MediaCloseProducer\n```\n\n---\n\n### 4. PRODUCER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 238-340)\n\n#### ProducerSource Enum:\n```rust\npub enum ProducerSource {\n    Microphone,  // Audio only\n    Camera,      // Video only\n    Screen,      // Video only\n}\n```\n\n#### Validation Constraints:\n1. **One camera per connection**: Prevents multiple camera producers simultaneously\n2. **One screen per connection**: Prevents multiple screen shares\n3. **Microphone**: No per-connection limit (multiple microphone sources possible)\n4. **Kind/Source Validation**: Kind must match source (e.g., \"microphone\" requires kind=\"audio\")\n\n#### Producer Creation Flow:\n```\nClient sends: MediaProduce {\n    kind: \"audio\"|\"video\",\n    source: \"microphone\"|\"camera\"|\"screen\",\n    routing_mode: \"sfu\",\n    rtp_parameters: RtpParameters\n}\n\nServer:\n1. Validates routing_mode (only \"sfu\" allowed, no mesh/hybrid)\n2. Validates source matches kind\n3. Verifies send transport exists\n4. Checks camera/screen limits\n5. Creates producer with mediasoup\n6. Stores in state.producers\n7. Broadcasts to all channel members\n```\n\n---\n\n### 5. CONSUMER MANAGEMENT\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/transport.rs` (Lines 488-568)\n\n#### Consumer Creation Logic:\n```rust\npub async fn create_consumer_for_connection(\n    connection_id: Uuid,\n    channel_id: Uuid,\n    producer_id: &str,\n    rtp_capabilities: RtpCapabilities,\n) -> Result<CreatedConsumer, String>\n```\n\n**Key Properties:**\n- Created in PAUSED state: `consumer_options.paused = true`\n- Client must call `MediaResumeConsumer` to start receiving\n- RTP parameters negotiated based on client capabilities\n\n**Validations:**\n1. Producer must exist in same channel\n2. Client must be in channel\n3. Client RTP capabilities must be able to consume producer\n4. Router validates compatibility: `router.can_consume()`\n\n**Concerns:**\n- No bitrate limits enforced on consumers\n- No adaptive bitrate control\n- Consumers manually managed (no automatic cleanup on producer close)\n- No bandwidth constraints per channel\n\n---\n\n### 6. NATIVE VIDEO CODEC & SCREEN SHARING\n\n**File:** `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs`\n\n#### Native Video Codec Support:\n```rust\npub enum NativeVideoCodec {\n    H264,   // Ready - PT 96, clock_rate 90kHz\n    Vp8,    // Ready - PT 98, clock_rate 90kHz\n    Vp9,    // Ready - PT 100, clock_rate 90kHz\n    Av1,    // Ready - PT 102, clock_rate 90kHz\n}\n```\n\n#### Native Sender Session (for Screen Sharing):\n```rust\npub struct NativeSenderSession {\n    pub producer_id: String,\n    pub rtp_target: String,           // Address to send RTP to\n    pub payload_type: u8,\n    pub ssrc: u32,                    // Canonical SSRC from connection_id\n    pub mime_type: String,\n    pub clock_rate: u32,\n    pub packetization_mode: u8,       // H.264 only\n    pub profile_level_id: String,     // H.264 only\n    pub codec: NativeCodecDescriptor,\n    pub available_codecs: Vec<NativeCodecDescriptor>,\n}\n```\n\n#### Screen Sharing Flow:\n1. Client requests `CreateNativeSenderSession` with optional preferred codecs\n2. Server creates PlainTransport with comedia=true\n3. Server creates producer on transport\n4. Returns RTP target endpoint and codec parameters\n5. Client sends raw H.264/VP8/VP9/AV1 RTP packets to target\n6. Server forwards through SFU to consumers\n\n**Configuration:**\n- H.264: Packetization mode 1 (single NAL per RTP packet)\n- SSRC deterministically derived from connection_id (first 4 bytes)\n- RTCP cname formatted as `native-{ssrc:x}`\n\n**Issue**: SSRC derivation is deterministic but could theoretically collide for different connection_ids sharing same first 4 bytes. Fallback seed is 0x4E41_5456 if collision detected.\n\n---\n\n### 7. WEBSOCKET SIGNALING LAYER\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs`\n\n#### Media Signal Protocol:\n\n**Request Format:**\n```json\n{\n  \"action\": \"get_router_rtp_capabilities|create_webrtc_transport|...\",\n  \"request_id\": \"optional-string\",\n  \"...\" : \"other params\"\n}\n```\n\n**Supported Actions:**\n1. `GetRouterRtpCapabilities` - Get channel's codec capabilities\n2. `CreateWebrtcTransport` - Create send/recv transport\n3. `ConnectWebrtcTransport` - Complete DTLS handshake\n4. `MediaProduce` - Create producer\n5. `MediaConsume` - Create consumer\n6. `MediaResumeConsumer` - Resume paused consumer\n7. `MediaCloseProducer` - Close producer\n8. `CreateNativeSenderSession` - Setup screen sharing\n9. `ClientDiagnostic` - Log client diagnostics\n\n#### Rate Limiting:\n```rust\nconst MAX_MEDIA_SIGNAL_EVENTS_PER_WINDOW: u32 = 80;\nconst MEDIA_SIGNAL_RATE_WINDOW: Duration = Duration::from_secs(5);\n```\n\n**Limit**: 80 media signal events per 5-second window per connection\n\n#### Validation:\n- request_id max 128 characters\n- Payload size limit: 32 KB\n- Field constraints: direction (16), transport_id (128), kind (16), source (32), routing_mode (16)\n\n#### Error Handling:\n```rust\npub enum MediaSignalSendOutcome {\n    Delivered,\n    Dropped,    // Serialization failed\n    Disconnect, // Queue full or connection closed\n}\n```\n\n**Policy**: Close connection if outbound queue full (prevents slow-consumer problems)\n\n---\n\n### 8. VOICE CHANNEL STATE MANAGEMENT\n\n**Files:**\n- `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 605-631, 1259-1415)\n- `/home/guibibi/projects/yankcord/server/src/ws/voice.rs`\n- `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` (Lines 318-394)\n\n#### In-Memory State Maps:\n```rust\npub struct AppState {\n    // Voice channel membership\n    pub voice_members_by_connection: Arc<RwLock<HashMap<Uuid, Uuid>>>,\n                                     // connection_id -> channel_id\n    pub voice_members_by_channel: Arc<RwLock<HashMap<Uuid, HashSet<String>>>>,\n                                   // channel_id -> usernames\n    // ... other fields\n}\n```\n\n#### Join Flow:\n```\nClient: JoinVoice { channel_id }\n    ↓\nHandler validates:\n    1. Channel exists\n    2. Channel is voice-enabled\n    3. Get channel's opus config\n    ↓\nUpdate state:\n    1. voice_members_by_connection.insert(connection_id, channel_id)\n    2. If switching channels: remove from old channel, cleanup media\n    3. voice_members_by_channel.entry(channel_id).or_default().insert(username)\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserJoined\n    2. Send to client: VoiceJoined { channel_id, user_id }\n```\n\n#### Leave Flow:\n```\nClient: LeaveVoice { channel_id }\n    ↓\nHandler:\n    1. Remove from voice_members_by_connection\n    2. Remove username from voice_members_by_channel\n    3. Cleanup producers via media.cleanup_connection_media()\n    4. Broadcast closed_producers to channel\n    ↓\nBroadcast:\n    1. GlobalMessage: VoiceUserLeft\n    2. Send to client: VoiceLeft { channel_id, user_id }\n```\n\n#### Disconnect Handling:\nWhen WebSocket connection closes:\n1. `cleanup_connection()` called with connection_id\n2. Removes from voice_members_by_connection and voice_members_by_channel\n3. Calls `media.cleanup_connection_media()` to close all producers/consumers\n4. Broadcasts VoiceUserLeft to all channels\n5. Broadcasts closed producer info to affected channels\n\n**Critical State Issue**: \n- No database persistence of voice channel membership\n- Membership purely in-memory\n- Server restart loses all voice session state\n- Clients must rejoin voice channels after server restart\n\n---\n\n### 9. SPEAKING STATUS & VOICE ACTIVITY\n\n**File:** `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` (Lines 611-632)\n\n#### Voice Activity Flow:\n```\nClient: VoiceActivity { channel_id, speaking: bool }\n    ↓\nHandler validates:\n    1. Connection is in the specified channel\n    2. (No rate limiting on speaking events)\n    ↓\nBroadcast:\n    broadcast_voice_activity_to_channel(state, channel_id, username, speaking, None)\n    └─> Sends to all OTHER connections in channel:\n        ServerMessage::VoiceUserSpeaking {\n            channel_id,\n            username,\n            speaking\n        }\n```\n\n**Important Notes:**\n- No database recording of speaking status\n- Purely ephemeral, real-time signaling\n- No speaking history or analytics\n- Clients independently detect voice activity (VAD on client side)\n\n---\n\n### 10. PRODUCER/CONSUMER LIFECYCLE & CLEANUP\n\n**Producer Cleanup:**\n```\nWhen Producer Closed:\n    1. Removed from state.producers\n    2. Removed from native_transports_by_producer (if native)\n    3. Broadcast ClosedProducer message to channel:\n        {\n            \"action\": \"producer_closed\",\n            \"producer_id\": \"...\",\n            \"source\": \"...\",\n            \"routing_mode\": \"...\"\n        }\n```\n\n**Consumer Cleanup:**\n- No explicit cleanup endpoint\n- Consumers auto-close when producer closes\n- Manual close not exposed via WebSocket\n\n**Connection Cleanup:**\n```\nWhen Connection Disconnects:\n    1. state.media.cleanup_connection_media(connection_id)\n       └─> Removes all producers/consumers for this connection\n    2. Returns Vec<ClosedProducer>\n    3. Broadcasts closed_producers to all channels\n```\n\n---\n\n### 11. ISSUES, BUGS & ANTI-PATTERNS\n\n#### CRITICAL ISSUES:\n\n1. **Codec Settings Never Update After Router Creation**\n   - If channel opus_bitrate/dtx/fec changed after first user joins, new users don't get updated settings\n   - Router caching doesn't invalidate on channel update\n   - **Impact**: Codec configuration changes require server restart\n   - **Solution**: Invalidate router when channel settings change\n\n2. **Producer Owner Lookup Silently Fails**\n   - When recv transport created, attempts to get producer owner's username\n   - If owner connection already closed, warns but continues\n   - New consumer doesn't receive \"new_producer\" notification for that producer\n   - **Impact**: Consumer state out of sync with actual producers in channel\n   - **Suggested Fix**: Either cache producer owner info or handle gracefully\n\n3. **No Consumer Auto-Cleanup**\n   - Consumers manually managed, no automatic lifecycle\n   - When producer closes, consumers still exist in HashMap\n   - Consumer close not exposed to client\n   - **Impact**: Memory leak of stale consumers\n   - **Suggested Fix**: Auto-close consumers when producer closes\n\n4. **Duplicate Camera/Screen Check - TOCTOU**\n   - Checked before creation AND after creation\n   - Race condition: two concurrent produce requests could both pass first check\n   - **Impact**: Theoretically could create 2 cameras per connection\n   - **Suggested Fix**: Single atomic check or lock\n\n5. **No Database Persistence of Voice Membership**\n   - Voice state purely in-memory\n   - Server restart loses all state\n   - Clients don't know if they need to rejoin\n   - **Impact**: Broken user experience on server restart\n   - **Suggested Fix**: Persist voice channel membership in database\n\n#### MEDIUM ISSUES:\n\n6. **Slow Consumer Producer Notifications**\n   - When recv transport created, for each producer, sends individual notification\n   - N producers = N separate JSON broadcasts\n   - No batching/bundling of producers list\n   - **Impact**: Inefficient network usage with many producers\n   - **Suggested Fix**: Send producer list in single JSON array\n\n7. **No Bandwidth/Bitrate Enforcement**\n   - Consumers created without bitrate limits\n   - No max-bitrate set on encodings\n   - No congestion control feedback from clients\n   - **Impact**: Network overload possible\n   - **Suggested Fix**: Configure reasonable defaults or per-channel limits\n\n8. **Voice Activity Broadcasting Sends Extra Parameter**\n   - `broadcast_voice_activity_to_channel` sends to ALL except sender\n   - But the exclude_connection_id is set to None\n   - Client sends their own speaking state to themselves too\n   - **Impact**: Redundant message\n   - **Suggested Fix**: Pass Some(connection_id) to exclude self\n\n9. **No Channel Permission Checks**\n   - Join voice doesn't verify user has permission to access channel\n   - No ACL or role-based channel access control for voice\n   - **Impact**: Any authenticated user can join any voice channel\n   - **Suggested Fix**: Add channel permission model\n\n10. **Mediasoup Worker Health Not Monitored**\n    - Workers created at startup, no restart logic\n    - No health checks or deadlock detection\n    - Worker crash would cause silent failures\n    - **Impact**: Server silently stops accepting voice connections\n    - **Suggested Fix**: Add worker health monitoring and auto-restart\n\n#### MINOR ISSUES:\n\n11. **SSRC Derivation Collision Risk**\n    - Canonical SSRC uses only first 4 bytes of UUID\n    - Fallback seed only triggers if exactly 0\n    - **Impact**: Extremely low, but possible SSRC collision\n    - **Suggested Fix**: Use full UUID or CRC32 of full UUID\n\n12. **No Requested Codec Preference Validation**\n    - Client can request any codec, server just filters to ready ones\n    - No limit on preferred_codecs list length\n    - **Impact**: Mild - clients well-behaved, but no server-side guards\n\n13. **Transport Direction Replaced Without Warning**\n    - Creating send transport twice replaces first one\n    - Any media sent on old transport is lost\n    - **Impact**: Client-side bug would lose media\n    - **Suggested Fix**: Return error if transport already exists\n\n14. **Mediasoup Error Messages Exposed**\n    - mediasoup library errors directly sent to client\n    - Could expose internal implementation details\n    - **Impact**: Low security impact, but information disclosure\n\n---\n\n### 12. CONFIGURATION SETTINGS\n\n**File:** `/home/guibibi/projects/yankcord/server/src/config.rs`\n\n```rust\npub struct MediaConfig {\n    pub worker_count: usize,                    // ENV: MEDIA_WORKER_COUNT (default: 2)\n    pub webrtc_listen_ip: String,               // ENV: WEBRTC_LISTEN_IP (default: 0.0.0.0)\n    pub announced_ip: Option<String>,           // ENV: WEBRTC_ANNOUNCED_IP\n    pub native_rtp_listen_ip: String,           // ENV: NATIVE_RTP_LISTEN_IP (default: 127.0.0.1)\n    pub native_rtp_announced_ip: Option<String>,// ENV: NATIVE_RTP_ANNOUNCED_IP\n}\n```\n\n**Environment Variables:**\n- `MEDIA_WORKER_COUNT`: Number of mediasoup workers (must be ≥1)\n- `WEBRTC_LISTEN_IP`: IP for WebRTC transport to listen on\n- `WEBRTC_ANNOUNCED_IP`: Public IP announced in ICE candidates\n- `NATIVE_RTP_LISTEN_IP`: IP for native RTP screen sharing\n- `NATIVE_RTP_ANNOUNCED_IP`: Public IP for native RTP\n\n**WebSocket Configuration (hardcoded):**\n- Outbound queue capacity: 256 messages\n- Idle timeout: 45 seconds\n- Auth timeout: 15 seconds\n- Presence idle (auto-idle status): 5 minutes\n\n**Rate Limiting:**\n- Media signal: 80 events per 5 seconds per connection\n- Payload size limit: 32 KB per media signal\n\n---\n\n### 13. DATABASE SCHEMA FOR VOICE\n\n```sql\n-- Channels table (created in migrations/20260216000001_initial.sql)\nCREATE TABLE channels (\n    id              UUID PRIMARY KEY,\n    name            TEXT NOT NULL,\n    description     TEXT,\n    kind            channel_kind,  -- 'text' or 'voice'\n    position        INT NOT NULL,\n    opus_bitrate    INTEGER,       -- Opus max average bitrate (bps)\n    opus_dtx        BOOLEAN,       -- Opus discontinuous transmission\n    opus_fec        BOOLEAN,       -- Opus forward error correction\n    created_at      TIMESTAMPTZ\n);\n```\n\n**No other voice-specific tables.**\n\n**Missing Features:**\n- No voice history/recording\n- No meeting recordings\n- No voice activity timeline\n- No user voice settings per channel\n- No voice mute/deafen state persistence\n- No voice channel permissions model\n\n---\n\n### 14. KEY FILES & FUNCTIONS SUMMARY\n\n| File | Key Components | Lines |\n|------|-----------------|-------|\n| `/home/guibibi/projects/yankcord/server/src/media/mod.rs` | MediaService, worker/router lifecycle | 177 |\n| `/home/guibibi/projects/yankcord/server/src/media/router.rs` | OpusConfig, codec definitions | 91 |\n| `/home/guibibi/projects/yankcord/server/src/media/transport.rs` | WebRTC transport, producer/consumer lifecycle | 656 |\n| `/home/guibibi/projects/yankcord/server/src/media/native_codec.rs` | Native video codec support, screen sharing | 215 |\n| `/home/guibibi/projects/yankcord/server/src/media/producer.rs` | Producer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/media/consumer.rs` | Consumer stubs | 4 |\n| `/home/guibibi/projects/yankcord/server/src/ws/media_signal.rs` | Media signaling protocol handler | 1064 |\n| `/home/guibibi/projects/yankcord/server/src/ws/voice.rs` | Voice broadcast functions | 118 |\n| `/home/guibibi/projects/yankcord/server/src/ws/handler.rs` | Voice join/leave, main WS handler | 1416 |\n| `/home/guibibi/projects/yankcord/server/src/ws/broadcast.rs` | State cleanup, connection management | 400 |\n| `/home/guibibi/projects/yankcord/server/src/ws/messages.rs` | WebSocket message types | 257 |\n\n---\n\n### 15. ARCHITECTURE DIAGRAM\n\n```\nClient\n  ↓ WebSocket Connection\n┌─────────────────────────────────┐\n│   WebSocket Handler             │\n│   - Authentication              │\n│   - Connection Management       │\n│   - Message Dispatching         │\n└─────────────────────────────────┘\n  ↓\n┌─────────────────────────────────────────────┐\n│   Media Signaling Handler                   │\n│   - Route RTP Capabilities                  │\n│   - Create WebRTC Transport                 │\n│   - Create Producer/Consumer                │\n│   - Rate Limiting (80 events/5s)            │\n└─────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────────────────────┐\n│   MediaService (SFU)                             │\n├──────────────────────────────────────────────────┤\n│  Workers (Vec<Worker>)                           │\n│    ↓                                             │\n│  Routers (HashMap<Uuid, Router>)                 │\n│    ├─ per-channel caching                        │\n│    ├─ codec config (opus, VP8, H264, etc)        │\n│    └─ RTP capability negotiation                 │\n│                                                  │\n│  ConnectionMediaState (HashMap<Uuid, State>)    │\n│    ├─ WebRTC Transports (send/recv)              │\n│    ├─ PlainTransports (native RTP)               │\n│    ├─ Producers (audio/video/screen)             │\n│    └─ Consumers (receive streams)                │\n└──────────────────────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   In-Memory State                │\n├──────────────────────────────────┤\n│  voice_members_by_connection     │\n│    (who's in which channel)      │\n│                                  │\n│  voice_members_by_channel        │\n│    (channel membership list)     │\n│                                  │\n│  media_signal_rate_by_connection │\n│    (rate limiting state)         │\n└──────────────────────────────────┘\n  ↓\n┌──────────────────────────────────┐\n│   Database                       │\n├──────────────────────────────────┤\n│  channels:                       │\n│    - id, name, kind='voice'      │\n│    - opus_bitrate, opus_dtx,fec  │\n└──────────────────────────────────┘\n```\n\n---\n\n### 16. RECOMMENDATIONS & IMPROVEMENTS\n\n**Priority 1 (Critical):**\n1. Add database persistence for voice channel membership\n2. Invalidate router cache when channel codec settings change\n3. Fix consumer auto-cleanup when producer closes\n4. Add channel permission checks for voice access\n\n**Priority 2 (High):**\n5. Implement worker health monitoring\n6. Batch producer notifications on recv transport creation\n7. Add bitrate enforcement/limits per consumer\n8. Fix producer owner lookup failure handling\n9. Add TOCTOU guard for camera/screen limit checks\n\n**Priority 3 (Medium):**\n10. Implement consumer lifecycle management\n11. Add voice history/analytics database table\n12. Implement voice activity recording\n13. Add per-user voice settings model\n14. Implement voice mute/deafen persistence\n\n**Priority 4 (Nice to Have):**\n15. Add multiple transport error recovery\n16. Implement auto-reconnection guidance\n17. Add voice quality metrics collection\n18. Implement adaptive bitrate adjustment\n19. Support REMB/TWCC congestion control feedback\n\n---\n\n### CONCLUSION\n\nThe Yankcord voice system is a **well-architected SFU implementation** using mediasoup. It handles WebRTC connections, producer/consumer management, and signaling correctly. However, it has **several critical issues** around codec setting persistence, consumer lifecycle management, and state recovery that should be addressed before production use. The architecture is sound but needs hardening for robustness and reliability.</result>\n<usage><total_tokens>80577</total_tokens><tool_uses>33</tool_uses><duration_ms>124352</duration_ms></usage>\n</task-notification>\nFull transcript available at: REDACTED.output"},"uuid":"b837ec00-79a0-4230-be5f-00aad8972b0e","timestamp":"2026-02-23T15:20:17.965Z","permissionMode":"default"}
{"parentUuid":"b837ec00-79a0-4230-be5f-00aad8972b0e","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01EWDc4gi5SXwavBRzfcVyYP","type":"message","role":"assistant","content":[{"type":"text","text":"The report has already been written to `VOICE-CHAT-REVIEW.md` — all three exploration agents (client, server, Tauri) finished and their findings are consolidated in that file."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7493,"cache_read_input_tokens":49791,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7493},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRE7KsRBwGyM8VHZxovn","type":"assistant","uuid":"c01add58-320e-45cc-80a8-c76f3a7c1b54","timestamp":"2026-02-23T15:20:24.525Z"}
{"parentUuid":"c01add58-320e-45cc-80a8-c76f3a7c1b54","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"6e40db40-fad3-46a9-b946-bdce975b0ede","toolUseID":"6e40db40-fad3-46a9-b946-bdce975b0ede","timestamp":"2026-02-23T15:20:24.553Z","uuid":"adad231a-f85c-40aa-9cb8-23a8fb9c2c44"}
{"type":"queue-operation","operation":"dequeue","timestamp":"2026-02-23T15:20:33.387Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c"}
{"parentUuid":"adad231a-f85c-40aa-9cb8-23a8fb9c2c44","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1788}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-23T15:20:26.342Z","uuid":"68af00c9-5358-40b6-ba87-22f1809c2cb6","toolUseID":"6e40db40-fad3-46a9-b946-bdce975b0ede"}
{"parentUuid":"68af00c9-5358-40b6-ba87-22f1809c2cb6","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":"<task-notification>\n<task-id>a4a521c</task-id>\n<tool-use-id>REDACTED</tool-use-id>\n<status>completed</status>\n<summary>Agent \"Explore voice chat client code\" completed</summary>\n<result>Perfect! Now I have a comprehensive view of the voice/audio/WebRTC system. Let me compile my findings:\n\n## Comprehensive Exploration of Voice Chat/WebRTC/Mediasoup Client Implementation\n\nBased on my thorough exploration of the client-side voice chat implementation in `/home/guibibi/projects/yankcord/client`, here's a detailed analysis:\n\n---\n\n## **1. ARCHITECTURE OVERVIEW**\n\nThe voice chat system uses **mediasoup-client** as the WebRTC library with an **SFU (Selective Forwarding Unit)** routing mode. It's a comprehensive implementation with client-side state management, audio/video processing, and native screen capture support via Tauri.\n\n---\n\n## **2. KEY COMPONENTS & FILES**\n\n### **2.1 State Management & Store** \n\n**File: `/home/guibibi/projects/yankcord/client/src/stores/voice.ts` (413 lines)**\n\n**Purpose:** Solid.js signal-based reactive state store for all voice-related state\n\n**Key Signals:**\n- `joinedVoiceChannelId` - Currently joined voice channel\n- `participantsByChannel` - Track which users are in each channel\n- `speakingByChannel` - Track speaking status per channel/user\n- `voiceActionState` - \"idle\", \"joining\", \"leaving\" state machine\n- `micMuted`, `speakerMuted` - Mute states\n- `cameraEnabled`, `screenShareEnabled` - Media activation states\n- `transportHealth` - Connection health state\n- `videoTiles` - Array of remote video streams\n\n**Key Functions:**\n- `applyVoiceSnapshot()` - Initialize voice presence\n- `applyVoiceJoined/Left/Speaking()` - Update participant state\n- `startVideoTilesSubscription()` / `startConnectionStatusSubscription()` - Subscribe to media state\n- `resetVoiceState()` - Clean slate when disconnecting\n- Health monitoring via `voiceHealthLevel()` that aggregates WebSocket and transport health\n\n**Issues Identified:**\n- No automatic cleanup on component unmount for subscriptions in some cases\n- Multiple unsubscribe refs that could leak if not properly managed\n\n---\n\n### **2.2 Media State Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/state.ts` (144 lines)**\n\n**Purpose:** Module-level state (not reactive) for mediasoup infrastructure\n\n**State Categories:**\n\n1. **Device & Transport**\n   - `device: Device | null` - mediasoup Device instance\n   - `sendTransport, recvTransport: Transport | null` - WebRTC transports\n\n2. **Producer State**\n   - `micProducer, micStream, micTrack` - Microphone\n   - `cameraProducer, cameraStream, cameraTrack` - Camera\n   - `screenProducer, screenStream, screenTrack` - Screen share\n   - `nativeScreenProducerId` - Tauri-native screen capture ID\n\n3. **Consumer State**\n   - `remoteConsumers: Map<string, Consumer>` - Audio/video consumers\n   - `consumerIdByProducerId: Map<string, string>` - Lookup table\n\n4. **Audio Processing**\n   - `micLevelAudioContext, micLevelAnalyserNode, micLevelData` - For voice activity detection\n   - `remotePlaybackAudioContext` - Shared context for remote audio\n\n5. **Volume Control**\n   - `consumerGainNodes, consumerNormalizationNodes` - Per-user volume/compression\n   - `remoteAudioElements: Map<string, HTMLAudioElement>` - Audio playback elements\n\n6. **Metadata**\n   - `producerUsernameById, producerSourceById, producerRoutingModeById` - Track producer metadata\n   - `queuedProducerAnnouncements` - Queue producers until initialized\n\n7. **Health Monitoring**\n   - `transportHealthState` - ICE connection state\n   - `signalListenerInitialized` - Track media signal setup\n\n---\n\n### **2.3 Transport Initialization & Lifecycle**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts` (376 lines)**\n\n**Purpose:** WebRTC transport setup, connection monitoring, and cleanup\n\n**Key Functions:**\n\n1. **`initializeMediaTransports(channelId: string)`** (Line 246-341)\n   - Idempotent initialization with promise-based deduplication\n   - Requests RTP capabilities from server\n   - Creates mediasoup Device and Send/Recv transports\n   - Wires up event handlers (connect, produce, ICE monitoring)\n   - Starts local audio producer immediately\n   - Flushes queued producer announcements\n   - **Pattern: Robust re-entrant guard against multiple concurrent initializations**\n\n2. **`closeTransports()`** (Line 163-244)\n   - Comprehensive cleanup of all resources\n   - Stops all producers (mic, camera, screen) and their tracks\n   - Closes all consumers\n   - Cleans up device change listener\n   - Stops voice activity monitoring\n   - Disposes microphone processing pipeline\n   - **Pattern: Defensive cleanup - removes resources even if already null**\n\n3. **Transport Health Monitoring** (Line 76-83, 101-132)\n   - `updateTransportHealthFromIce()` - Aggregates send/recv transport states\n   - Disconnect recovery with 10-second timeout (Line 119-123)\n   - Notifies all subscribers on state change\n   - States: \"connected\", \"new\", \"closed\", \"disconnected\", \"failed\"\n   - Severity mapping for worst-state calculation\n\n4. **Event Handlers**\n   - `wireTransportConnect()` - DTLS parameter exchange\n   - `wireSendTransportProduce()` - Producer creation signaling\n   - `wireTransportConnectionStateMonitor()` - ICE monitoring with auto-recovery\n\n5. **Mute Functions**\n   - `setMicrophoneMuted(muted)` - Disables track + reports voice activity\n   - `setSpeakersMuted(muted)` - Mutes all remote audio elements\n\n**Issues Identified:**\n- No retry logic if initial transport creation fails\n- Single global `disconnectRecoveryTimer` could theoretically be overwritten\n- Transport state machine could have edge cases with rapid join/leave\n- Audio context resumption error handling is silent (no logs)\n\n---\n\n### **2.4 Producer Management (Sending Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts` (737 lines)**\n\n**Purpose:** Manage outgoing audio, camera, and screen share streams\n\n**Key Producers:**\n\n1. **Microphone Producer** - `startLocalAudioProducer()` (Line 143-223)\n   - Gets user media with constraints (noise suppression, echo cancellation)\n   - Creates processed microphone track via `createProcessedMicrophoneTrack()`\n   - Wraps track in mediasoup Producer\n   - Starts voice activity monitoring\n   - Handles channel switch during startup\n   - **Pattern: Careful track ownership - uses `stopTracks: false` to manage lifecycle separately**\n\n2. **Camera Producer** - `startLocalCameraProducer()` (Line 237-315)\n   - Gets video constraints via `cameraInputConstraint()`\n   - Fallback logic for device availability\n   - H.264 codec preference\n   - Produces with `stopTracks: false`\n   - Error normalization for user display\n\n3. **Screen Share - Two Modes:**\n   - **Browser Mode** - `startBrowserScreenProducer()` (Line 380-490)\n     - Uses `getDisplayMedia()` API\n     - Optional constraint application (resolution, FPS)\n     - Content hint for encoder optimization (motion vs detail)\n     - Codec preference for platform\n     - Bitrate configuration with encoder hints\n   \n   - **Native Tauri Mode** - `startNativeScreenProducer()` (Line 492-643)\n     - Only on Tauri runtime with sourceId selected\n     - Uses RTP sender backend (not WebRTC producer)\n     - H.264 codec only (for compatibility)\n     - Extensive codec negotiation & validation\n     - Fallback monitor (polling every 1s for encoder failures)\n     - Diagnostics reporting to server\n     - **Pattern: Graceful fallback with heartbeat monitoring**\n\n4. **Track Lifecycle**\n   - Cleanup functions: `stopAndReleaseCameraTracks()`, `stopAndReleaseScreenTracks()`\n   - Producer close events trigger automatic cleanup\n   - Track ended events trigger producer closure\n   - Channel switch guards to prevent orphaned producers\n\n5. **Microphone Processing Pipeline**\n   - Volume gain node (for outgoing volume control)\n   - Creates processed track from source\n   - Mute state applied to both source and processed tracks\n\n**Issues Identified:**\n- No timeout for producer creation (could hang if network fails)\n- Screen share codec selection logs to console in debug mode - could be verbose\n- Native capture fallback flag is per-session; user can't retry browser mode once native attempted\n- Multiple try-catch blocks could benefit from unified error logging\n- Producer stats logging `logScreenShareProducerStats()` only logs on screen share start, not continuous\n\n---\n\n### **2.5 Consumer Management (Receiving Audio/Video)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts` (382 lines)**\n\n**Purpose:** Create and manage consuming remote audio/video streams\n\n**Key Functions:**\n\n1. **`consumeRemoteProducer(channelId, producerId)`** (Line 166-295)\n   - Requests consumer from server\n   - Creates consumer via `recvTransport.consume()`\n   - **Audio Path:**\n     - Creates HTMLAudioElement\n     - Sets up audio processing chain: SourceNode → NormalizationCompressor → GainNode → Destination\n     - Applies per-user volume + global incoming volume\n     - Resumes consumer before playback\n     - Retry logic for `audio.play()` (500ms delay + second attempt)\n   - **Video Path:**\n     - Creates RemoteVideoTile entry\n     - Resumes consumer\n     - Queues for tile updates\n   - Event handlers for transport close and track ended\n\n2. **Audio Chain Architecture** (Line 225-244)\n   ```\n   SourceNode (raw consumer track)\n   → NormalizationNode (DynamicsCompressor)\n   → GainNode (per-user volume)\n   → Destination (playback)\n   ```\n   - Normalization threshold: -24dB, knee: 20dB, ratio: 3, attack: 3ms, release: 250ms\n   - Provides consistent volume across speakers\n   - Disabled when `voiceAutoLevelEnabled` is false\n\n3. **Volume Management**\n   - `updateUserGainNodes()` - Updates specific user's volume\n   - `updateIncomingVoiceGainNodes()` - Updates global incoming volume\n   - `updateVoiceNormalizationNodesEnabled()` - Toggle auto-leveling\n   - Per-user volume from settings store\n\n4. **Producer Queuing** - `queueOrConsumeProducer()` (Line 321-353)\n   - If not initialized yet, queues producer announcement\n   - On initialization complete, `flushQueuedProducerAnnouncements()` processes queue\n\n5. **Cleanup** - `disposeRemoteConsumer(consumerId)` (Line 120-164)\n   - Closes consumer\n   - Disconnects all audio nodes\n   - Removes audio element from DOM\n   - Cleans up metadata maps\n   - Possibly closes shared audio context if last consumer\n\n**Issues Identified:**\n- Audio play() retry uses hardcoded 500ms delay - no exponential backoff\n- No per-consumer timeout for requestMediaSignal - could hang indefinitely\n- Consumer track ended detection doesn't distinguish between normal end and network failure\n- NormalizationNode configuration recreated per consumer instead of module-level constant\n- No logging for consumer creation failures - silent error handling\n- Gain node value clamping (0-200%) happens in multiple places - duplication\n\n---\n\n### **2.6 Voice Activity Detection & Speaking Status**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts` (111 lines)**\n\n**Purpose:** Monitor microphone level and report speaking status\n\n**Key Metrics:**\n- FFT size: 512\n- Smoothing time constant: 0.85\n- RMS threshold: 0.04 (4%)\n- Speaking hold duration: 220ms (hold-over to avoid jitter)\n\n**Algorithm:**\n1. Analyser node performs FFT on incoming audio\n2. Calculates RMS (root mean square) of audio samples\n3. If RMS >= threshold AND not muted → set hold-until time\n4. Current time <= hold-until → report speaking=true\n5. Muting immediately reports speaking=false\n\n**Functions:**\n- `startMicLevelMonitoring()` - Creates audio context and starts RAF-based monitor loop\n- `stopMicLevelMonitoring()` - Cleanup and final speaking=false report\n\n**Issues Identified:**\n- Uses `requestAnimationFrame` for 60fps monitoring - unnecessary overhead\n- Should use fixed interval (e.g., 50ms) instead\n- `micSpeakingLastSent` is a boolean flag, not a full state - can't distinguish between not-yet-sent and sent-false\n- No jitter buffer - could spam speaking state changes\n\n---\n\n### **2.7 Microphone Processing Pipeline**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts` (104 lines)**\n\n**Purpose:** Apply outgoing volume control to microphone track\n\n**Architecture:**\n```\nUserMedia Stream\n  → SourceNode\n    → GainNode (volume)\n      → DestinationNode (processed track)\n```\n\n**Lifecycle:**\n- Single active session at a time\n- `createProcessedMicrophoneTrack()` - Creates new session with gain node\n- `activateMicrophoneProcessing()` - Sets session as active (disposes previous)\n- `updateOutgoingMicrophoneGain()` - Changes gain value in active session\n- `updateOutgoingMicrophoneMuted()` - Sets track.enabled on both source and processed\n\n**Issues Identified:**\n- Keeps original sourceTrack around - consumes extra resources\n- No cleanup callback - if active session set but never disposed, resources leak\n- Gain clamping function duplicated from consumers.ts\n- No validation that sourceTrack is still valid before using it\n\n---\n\n### **2.8 Media Signaling (WebSocket Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts` (178 lines)**\n\n**Purpose:** Request-response protocol for media operations (RTC negotiation, producer/consumer management)\n\n**Signal Actions:**\n- `get_router_rtp_capabilities` - Get server's codec capabilities\n- `create_webrtc_transport` - Create send/recv transport\n- `connect_webrtc_transport` - Exchange DTLS parameters\n- `media_produce` - Create producer\n- `media_close_producer` - Close producer\n- `media_consume` - Create consumer\n- `media_resume_consumer` - Resume consumer playback\n- `create_native_sender_session` - RTP sender setup (native capture)\n- `client_diagnostic` - Report native sender metrics\n\n**Request-Response Pattern:**\n- Each request gets unique ID: `media-${Date.now()}-${counter}`\n- 10-second timeout (Line 113-116)\n- Response matched to request by ID\n- Pending requests tracked in Map\n- Server can send unsolicited messages (new_producer, producer_closed, voice_activity)\n\n**Voice Activity Reporting:**\n- `reportVoiceActivity()` - Send speaking=true/false to server\n- Triggered by voice level monitoring\n\n**Diagnostics:**\n- `reportCodecDecision()` - Log codec selection decision\n- `reportNativeSenderDiagnostic()` - Report native sender status/errors\n\n**Issues Identified:**\n- Fixed 10-second timeout for all operations - some might need longer (network dependent)\n- No retry logic - first timeout = failure\n- PendingRequests could accumulate if responses never arrive (timeout cleanup exists, but requests are still lost)\n- No congestion detection - if many requests fail, no backpressure\n\n---\n\n### **2.9 Subscription System**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts` (122 lines)**\n\n**Purpose:** Publisher-subscriber pattern for media state changes\n\n**Subscribers:**\n1. `videoTilesSubscribers` - Remote camera/screen tiles\n2. `cameraStateSubscribers` - Local camera enabled/error/stream\n3. `screenStateSubscribers` - Local screen share enabled/error/stream/routingMode\n4. `transportHealthSubscribers` - Connection health state\n\n**Pattern:**\n- Each subscription function calls subscriber immediately with current state\n- Returns unsubscribe function\n- Used by `voice.ts` store to maintain reactive state\n\n**Issues Identified:**\n- No limits on subscriber count - potential memory leak if many subscriptions created\n- No deduplication - could call subscriber twice if subscribed twice\n- Subscribers called synchronously - blocking if callback is slow\n\n---\n\n### **2.10 Device Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts** (150+ lines)**\n\n**Purpose:** Enumerate and switch audio/video devices at runtime\n\n**Device Enumeration:**\n- `listAudioDevices()` - List microphones & speakers\n- `listCameraDevices()` - List cameras\n- Labels sorted alphabetically with fallback numbering\n\n**Device Selection:**\n- `setPreferredMicrophoneDevice()` - Hot-swap microphone\n  - Gets new user media\n  - Creates new processing session\n  - Replaces producer track if exists, or creates new producer\n  - Manages fallback if device unavailable\n  \n- `setPreferredCameraDevice()` - Hot-swap camera (partial implementation visible)\n- `setPreferredSpeakerDevice()` - Route speaker output\n  - Uses `HTMLAudioElement.setSinkId()` if supported\n  - Applied to all remote audio elements\n\n**Device Change Detection:**\n- `registerDeviceChangeListener()` - Fires when devices added/removed\n- Resets audio devices if current device disappears\n- Prevents duplicate registrations\n\n**Issues Identified:**\n- Device change listener doesn't distinguish between input/output changes\n- Hot-swap has no fallback if getRtpCapabilities changes (rare but possible)\n- Speaker routing set per-element, not globally - new consumers must be manually routed\n- Sorting is expensive on every enumeration - could cache\n\n---\n\n### **2.11 Constraints & Codec Management**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts` (97 lines)**\n\n**Audio Constraints:**\n```typescript\n{\n  deviceId: { exact: selectedDeviceId },\n  noiseSuppression: voiceNoiseSuppressionEnabled(),\n  echoCancellation: voiceEchoCancellationEnabled(),\n  channelCount: 1  // Mono\n}\n```\n- Uses browser supported constraints API\n- Graceful degradation if constraints unavailable\n\n**Video Constraints (Camera):**\n- Simple exact device ID constraint\n\n**Screen Share Constraints:**\n- Resolution: 720p (1280×720), 1080p (1920×1080), 1440p (2560×1440), 4k (3840×2160)\n- FPS: 30 or 60\n- displaySurface hint: \"monitor\" or \"window\"\n- contentHint: \"motion\" (>=60fps or app) or \"detail\"\n\n**Codec Selection:**\n- Screen share: H.264 > VP8 > VP9 (platform-independent, NVENC hardware support)\n- Native: H.264 only\n\n**Issues Identified:**\n- No support for audio bandwidth constraints\n- Screen share 4K resolution could be very expensive\n- No validation that requested FPS/resolution is supported before attempting\n\n---\n\n### **2.12 Error Handling**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts` (72 lines)**\n\n**Error Normalization:**\n\n1. **Camera Errors:**\n   - Permission denied → \"Camera access was denied...\"\n   - Not found → \"No camera device was found...\"\n   - Not readable/in use → \"Camera is unavailable or in use...\"\n   - Generic → Pass through error message\n\n2. **Screen Share Errors:**\n   - Permission denied → \"Screen share permission was denied...\"\n   - Not found → \"No shareable display source was found...\"\n   - Not readable → \"Screen sharing is unavailable or already in use...\"\n   - Generic → Pass through error message\n\n3. **Device Detection:**\n   - `isMissingDeviceError()` - Check if error is device-not-found\n\n**Issues Identified:**\n- Error messages are user-friendly but not actionable\n- No error codes - difficult to log/debug\n- Generic DOMException handling is catch-all at end\n\n---\n\n### **2.13 Native Screen Capture (Tauri)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/api/media/native.ts` (88 lines)**\n\n**Purpose:** Wrap Tauri native screen capture APIs\n\n**Functions:**\n- `listNativeCaptureSources()` - Enumerate windows/screens/apps\n- `nativeCodecCapabilities()` - Check available codecs\n- `startNativeCapture()` - Arm native capture service\n- `stopNativeCapture()` - Disarm service\n- `nativeCaptureStatus()` - Poll for live metrics\n\n**Fallback Monitor:**\n- Polling every 1s for encoder failures\n- Fallback reasons: \"degradation\", \"encoder_failure\", etc.\n- Auto-stops if fallback reason appears\n- Reports diagnostic event to server\n\n**Backend Selection:**\n- Reads encoder_backend (NVENC, OpenH264)\n- Tries requested backend, falls back to other\n- Extensive diagnostics in `NativeCaptureStatus`\n\n**Issues Identified:**\n- Hardcoded 1s poll interval - could miss rapid failures\n- Codec mime type validation string-matching (should use enum)\n- No timeout if native capture hangs\n\n---\n\n## **3. UI COMPONENTS**\n\n### **3.1 Voice Dock Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx` (131 lines)**\n\n**Purpose:** Main control panel for voice channel operations\n\n**Controls:**\n- Disconnect button\n- Mic mute toggle\n- Speaker mute toggle  \n- Camera enable/disable\n- Screen share enable/disable\n\n**Status Display:**\n- Connected channel name\n- Connection health (good/degraded/failed)\n- Health dot indicator + label\n- Camera/screen share error messages\n- Routing mode (SFU)\n\n**Native Debug Panel** (Tauri only, debug mode):\n- Frame queue stats\n- Encoder output rate\n- RTP packet counts\n- Queue backlog & drop counts\n- Encode latency\n- Codec info\n- Transport/producer health\n- Pressure metrics\n- Encoder backend info\n\n**Issues Identified:**\n- No tooltip for health states\n- Debug panel is text-heavy and cramped\n- Retry connection button shown but doesn't explain what will reconnect\n\n---\n\n### **3.2 Video Stage Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx` (78 lines)**\n\n**Purpose:** Display grid of video tiles (camera + screen share)\n\n**Layout:**\n- Local camera (if enabled) in grid\n- Local screen share (if enabled) in grid\n- Remote camera tiles (from videoTiles subscription)\n\n**Features:**\n- Auto-play video elements\n- Muted local streams\n- Username + source labels\n- CSS classes for styling (is-local, is-screen-share)\n\n**Issues Identified:**\n- No pagination/max tile limit (could become unwieldy with many participants)\n- No speaker highlight indicator\n- Order is arbitrary for remote tiles (relies on alphabetical sort in subscriptions.ts)\n- No click-to-focus or fullscreen\n\n---\n\n### **3.3 Voice Settings Component**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx` (110 lines)**\n\n**Purpose:** User-facing voice settings\n\n**Toggles:**\n- Noise suppression\n- Echo cancellation\n- Auto level incoming voices\n\n**Sliders:**\n- Incoming voice volume (0-200%)\n- Outgoing microphone volume (0-200%)\n\n**Issues Identified:**\n- No input validation (could receive invalid percentages)\n- Help text is generic, no device-specific guidance\n- Volume slider goes to 200% - could cause distortion\n\n---\n\n## **4. INTEGRATION WITH MAIN APPLICATION**\n\n### **4.1 ChannelList Component (Voice Integration)**\n\n**File: `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (1200+ lines)**\n\n**Key Voice Operations:**\n\n1. **Join Voice** - `joinVoiceChannel()`\n   - Sets state to \"joining\"\n   - Sends WebSocket message\n\n2. **Leave Voice** - `leaveVoiceChannel()`\n   - Sets state to \"leaving\"\n   - Sends WebSocket message\n\n3. **Toggle Mic** - `handleToggleMicMuted()`\n   - Updates mute state\n   - Calls `setMicrophoneMuted()`\n\n4. **Toggle Camera** - `handleToggleCamera()`\n   - Idempotent with pending state\n   - Calls `startLocalCameraProducer()` or `stopLocalCameraProducer()`\n   - Shows error toast on failure\n\n5. **Toggle Screen Share** - `handleToggleScreenShare()`\n   - Browser mode: Immediate `startLocalScreenProducer()`\n   - Tauri mode: Opens modal to select source, then starts\n   - Calls `stopLocalScreenProducer()` if already sharing\n\n6. **Voice Presence Events**\n   - `voice_joined` → Initialize transports, restore settings\n   - `voice_left` → Cleanup, reset state\n   - `voice_user_joined` → Play join cue, update participants\n   - `voice_user_left` → Play leave cue, update participants\n   - `voice_user_speaking` → Update speaking indicator\n   - `voice_presence_snapshot` → Initialize on startup\n\n7. **Error Handling**\n   - Error type message → Set action state to idle\n   - Network close → Show rejoin notice + cleanup\n\n8. **Cleanup on Unmount**\n   - Stop subscriptions\n   - Remove event listeners\n   - Clear timers\n   - Stop screen share preview\n\n**Issues Identified:**\n- Error message shown in toast but error details lost\n- No user confirmation for destructive actions (e.g., leaving voice)\n- Native metrics polling (1s interval) runs constantly when screen sharing - could drain battery\n\n---\n\n## **5. STATE FLOW DIAGRAM**\n\n```\nWebSocket Message (voice_joined)\n  ↓\nsetJoinedVoiceChannel(id)\n  ↓\ninitializeMediaTransports(id)\n  ├─ Request RTP capabilities\n  ├─ Load Device with capabilities\n  ├─ Create Send/Recv transports\n  ├─ Wire transport events\n  └─ startLocalAudioProducer()\n      ├─ getUserMedia() with constraints\n      ├─ createProcessedMicrophoneTrack() (gain node)\n      ├─ sendTransport.produce()\n      └─ startMicLevelMonitoring()\n        └─ RAF loop → Calculate RMS → reportVoiceActivity()\n  ├─ registerDeviceChangeListener()\n  └─ flushQueuedProducerAnnouncements()\n      └─ consumeRemoteProducer() for each queued\n\nOn new_producer signal\n  ├─ Record username, source, routingMode\n  └─ queueOrConsumeProducer() → consumeRemoteProducer()\n      ├─ Request consumer from server\n      ├─ Create consumer via recvTransport\n      ├─ If audio: Set up playback chain\n      │   ├─ Create HTMLAudioElement\n      │   ├─ SourceNode → NormalizationCompressor → GainNode → Destination\n      │   └─ audio.play()\n      └─ If video: Create VideoTile + subscribe UI\n\nWebSocket Message (voice_left)\n  ↓\ncleanupMediaTransports()\n  ├─ closeTransports()\n  │   ├─ Dispose all producers & tracks\n  │   ├─ Close all consumers\n  │   ├─ Dispose audio nodes & elements\n  │   └─ Close transports & device\n  └─ Reset all state signals\n```\n\n---\n\n## **6. DETAILED ISSUES & RECOMMENDATIONS**\n\n### **Critical Issues**\n\n1. **No Timeout on Transport Creation**\n   - **Location:** `initializeMediaTransports()` line 279\n   - **Issue:** If server hangs responding to capabilities request, initialization blocks indefinitely\n   - **Fix:** Add 5-second timeout to `requestMediaSignal()` calls in transport init\n\n2. **Silent Audio Play Failure Retry**\n   - **Location:** `consumers.ts` line 247-265\n   - **Issue:** If `audio.play()` fails twice, error is logged but not propagated\n   - **Impact:** User hears silence but no error toast\n   - **Fix:** Throw error after second failure, let caller handle\n\n3. **Microphone Processing Resource Leak**\n   - **Location:** `microphoneProcessing.ts`\n   - **Issue:** If `activateMicrophoneProcessing()` is called without prior cleanup, old session orphaned\n   - **Fix:** Explicit dispose call or use WeakMap for auto-cleanup\n\n4. **Voice Activity Detection Too Sensitive**\n   - **Location:** `voiceActivity.ts` line 77-78\n   - **Issue:** 220ms hold-over can miss natural speech pauses\n   - **Recommendation:** Use 300-400ms, or make configurable\n\n### **High Priority Issues**\n\n5. **Screen Share Fallback Stuck**\n   - **Location:** `producers.ts` line 680-685\n   - **Issue:** Once `nativeCaptureAttempted` set true, user can't retry browser mode\n   - **Fix:** Add UI button to reset flag, or prompt user\n\n6. **Transport Health Monitoring Race Condition**\n   - **Location:** `transports.ts` line 106-112\n   - **Issue:** Multiple transports closing in parallel could set state to wrong value\n   - **Fix:** Use sequence number or lock to ensure ordering\n\n7. **No Reconnection Logic**\n   - **Issue:** If WebSocket reconnects, media transports not re-established\n   - **Fix:** Add auto-reconnect on WS reconnect (currently relies on user clicking Retry)\n\n### **Medium Priority Issues**\n\n8. **Volume Clamping Duplicated**\n   - **Locations:** `consumers.ts` line 39-44, `microphoneProcessing.ts` line 10-15\n   - **Fix:** Export single function from utils module\n\n9. **Consumer Creation Timeout**\n   - **Location:** `consumers.ts` line 184\n   - **Issue:** No timeout on `requestMediaSignal(\"media_consume\")`\n   - **Fix:** Add shorter timeout (3-5s) for per-consumer requests\n\n10. **Device Change Listener Not De-Registered**\n    - **Location:** `transports.ts` line 168\n    - **Issue:** Listener registered in `initializeMediaTransports`, de-registered on close, but no guard\n    - **Fix:** Add state guard to prevent double de-registration\n\n### **Code Quality Issues**\n\n11. **Error Handling Inconsistency**\n    - Some code uses `console.warn`, some uses `console.error`, some uses throw\n    - **Fix:** Standardize on error boundary propagation\n\n12. **Missing JSDoc Comments**\n    - Complex functions like `consumeRemoteProducer` lack documentation\n    - **Fix:** Add JSDoc for public APIs\n\n13. **Magic Numbers**\n    - 10000ms timeout, 220ms hold, 512 FFT size, 0.04 threshold not documented\n    - **Fix:** Extract to named constants with comments\n\n---\n\n## **7. PERFORMANCE CONSIDERATIONS**\n\n1. **Audio Context Lifecycle**\n   - Creates multiple AudioContexts (mic level, remote playback, mic processing)\n   - Browser limits ~10 contexts max - current design uses 3 when at capacity\n   - **Safe but could be optimized:** Reuse single context for monitoring\n\n2. **Voice Activity Detection RAF Loop**\n   - Runs at 60fps (browser refresh rate)\n   - **Issue:** Overkill for voice activity (could be 20fps)\n   - **Fix:** Use 50ms setInterval instead\n\n3. **Storage of All Remote Audio Elements**\n   - `remoteAudioElements` map keeps reference to all audio elements\n   - **Potential issue:** Never cleaned from DOM, only disconnected\n   - **Fix:** Use WeakMap or actively remove elements\n\n4. **Native Sender Metrics Polling**\n   - 1-second interval polling from Rust backend\n   - **Cost:** Continuous IPC calls\n   - **Optimization:** Debounce to 2-3 seconds or on-demand\n\n---\n\n## **8. SECURITY CONSIDERATIONS**\n\n1. **Producer/Consumer Metadata**\n   - Username stored client-side in `producerUsernameById` Map\n   - **Risk:** Could be spoofed if network message forged\n   - **Mitigation:** Server validates all signaling messages\n\n2. **Codec Negotiation**\n   - Accepts codec from server without validation\n   - **Mitigation:** Limited set of supported codecs in device.rtpCapabilities\n\n3. **SinkId Device Selection**\n   - `setSinkId` could fail silently\n   - **Risk:** Audio routed to unexpected output\n   - **Mitigation:** Device selection is user-initiated\n\n---\n\n## **9. SUMMARY TABLE**\n\n| Component | Purpose | Lines | Key Pattern | Risk Level |\n|-----------|---------|-------|-------------|-----------|\n| voice.ts | Reactive state store | 413 | Solid.js signals | Low |\n| state.ts | Module-level state | 144 | Module exports | Low |\n| transports.ts | RTC setup/lifecycle | 376 | Idempotent init + cleanup | Medium |\n| producers.ts | Outgoing media | 737 | Track ownership mgmt | High |\n| consumers.ts | Incoming media | 382 | Audio processing chain | High |\n| voiceActivity.ts | Speaking detection | 111 | RAF-based monitoring | Medium |\n| microphoneProcessing.ts | Outgoing volume | 104 | Single active session | Medium |\n| signaling.ts | WebSocket protocol | 178 | Request-response | Medium |\n| subscriptions.ts | Publisher-subscriber | 122 | Observer pattern | Low |\n| devices.ts | Audio/video devices | 150+ | Hot-swap at runtime | High |\n| constraints.ts | Media constraints | 97 | Constraint generation | Low |\n| errors.ts | Error normalization | 72 | Error mapping | Low |\n| native.ts | Tauri integration | 88 | API wrapper | Medium |\n| VoiceDock.tsx | Control UI | 131 | Component | Low |\n| VideoStage.tsx | Video grid | 78 | Component | Low |\n| VoiceAudioPreferences.tsx | Settings UI | 110 | Component | Low |\n| ChannelList.tsx | Main integration | 1200+ | Orchestration | High |\n\n---\n\n## **10. FILE PATHS (ABSOLUTE)**\n\nAll voice-related files are located at:\n\n- `/home/guibibi/projects/yankcord/client/src/stores/voice.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/index.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/types.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/state.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/transports.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/producers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/consumers.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/signaling.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/subscriptions.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/voiceActivity.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/microphoneProcessing.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/devices.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/constraints.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/codecs.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/errors.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media/native.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/media.ts` (re-export wrapper)\n- `/home/guibibi/projects/yankcord/client/src/api/nativeCapture.ts` (Tauri bindings)\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/VoiceDock.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/VideoStage.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/settings/VoiceAudioPreferences.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/channel-list/ScreenShareModal.tsx`\n- `/home/guibibi/projects/yankcord/client/src/components/ChannelList.tsx` (integration)\n- `/home/guibibi/projects/yankcord/client/src/utils/voiceCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/utils/audioCue.ts`\n- `/home/guibibi/projects/yankcord/client/src/api/ws.ts` (WebSocket definitions)\n\nNative Tauri implementation:\n- `/home/guibibi/projects/yankcord/client/src-tauri/src/` (Rust backend for native capture)\n\nThis concludes the comprehensive exploration of the voice chat system on the client side.</result>\n<usage><total_tokens>95540</total_tokens><tool_uses>41</tool_uses><duration_ms>162087</duration_ms></usage>\n</task-notification>\nFull transcript available at: REDACTED.output"},"uuid":"2a88236d-9584-4b53-9c7d-fcff03e57dc3","timestamp":"2026-02-23T15:20:33.402Z","permissionMode":"default"}
{"parentUuid":"2a88236d-9584-4b53-9c7d-fcff03e57dc3","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_013YTqNHDcNYYJwXNRFoyiGm","type":"message","role":"assistant","content":[{"type":"text","text":"All agents have finished. The full report is at **`VOICE-CHAT-REVIEW.md`** in the project root — it covers all findings from client, server, and Tauri."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":9739,"cache_read_input_tokens":57330,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":9739},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRE8TuPTio6GQx4rWTcz","type":"assistant","uuid":"8984ddc6-db67-4674-9485-1c38f77aee57","timestamp":"2026-02-23T15:20:40.262Z"}
{"parentUuid":"8984ddc6-db67-4674-9485-1c38f77aee57","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"91fe466b-7db0-4186-af6e-44bdc00c25e6","toolUseID":"91fe466b-7db0-4186-af6e-44bdc00c25e6","timestamp":"2026-02-23T15:20:40.329Z","uuid":"bfe44471-e4e1-4fde-a8be-6bf1112f2a19"}
{"type":"queue-operation","operation":"dequeue","timestamp":"2026-02-23T15:20:49.387Z","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c"}
{"parentUuid":"bfe44471-e4e1-4fde-a8be-6bf1112f2a19","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1763}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-23T15:20:42.093Z","uuid":"d952f061-e982-49d9-8cd4-336ab38dc66e","toolUseID":"91fe466b-7db0-4186-af6e-44bdc00c25e6"}
{"parentUuid":"d952f061-e982-49d9-8cd4-336ab38dc66e","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"user","message":{"role":"user","content":"<task-notification>\n<task-id>af8b6d8</task-id>\n<tool-use-id>toolu_01JiBfoph47qJdUduVVbVC9r</tool-use-id>\n<status>completed</status>\n<summary>Agent \"Explore Tauri voice integration\" completed</summary>\n<result>Perfect! Now I have all the information I need. Let me compile my comprehensive findings:\n\n## Comprehensive Exploration: Tauri Desktop Client Voice Chat Module\n\n### Executive Summary\n\nThe Yankcord application uses **WebRTC via mediasoup-client** for voice communication, with **both web and Tauri clients sharing the same audio/voice logic**. The Tauri desktop client does NOT have separate audio handling - instead, it provides **native screen capture for video streaming** while delegating all voice/audio functionality to browser WebRTC APIs through the Chromium-based Tauri webview.\n\n---\n\n### 1. Tauri Backend (Rust) - /home/guibibi/projects/yankcord/client/src-tauri/\n\n#### Structure:\n- **Main entry point**: `/home/guibibi/projects/yankcord/client/src-tauri/src/main.rs` - Minimal Tauri bootstrap\n- **Core logic**: `/home/guibibi/projects/yankcord/client/src-tauri/src/lib.rs`\n\n#### Key Files:\n\n**lib.rs**:\n```rust\npub fn run() {\n    tauri::Builder::default()\n        .manage(capture::service::NativeCaptureService::default())\n        .plugin(tauri_plugin_opener::init())\n        .plugin(tauri_plugin_notification::init())\n        .plugin(tauri_plugin_updater::Builder::new().build())\n        .invoke_handler(tauri::generate_handler![\n            capture::service::list_native_capture_sources,\n            capture::service::native_codec_capabilities,\n            capture::service::start_native_capture,\n            capture::service::stop_native_capture,\n            capture::service::native_capture_status\n        ])\n```\n\n**Tauri Commands Exposed**:\n1. `list_native_capture_sources` - Lists available screens/windows/applications to capture\n2. `native_codec_capabilities` - Reports available video codecs (H264, VP8, VP9, AV1)\n3. `start_native_capture` - Initiates native screen/window capture with specified codec, resolution, FPS, bitrate\n4. `stop_native_capture` - Stops active native capture\n5. `native_capture_status` - Returns detailed metrics on encoding, RTP transmission, performance\n\n**No Tauri Commands for Audio**: The Rust backend provides **zero audio-related Tauri commands**. All voice/audio functionality is handled entirely through browser WebRTC APIs.\n\n#### Dependencies:\n- `tauri = { version = \"2\", features = [] }`\n- `tauri-plugin-opener = \"2\"` - Open URLs/files\n- `tauri-plugin-notification = \"2\"` - Desktop notifications\n- `tauri-plugin-updater = \"2\"` - App auto-updates\n- **No audio libraries** (no cpal, rodio, dasp, etc.)\n\n#### Capabilities:\nFile: `/home/guibibi/projects/yankcord/client/src-tauri/capabilities/default.json`\n\n```json\n{\n  \"permissions\": [\n    \"core:default\",\n    \"core:window:allow-close\",\n    \"core:window:allow-minimize\",\n    \"core:window:allow-toggle-maximize\",\n    \"core:window:allow-start-dragging\",\n    \"opener:default\",\n    \"notification:default\",\n    \"updater:default\"\n  ]\n}\n```\n\n**No WebRTC or audio permissions defined** - Tauri delegates these to the webview's built-in browser permissions system.\n\n---\n\n### 2. Frontend WebRTC Voice Architecture - /home/guibibi/projects/yankcord/client/src/\n\n#### Core Voice Stack:\n- **MediaSoup Client** (`mediasoup-client@3.18.6`) - SFU WebRTC protocol\n- **Web Audio API** - For microphone monitoring and audio processing\n- **getUserMedia API** - For microphone and speaker device enumeration\n- **All audio handled through browser webview** - NO native Rust audio handling\n\n#### Voice-Related Files:\n\n**API Modules** (`/client/src/api/media/`):\n\n1. **nativeCapture.ts** - Tauri bridge for screen capture (NOT audio)\n   - Defines types: `NativeCaptureSource`, `StartNativeCaptureRequest`, `NativeCaptureStatus`\n   - Calls Tauri commands via `invoke()` from `@tauri-apps/api/core`\n   - Used for screen sharing only, not voice\n\n2. **voiceActivity.ts** - Microphone level monitoring and speaking detection\n   ```typescript\n   export function startMicLevelMonitoring(channelId: string, stream: MediaStream) {\n     const audioContext = new AudioContext();\n     const analyserNode = audioContext.createAnalyser();\n     analyserNode.fftSize = 512;\n     analyserNode.smoothingTimeConstant = 0.85;\n     \n     // Monitors RMS level, reports speaking activity via reportVoiceActivity()\n   }\n   ```\n   - Detects voice activity using RMS (root mean square) analysis\n   - Reports to server via WebSocket signaling\n   - **Platform agnostic** - same code for web and Tauri\n\n3. **microphoneProcessing.ts** - Audio gain/volume control\n   ```typescript\n   export function createProcessedMicrophoneTrack(\n     stream: MediaStream, \n     volume: number, \n     muted: boolean\n   ): MicrophoneProcessingSession\n   ```\n   - Creates AudioContext with GainNode for outgoing volume adjustment\n   - Applies muting/unmuting to source and processed tracks\n   - **Pure Web Audio API** - zero native code\n\n4. **devices.ts** - Microphone and speaker device management\n   ```typescript\n   export async function listAudioDevices(): Promise<AudioDeviceInventory> {\n     const devices = await navigator.mediaDevices.enumerateDevices();\n   }\n   \n   export async function setPreferredMicrophoneDevice(deviceId: string | null) {\n     const nextStream = await navigator.mediaDevices.getUserMedia({\n       audio: audioInputConstraint(deviceId)\n     });\n   }\n   ```\n   - Uses standard `navigator.mediaDevices` APIs\n   - Supports speaker selection via `audio.setSinkId()` when available\n   - **Zero Tauri-specific code**\n\n5. **constraints.ts** - MediaTrackConstraints builder\n   ```typescript\n   export function audioInputConstraint(deviceId: string | null): MediaTrackConstraints | boolean {\n     const constraints: MediaTrackConstraints = {};\n     const supportedConstraints = navigator.mediaDevices?.getSupportedConstraints?.();\n     \n     if (supportedConstraints?.noiseSuppression) {\n       constraints.noiseSuppression = voiceNoiseSuppressionEnabled();\n     }\n     if (supportedConstraints?.echoCancellation) {\n       constraints.echoCancellation = voiceEchoCancellationEnabled();\n     }\n   }\n   ```\n   - Applies noise suppression (via WebRTC's libwebrtc)\n   - Applies echo cancellation (via browser's built-in AEC)\n   - Channel count: mono (1 channel)\n\n6. **consumers.ts** - Remote audio playback (remote participants)\n   - Creates HTML audio elements for each remote participant\n   - Routes audio through Web Audio API for per-user volume control\n   - Uses DynamicsCompressorNode for \"auto level incoming voices\" feature\n   ```typescript\n   function configureNormalizationNode(node: DynamicsCompressorNode, enabled: boolean) {\n     if (enabled) {\n       node.threshold.value = -24;\n       node.knee.value = 20;\n       node.ratio.value = 3;\n       node.attack.value = 0.003;\n       node.release.value = 0.25;\n     }\n   }\n   ```\n\n7. **producers.ts** - Local audio/video producer setup\n   - Creates microphone producer via `sendTransport.produce()`\n   - Creates camera producer for video\n   - Creates screen share producer (uses native Tauri capture on desktop)\n\n8. **signaling.ts** - WebSocket protocol for media negotiation\n   - Reports voice activity to server\n   - Requests media signal for producer/consumer setup\n   - No direct audio signaling\n\n9. **transports.ts** - WebRTC transport (DTLS/ICE) initialization\n   - Handles DTLS parameter negotiation\n   - Monitors transport health\n   - Cleanup on disconnect\n\n10. **codecs.ts** - Codec selection\n    ```typescript\n    export function selectScreenShareCodecForPlatform(): ProduceCodec | undefined {\n      // Prefers H264 > VP8 > VP9\n      // Platform-aware but applies to screen share only\n    }\n    \n    export function nativePreferredCodecsFor(): string[] {\n      return [\"video/H264\"]; // For native Tauri screen capture\n    }\n    ```\n\n#### Voice Settings Storage:\nFile: `/client/src/stores/settings.ts`\n\n```typescript\nconst AUDIO_INPUT_KEY = \"yankcord_audio_input_device_id\";\nconst AUDIO_OUTPUT_KEY = \"yankcord_audio_output_device_id\";\nconst VOICE_AUTO_LEVEL_ENABLED_KEY = \"yankcord_voice_auto_level_enabled\";\nconst VOICE_NOISE_SUPPRESSION_ENABLED_KEY = \"yankcord_voice_noise_suppression_enabled\";\nconst VOICE_ECHO_CANCELLATION_ENABLED_KEY = \"yankcord_voice_echo_cancellation_enabled\";\nconst VOICE_INCOMING_VOLUME_KEY = \"yankcord_voice_incoming_volume\";\nconst VOICE_OUTGOING_VOLUME_KEY = \"yankcord_voice_outgoing_volume\";\n```\n\nAll settings stored in **localStorage** - same for web and Tauri.\n\n#### Voice State Management:\nFile: `/client/src/stores/voice.ts` - Tracks:\n- `joinedVoiceChannelId` - Current voice channel\n- `participantsByChannel` - Who's in each channel\n- `speakingByChannel` - Who's currently speaking\n- `voiceActionState` - \"idle\" | \"joining\" | \"leaving\"\n- `micMuted` - Local mute state\n- `speakerMuted` - Remote audio mute\n- `cameraEnabled`, `screenShareEnabled` - Video states\n- `transportHealth` - WebRTC connection quality\n- Video tile subscriptions for remote video streams\n\n#### Voice UI Components:\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice channel participant display\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings UI\n- Noise suppression, echo cancellation, volume controls (both incoming/outgoing)\n\n---\n\n### 3. Key Differences Between Web and Tauri Clients\n\n#### Audio/Voice:\n- **Web Client**: Uses browser WebRTC, browser's audio device enumeration\n- **Tauri Client**: **Identical** - Same WebRTC via Tauri's Chromium webview, browser audio device enumeration\n- **No difference** in how voices are captured, processed, or transmitted\n\n#### Screen Sharing:\n- **Web Client**: Uses `navigator.mediaDevices.getDisplayMedia()` (browser picker)\n- **Tauri Client**: Uses native Tauri commands for screen/window capture, can pass native source IDs, supports hardware-accelerated H264/NVENC encoding\n  - Fallback to browser capture if native fails\n  - Native capture is **video-only** (no audio)\n\n#### Platform Detection:\nFile: `/client/src/utils/platform.ts`\n\n```typescript\nexport function isTauriRuntime(): boolean {\n  return typeof window.__TAURI_INTERNALS__ !== \"undefined\";\n}\n```\n\nUsed to:\n1. Attempt native screen capture first on Tauri\n2. Check Windows platform for codec preferences\n3. Enable NVENC hardware encoding feature flags\n\n---\n\n### 4. Native Audio Handling - Summary\n\n**There is NO native audio handling in the Tauri client.**\n\nAudio flows:\n1. **Outgoing**: \n   - `navigator.mediaDevices.getUserMedia()` → microphone stream\n   - WebAudioAPI GainNode for volume adjustment\n   - Sent to server via WebRTC (mediasoup)\n\n2. **Incoming**:\n   - Received via WebRTC consumer\n   - Routed to HTML audio element\n   - Optional Web Audio API GainNode for per-user volume control\n   - Optional DynamicsCompressorNode for auto-normalization\n\n3. **Processing**:\n   - Noise suppression: Browser's WebRTC libwebrtc (constraint-based)\n   - Echo cancellation: Browser's WebRTC libwebrtc (constraint-based)\n   - Voice activity detection: Custom JavaScript using Web Audio API FFT analysis\n\n---\n\n### 5. Recent Voice Improvements\n\nRecent commit: **4cd8bfa** (\"feat: improve voice connectivity\")\n\nChanges include:\n- Improved transport health monitoring\n- Better consumer audio routing\n- Enhanced subscription system for media state\n- Per-user volume control via DynamicsCompressor normalization\n- Auto-level incoming voices feature\n\n**No Tauri-specific changes** - all improvements are browser-level WebRTC optimizations.\n\n---\n\n### 6. Tauri Configuration\n\nFile: `/client/src-tauri/tauri.conf.json`\n\n```json\n{\n  \"app\": {\n    \"windows\": [{\n      \"title\": \"Yankcord\",\n      \"decorations\": false,\n      \"width\": 1280,\n      \"height\": 800\n    }],\n    \"security\": {\n      \"csp\": \"default-src 'self'; connect-src 'self' https: http: wss: ws:; img-src 'self' data: blob: https: http:; style-src 'self' 'unsafe-inline'\"\n    }\n  }\n}\n```\n\n**CSP allows**:\n- WebSocket connections (wss: ws:) - for voice signaling\n- HTTPS/HTTP - for API calls\n- Blob resources - for media streams\n\n**No WebRTC-specific CSP rules** - Tauri's webview handles this internally.\n\n---\n\n### 7. Files Summary\n\n#### Tauri Rust Code (NO voice/audio):\n- `/client/src-tauri/src/main.rs` - Entry point (181 bytes)\n- `/client/src-tauri/src/lib.rs` - Tauri app setup, command handlers (764 bytes)\n- `/client/src-tauri/src/capture/` - Screen capture backend (video only)\n  - No audio dependencies or code\n\n#### Frontend Voice Code (Browser WebRTC):\n- `/client/src/api/media/` - 15 files, all platform-agnostic WebRTC/Web Audio\n- `/client/src/api/nativeCapture.ts` - Tauri bridge (screen capture only)\n- `/client/src/stores/voice.ts` - Voice state management\n- `/client/src/stores/settings.ts` - Audio preferences storage\n- `/client/src/components/channel-list/VoiceDock.tsx` - Voice UI\n- `/client/src/components/settings/VoiceAudioPreferences.tsx` - Audio settings panel\n\n#### Configuration:\n- `/client/src-tauri/Cargo.toml` - No audio libraries\n- `/client/src-tauri/capabilities/default.json` - No WebRTC permissions (delegated to webview)\n- `/client/package.json` - Only `@tauri-apps/api` used, not for audio\n\n---\n\n### Conclusion\n\nThe Tauri desktop client **reuses 100% of the web client's voice implementation**. There are no separate audio capture, processing, or transmission paths. The Tauri backend provides:\n\n1. **Native screen capture for video** (not audio)\n2. **Standard Tauri plugins** (notifications, updates, opener)\n3. **No audio-specific functionality**\n\nAll voice/audio features use the browser's WebRTC stack through Tauri's Chromium webview:\n- Device enumeration via `navigator.mediaDevices`\n- Audio processing via Web Audio API\n- Transmission via mediasoup-client\n- Noise suppression/echo cancellation via browser's libwebrtc constraints\n\nThis is a **correct and efficient architecture** - native audio APIs would add complexity without benefit, as WebRTC already provides optimized audio capture and processing.</result>\n<usage><total_tokens>68069</total_tokens><tool_uses>44</tool_uses><duration_ms>143681</duration_ms></usage>\n</task-notification>\nFull transcript available at: REDACTED.output"},"uuid":"a30eb2c4-e9d1-4bca-8ba9-62079ab42313","timestamp":"2026-02-23T15:20:49.394Z","permissionMode":"default"}
{"parentUuid":"a30eb2c4-e9d1-4bca-8ba9-62079ab42313","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","message":{"model":"claude-opus-4-6","id":"msg_01N232DG5yfgsr5fG9QUhYED","type":"message","role":"assistant","content":[{"type":"text","text":"All three agents have completed. The comprehensive voice chat review report is ready at **`VOICE-CHAT-REVIEW.md`** in the project root. Let me know if you'd like to dig into any specific area or start working on any of the identified issues."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":4146,"cache_read_input_tokens":67115,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4146},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYRE9doinMbp7s9ZRProm","type":"assistant","uuid":"17b5611f-c971-4580-87f6-3681af010686","timestamp":"2026-02-23T15:20:55.465Z"}
{"parentUuid":"17b5611f-c971-4580-87f6-3681af010686","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"46d29819-33d9-49a0-81be-8c565956351a","toolUseID":"46d29819-33d9-49a0-81be-8c565956351a","timestamp":"2026-02-23T15:20:55.506Z","uuid":"c373f13d-e75f-4ea6-8c9f-301578736742"}
{"parentUuid":"c373f13d-e75f-4ea6-8c9f-301578736742","isSidechain":false,"userType":"external","cwd":"/home/guibibi/projects/yankcord","sessionId":"ee7ec010-dbd6-4948-8afc-fd015731a85c","version":"2.1.49","gitBranch":"main","slug":"optimized-swinging-sunrise","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1784}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-23T15:20:57.292Z","uuid":"3018345d-83a4-4073-bff0-ef4a050464a9","toolUseID":"46d29819-33d9-49a0-81be-8c565956351a"}
